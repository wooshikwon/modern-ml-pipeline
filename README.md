# ï¿½ï¿½ Modern ML Pipeline

**ì°¨ì„¸ëŒ€ MLOps í”Œë«í¼ - í•™ìŠµë¶€í„° ë°°í¬ê¹Œì§€ ìë™í™”ëœ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸**

[![Python 3.11+](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/badge/dependency-uv-green.svg)](https://github.com/astral-sh/uv)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ“‹ í”„ë¡œì íŠ¸ ì†Œê°œ

Modern ML Pipelineì€ **YAML ì„¤ì •ë§Œìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ë°°í¬**í•  ìˆ˜ ìˆëŠ” í†µí•© MLOps í”Œë«í¼ì…ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ íŠ¹ì§•

- **ğŸ”§ Zero-Code ML**: YAML ë ˆì‹œí”¼ë§Œìœ¼ë¡œ ëª¨ë“  ML ëª¨ë¸ ì‹¤í—˜ ê°€ëŠ¥
- **âš¡ ìë™ ìµœì í™”**: Optuna ê¸°ë°˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹
- **ğŸ—ï¸ ì™„ì „í•œ ì¬í˜„ì„±**: ë™ì¼í•œ ê²°ê³¼ 100% ë³´ì¥
- **ğŸŒ ë©€í‹° í™˜ê²½**: LOCAL â†’ DEV â†’ PROD ë‹¨ê³„ì  í™•ì¥
- **ğŸš€ ì¦‰ì‹œ ë°°í¬**: í•™ìŠµëœ ëª¨ë¸ ë°”ë¡œ API ì„œë¹™

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (5ë¶„ ì„¤ì •)

### 1. ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/wooshikwon/modern-ml-pipeline.git
cd modern-ml-pipeline

# Python í™˜ê²½ ì„¤ì • (uv ê¶Œì¥)
uv venv && uv sync
# ë˜ëŠ” pip ì‚¬ìš©ì‹œ: pip install -r requirements.txt
```

### 2. í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

```bash
# ìƒˆ í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
uv run python main.py init

# ìƒì„±ëœ íŒŒì¼ í™•ì¸
ls config/    # base.yaml, data_adapters.yaml
ls recipes/   # example_recipe.yaml
```

### 3. ì²« ë²ˆì§¸ ë ˆì‹œí”¼ ìƒì„± (`guide` ëª…ë ¹ì–´)

```bash
# sklearnì˜ RandomForestClassifierì— ëŒ€í•œ ë ˆì‹œí”¼ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
uv run python main.py guide sklearn.ensemble.RandomForestClassifier > recipes/my_first_model.yaml

# ìƒì„±ëœ íŒŒì¼ì„ ì—´ì–´ source_uri, target_column ë“±ì„ ë‹¹ì‹ ì˜ ë°ì´í„°ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
```

### 4. ëª¨ë¸ ê²€ì¦ ë° í•™ìŠµ

```bash
# ìˆ˜ì •ëœ ë ˆì‹œí”¼ íŒŒì¼ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
uv run python main.py validate --recipe-file recipes/my_first_model.yaml

# ëª¨ë¸ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
uv run python main.py train --recipe-file recipes/my_first_model.yaml

# í•™ìŠµ ê²°ê³¼ í™•ì¸ (MLflow UI - ìë™ ì‹¤í–‰)
# ë¡œì»¬ íŒŒì¼ ëª¨ë“œ: MLflow UIê°€ ìë™ìœ¼ë¡œ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤
# ë¸Œë¼ìš°ì €ì—ì„œ ìë™ìœ¼ë¡œ ì—´ë¦¬ê±°ë‚˜ ì½˜ì†” ë©”ì‹œì§€ì˜ URLë¡œ ì ‘ì†í•˜ì„¸ìš”
# ìˆ˜ë™ ì‹¤í–‰: mlflow ui --backend-store-uri ./mlruns
```

### 5. ëª¨ë¸ ë°°í¬ ë° ì¶”ë¡ 

```bash
# í•™ìŠµì—ì„œ ë‚˜ì˜¨ run-id ì‚¬ìš© (ì˜ˆ: abc123def456)
RUN_ID="your-run-id-here"

# ë°°ì¹˜ ì¶”ë¡ 
uv run python main.py batch-inference --run-id $RUN_ID

# ì‹¤ì‹œê°„ API ì„œë¹™
uv run python main.py serve-api --run-id $RUN_ID
# API í…ŒìŠ¤íŠ¸: curl http://localhost:8000/predict -X POST -H 'Content-Type: application/json' -d '{"user_id": 1, "event_ts": "2024-01-01T00:00:00"}'
```

### 6. Docker ì´ë¯¸ì§€ë¡œ ì‹¤í–‰

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ (ì„œë¹™ìš©)
docker build -t mmp-api --target serve .

# ëª¨ë¸ ì„œë¹™ (í¬íŠ¸ 8000 ë…¸ì¶œ)
docker run --rm -p 8000:8000 mmp-api --run-id $RUN_ID

# ì´ë¯¸ì§€ ë¹Œë“œ (í•™ìŠµìš©)
docker build -t mmp-train --target train .

# í•™ìŠµ ì‹¤í–‰ (ë ˆì‹œí”¼ íŒŒì¼ ê²½ë¡œ ì§€ì •)
docker run --rm mmp-train --recipe-file recipes/recipe_example.yaml
```

---

## ğŸ“– ê¸°ë³¸ ì‚¬ìš©ë²•

### CLI ëª…ë ¹ì–´ ì „ì²´ ëª©ë¡

```bash
# í”„ë¡œì íŠ¸ ê´€ë¦¬
uv run python main.py init [--dir ./my-project]     # ìƒˆ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
uv run python main.py validate --recipe-file <path> # ì„¤ì • íŒŒì¼ ê²€ì¦

# ë ˆì‹œí”¼ ê°€ì´ë“œ
uv run python main.py guide <model_class_path>       # ëª¨ë¸ì— ë§ëŠ” ë ˆì‹œí”¼ í…œí”Œë¦¿ ìƒì„±

# ëª¨ë¸ ê°œë°œ
uv run python main.py train --recipe-file <path>    # ëª¨ë¸ í•™ìŠµ
uv run python main.py train --recipe-file <path> --context-params '{"date":"2024-01-01"}'  # ë™ì  íŒŒë¼ë¯¸í„°

# ëª¨ë¸ ì¶”ë¡ 
uv run python main.py batch-inference --run-id <id> # ë°°ì¹˜ ì¶”ë¡ 
uv run python main.py serve-api --run-id <id>       # ì‹¤ì‹œê°„ API

# ì‹œìŠ¤í…œ ê²€ì¦
uv run python main.py test-contract                 # ì¸í”„ë¼ ì—°ê²° í…ŒìŠ¤íŠ¸
```

### Recipe íŒŒì¼ ì‘ì„±ë²•

RecipeëŠ” ëª¨ë¸ì˜ ëª¨ë“  ë…¼ë¦¬ë¥¼ ì •ì˜í•˜ëŠ” YAML íŒŒì¼ì…ë‹ˆë‹¤:

```yaml
# recipes/my_model.yaml
model:
  # ëª¨ë¸ í´ë˜ìŠ¤ (sklearn, xgboost, lightgbm ë“± ëª¨ë“  Python íŒ¨í‚¤ì§€)
  class_path: "sklearn.ensemble.RandomForestClassifier"
  
  # í•˜ì´í¼íŒŒë¼ë¯¸í„° (ê³ ì •ê°’ ë˜ëŠ” ìµœì í™” ë²”ìœ„)
  hyperparameters:
    n_estimators: 100              # ê³ ì •ê°’
    max_depth: {type: "int", low: 3, high: 10}  # ìë™ ìµœì í™” ë²”ìœ„
  
  # ë°ì´í„° ë¡œë”©
  loader:
    name: "default_loader"
    source_uri: "data/my_dataset.parquet"  # íŒŒì¼ ê²½ë¡œ ë˜ëŠ” SQL
    adapter: storage
  
  # ë°ì´í„° ì „ì²˜ë¦¬
  preprocessor:
    name: "default_preprocessor"
    params:
      exclude_cols: ["id", "timestamp"]
  
  # ëª¨ë¸ ì„¤ì •
  data_interface:
    task_type: "classification"    # classification, regression, causal
    target_col: "target"

# ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ì„ íƒì‚¬í•­)
hyperparameter_tuning:
  enabled: true
  n_trials: 50
  metric: "roc_auc"
  direction: "maximize"
```

---

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### 1. ë™ì  SQL í…œí”Œë¦¿ (Jinja2)

```sql
-- recipes/sql/dynamic_query.sql.j2
SELECT user_id, feature1, feature2, target
FROM my_table 
WHERE date = '{{ target_date }}'
LIMIT {{ limit | default(1000) }}
```

```bash
# í…œí”Œë¦¿ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜ ì‹¤í–‰
uv run python main.py train \
  --recipe-file recipes/templated_model.yaml \
  --context-params '{"target_date": "2024-01-01", "limit": 5000}'
```

### 2. Feature Store ì—°ë™

```yaml
# recipes/feature_store_model.yaml
model:
  augmenter:
    type: "feature_store"
    features:
      - feature_namespace: "user_demographics"
        features: ["age", "country"]
      - feature_namespace: "user_behavior"
        features: ["click_rate", "conversion_rate"]
```

### 3. í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬

```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ì „í™˜
APP_ENV=local   uv run python main.py train ...  # ë¡œì»¬ íŒŒì¼ ê¸°ë°˜
APP_ENV=dev     uv run python main.py train ...  # PostgreSQL + Redis  
APP_ENV=prod    uv run python main.py train ...  # BigQuery + Redis Labs
```

---

## ğŸŒ ì‹¤í–‰ ëª¨ë“œë³„ ê°€ì´ë“œ

### ğŸš€ ë…ë¦½ ì‹¤í–‰ ëª¨ë“œ (ê¸°ë³¸ê°’ - ê¶Œì¥)
**MLflow Graceful Degradation ì ìš© - ì™¸ë¶€ ì„œë²„ ì—†ì´ë„ ì™„ì „ ë™ì‘**

```bash
# ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥ - ì™¸ë¶€ ì„œë²„ë‚˜ Docker ë¶ˆí•„ìš”  
uv run python main.py train --recipe-file recipes/example.yaml
```

- **MLflow**: ë¡œì»¬ íŒŒì¼ (`./mlruns`) + ìë™ UI ì‹¤í–‰
- **Feature Store**: PassThrough ëª¨ë“œ (ì™¸ë¶€ ì˜ì¡´ì„± ì—†ìŒ)  
- **ë°ì´í„°**: ë¡œì»¬ íŒŒì¼ (CSV, Parquet ë“±)
- **íŠ¹ì§•**: ì„¤ì¹˜ ì¦‰ì‹œ ì‹¤í–‰, ì¸í„°ë„· ì—°ê²° ë¶ˆí•„ìš”, ë¹ ë¥¸ ì‹¤í—˜

### ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥ ëª¨ë“œ (mmp-local-dev ì—°ë™)
**ì„ íƒì  ê³ ê¸‰ ê¸°ëŠ¥ - Feature Store ë° ê³µìœ  MLflow ì„œë²„ ì‚¬ìš©**

```bash
# 1. mmp-local-dev ì„¤ì¹˜ ë° ì‹¤í–‰ (ì„ íƒì‚¬í•­)
git clone https://github.com/wooshikwon/mmp-local-dev.git ../mmp-local-dev  
cd ../mmp-local-dev && docker-compose up -d

# 2. í™˜ê²½ ë³€ê²½ í›„ ì‹¤í–‰
echo "APP_ENV=dev" > .env
echo "MLFLOW_TRACKING_URI=http://localhost:5002" >> .env
uv run python main.py train --recipe-file recipes/example.yaml
```

- **MLflow**: ê³µìœ  ì„œë²„ (http://localhost:5002)
- **Feature Store**: Feast (PostgreSQL + Redis)
- **ë°ì´í„°**: ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒ, íŒ€ ê³µìœ  ì‹¤í—˜  
- **íŠ¹ì§•**: í”„ë¡œë•ì…˜ ìœ ì‚¬ í™˜ê²½, íŒ€ í˜‘ì—…, Feature Store í…ŒìŠ¤íŠ¸

### â˜ï¸ í´ë¼ìš°ë“œ ì—°ê²° ëª¨ë“œ (í”„ë¡œë•ì…˜)
```bash
# í™˜ê²½ë³€ìˆ˜ë¡œ í´ë¼ìš°ë“œ ì„œë²„ ì—°ê²°
APP_ENV=prod MLFLOW_TRACKING_URI=https://your-mlflow-server.com \
uv run python main.py train --recipe-file recipes/prod_model.yaml
```

- **MLflow**: í´ë¼ìš°ë“œ ì„œë²„ (GCP/AWS/Azure)
- **Feature Store**: í”„ë¡œë•ì…˜ Feast í´ëŸ¬ìŠ¤í„°
- **ë°ì´í„°**: BigQuery, Snowflake ë“± ëŒ€ê·œëª¨ DW
- **MLflow**: í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€
- **íŠ¹ì§•**: í™•ì¥ì„±, ì•ˆì •ì„±

---

## ğŸ“Š ì§€ì›í•˜ëŠ” ML í”„ë ˆì„ì›Œí¬

### ë¶„ë¥˜ (Classification)
```yaml
# scikit-learn
class_path: "sklearn.ensemble.RandomForestClassifier"
class_path: "sklearn.linear_model.LogisticRegression"

# XGBoost
class_path: "xgboost.XGBClassifier"

# LightGBM  
class_path: "lightgbm.LGBMClassifier"
```

### íšŒê·€ (Regression)
```yaml
class_path: "sklearn.ensemble.RandomForestRegressor"
class_path: "sklearn.linear_model.LinearRegression"
class_path: "xgboost.XGBRegressor"
class_path: "lightgbm.LGBMRegressor"
```

### ì¸ê³¼ì¶”ë¡  (Causal Inference)
```yaml
# CausalML
class_path: "causalml.inference.meta.XGBTRegressor"
class_path: "causalml.inference.meta.TRegressor"
```

---

## ğŸ” í™˜ê²½ë³€ìˆ˜ ë° ë¹„ë°€ ê´€ë¦¬

Modern ML Pipelineì€ **config YAMLì—ëŠ” ì—°ê²° ì •ë³´ë§Œ, ì‹¤ì œ ë¹„ë°€ì€ í™˜ê²½ë³€ìˆ˜ë¡œ ì£¼ì…**í•˜ëŠ” ë³´ì•ˆ íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ğŸ“‹ ê¸°ë³¸ ì‚¬ìš©ë²•

#### 1. .env íŒŒì¼ ì„¤ì •
```bash
# ê¸°ë³¸ .env íŒŒì¼ ìƒì„±
cp .env.example .env

# í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cat >> .env << EOF
APP_ENV=local
MLFLOW_TRACKING_URI=http://localhost:5002
POSTGRES_PASSWORD=mysecretpassword
EOF
```

#### 2. Config YAMLì—ì„œ í™˜ê²½ë³€ìˆ˜ ì°¸ì¡°
```yaml
# config/prod.yaml
data_adapters:
  adapters:
    sql:
      connection_uri: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}"

mlflow:
  tracking_uri: ${MLFLOW_TRACKING_URI}

feature_store:
  feast_config:
    online_store:
      connection_string: ${REDIS_CONNECTION_STRING}
```

### ğŸŒ ì¸í”„ë¼ë³„ ì„¤ì • ì˜ˆì‹œ

#### â˜ï¸ Google Cloud Platform
```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export GCP_PROJECT_ID="my-ml-project"
export GOOGLE_APPLICATION_CREDENTIALS="/path/to/service-account.json"
export BIGQUERY_DATASET="ml_pipeline_data"

# configì—ì„œ ì°¸ì¡°
# connection_uri: "bigquery://${GCP_PROJECT_ID}/${BIGQUERY_DATASET}"
```

#### â˜ï¸ Amazon Web Services  
```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê¶Œì¥: IAM Role ì‚¬ìš©)
export AWS_ACCESS_KEY_ID="AKIA..."
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_REGION="us-east-1"
export S3_BUCKET="my-ml-data-bucket"

# configì—ì„œ ì°¸ì¡°
# storage_options:
#   key: ${AWS_ACCESS_KEY_ID}
#   secret: ${AWS_SECRET_ACCESS_KEY}
```

#### ğŸ”µ Microsoft Azure
```bash
# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export AZURE_STORAGE_ACCOUNT="mystorageaccount"  
export AZURE_STORAGE_KEY="your-storage-key"
export AZURE_SQL_PASSWORD="your-password"

# configì—ì„œ ì°¸ì¡°
# storage_options:
#   account_name: ${AZURE_STORAGE_ACCOUNT}
#   account_key: ${AZURE_STORAGE_KEY}
```

### ğŸ”’ ë³´ì•ˆ Best Practices

#### 1. ë¡œì»¬ ê°œë°œ
```bash
# .env íŒŒì¼ ì‚¬ìš© (ìë™ ë¡œë”©ë¨)
echo "POSTGRES_PASSWORD=dev-password" >> .env
echo "API_KEY=dev-api-key" >> .env
```

#### 2. ì»¨í…Œì´ë„ˆ/CI-CD
```bash
# í™˜ê²½ë³€ìˆ˜ë¡œ ì§ì ‘ ì£¼ì…
docker run -e POSTGRES_PASSWORD="$VAULT_PASSWORD" my-ml-app
export POSTGRES_PASSWORD="$(kubectl get secret db-secret -o jsonpath='{.data.password}' | base64 -d)"
```

#### 3. í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ (ê¶Œì¥)
```bash
# ì„œë¹„ìŠ¤ ê³„ì •/IAM Role ìë™ ì¸ì¦ (í™˜ê²½ë³€ìˆ˜ ë¶ˆí•„ìš”)
gcloud auth application-default login  # GCP
# EC2/EKSì˜ IAM Role ìë™ ì‚¬ìš©        # AWS  
# Managed Identity ìë™ ì‚¬ìš©           # Azure
```

### ğŸ¯ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© íŒ¨í„´

**í•„ìˆ˜ ë³€ìˆ˜** (ê¸°ë³¸ê°’ ì—†ìŒ):
```yaml
connection_uri: "postgresql://user:${POSTGRES_PASSWORD}@host/db"
```

**ì„ íƒì  ë³€ìˆ˜** (ê¸°ë³¸ê°’ ì œê³µ):
```yaml  
mlflow:
  tracking_uri: ${MLFLOW_TRACKING_URI:./mlruns}  # ê¸°ë³¸ê°’: ë¡œì»¬ íŒŒì¼
  experiment_name: ${EXPERIMENT_NAME:Default-Experiment}
```

### ğŸ“š ì§€ì›í•˜ëŠ” ëª¨ë“  í™˜ê²½ë³€ìˆ˜

ì „ì²´ í™˜ê²½ë³€ìˆ˜ ëª©ë¡ê³¼ ì„¤ì • ì˜ˆì‹œëŠ” [.env.example](/.env.example) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”:

- **ê¸°ë³¸ ì„¤ì •**: `APP_ENV`, `LOG_LEVEL`
- **MLflow**: `MLFLOW_TRACKING_URI`, `MLFLOW_EXPERIMENT_NAME`
- **ë°ì´í„°ë² ì´ìŠ¤**: `POSTGRES_*`, `BIGQUERY_*`, `SNOWFLAKE_*`
- **í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€**: `GCS_*`, `S3_*`, `AZURE_*`
- **Feature Store**: `REDIS_*`, `FEAST_*`
- **ë³´ì•ˆ**: `API_SECRET_KEY`, `JWT_SECRET_KEY`
- **ëª¨ë‹ˆí„°ë§**: `SENTRY_DSN`, `DATADOG_API_KEY`

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

**1. MLflow ìë™ ì „í™˜ í™•ì¸**
```bash
# Graceful Degradation ë™ì‘ í™•ì¸ - ì„œë²„ ì—†ì´ë„ ì •ìƒ ë™ì‘
curl http://localhost:5002/health
# í™˜ê²½ë³€ìˆ˜ í™•ì¸
echo $MLFLOW_TRACKING_URI
```

**2. ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ**
```bash
# í˜„ì¬ ê²½ë¡œ í™•ì¸
pwd
# ë°ì´í„° íŒŒì¼ ê²½ë¡œ í™•ì¸ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
ls data/my_dataset.parquet
```

**3. íŒ¨í‚¤ì§€ ì˜ì¡´ì„± ì˜¤ë¥˜**
```bash
# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì¶”ê°€ ì„¤ì¹˜
uv add scikit-learn xgboost lightgbm
# ë˜ëŠ”: pip install scikit-learn xgboost lightgbm
```

**4. Feature Store ì—°ê²° ì˜¤ë¥˜**
```bash
# Redis ì—°ê²° í™•ì¸
redis-cli ping
# PostgreSQL ì—°ê²° í™•ì¸  
psql -h localhost -p 5432 -U mlpipeline_user -d mlpipeline_db
```

### ë¡œê·¸ í™•ì¸

```bash
# ìƒì„¸ ë¡œê·¸ ì¶œë ¥
export LOG_LEVEL=DEBUG
uv run python main.py train --recipe-file recipes/my_model.yaml

# ë¡œê·¸ íŒŒì¼ ìœ„ì¹˜
tail -f logs/modern_ml_pipeline.log
```

---

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- **[ê°œë°œì ê°€ì´ë“œ](docs/DEVELOPER_GUIDE.md)**: ì‹¬í™” ì‚¬ìš©ë²• ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•
- **[ì¸í”„ë¼ ê°€ì´ë“œ](docs/INFRASTRUCTURE_STACKS.md)**: í™˜ê²½ë³„ ì¸í”„ë¼ ì„¤ì •
- **[Blueprint](blueprint.md)**: ì‹œìŠ¤í…œì˜ í•µì‹¬ ì„¤ê³„ ì›ì¹™ê³¼ ì‹¤ì œ ì½”ë“œ êµ¬í˜„ì„ ì—°ê²°í•œ ê¸°ìˆ  ì²­ì‚¬ì§„

---

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ìˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

---

## ğŸ“ ì§€ì› ë° ë¬¸ì˜

- **ì´ìŠˆ ì œë³´**: [GitHub Issues](https://github.com/wooshikwon/modern-ml-pipeline/issues)
- **ë¬¸ì„œ**: [Wiki](https://github.com/wooshikwon/modern-ml-pipeline/wiki)
- **ì´ë©”ì¼**: [your-email@example.com](mailto:your-email@example.com)
