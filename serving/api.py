import uvicorn
import pandas as pd
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from typing import Dict, Any, List, Type
from pydantic import BaseModel, create_model

from src.settings import Settings
from src.utils.system.logger import logger
from src.utils.system import mlflow_utils
from serving.schemas import (
    get_pk_from_loader_sql,
    create_dynamic_prediction_request,
    create_batch_prediction_request,
    PredictionResponse,
    BatchPredictionResponse,
    HealthCheckResponse,
    # ğŸ†• Blueprint v17.0: ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆë“¤
    ModelMetadataResponse,
    OptimizationHistoryResponse,
    HyperparameterOptimizationInfo,
    TrainingMethodologyInfo,
)

class AppContext:
    def __init__(self):
        self.model: mlflow.pyfunc.PyFuncModel | None = None
        self.model_uri: str = ""
        self.settings: Settings | None = None
        self.feature_store_config: Dict | None = None
        self.feature_columns: List[str] = []
        self.join_key: str = ""
        self.PredictionRequest: Type[BaseModel] = create_model("DefaultPredictionRequest")
        self.BatchPredictionRequest: Type[BaseModel] = create_model("DefaultBatchPredictionRequest")

app_context = AppContext()

def create_app(run_id: str) -> FastAPI:
    @asynccontextmanager
    async def lifespan(app: FastAPI):
        logger.info("FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
        
        try:
            # 1. ì§€ì •ëœ run_idë¡œ ì™„ì „í•œ Wrapped Artifact ë¡œë“œ
            model_uri = f"runs:/{run_id}/model"
            app_context.model = mlflow.pyfunc.load_model(model_uri)
            app_context.model_uri = model_uri
            logger.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_uri}")

            # 2. í˜„ì¬ í™˜ê²½ì˜ config ë¡œë“œ (ì„œë¹™ ì„¤ì •ë§Œ í•„ìš”)
            from src.settings import load_settings
            temp_settings = load_settings("xgboost_x_learner")  # í™˜ê²½ ì„¤ì •ë§Œ ì‚¬ìš©
            app_context.settings = temp_settings
            app_context.feature_store_config = temp_settings.serving.realtime_feature_store

            # ğŸ†• 3. Blueprint v17.0: ì •êµí•œ SQL íŒŒì‹±ìœ¼ë¡œ API ìŠ¤í‚¤ë§ˆ ìƒì„±
            from src.utils.system.sql_utils import parse_select_columns, parse_feature_columns
            
            # loader_sql_snapshotì—ì„œ API ì…ë ¥ ì»¬ëŸ¼ ì¶”ì¶œ
            pk_fields = parse_select_columns(app_context.model.loader_sql_snapshot)
            logger.info(f"API ìš”ì²­ PK í•„ë“œë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤: {pk_fields}")

            # 4. Feature Store ì¡°íšŒ ì¤€ë¹„ (Blueprint 4.2.3ì˜ 4ë²ˆ)
            feature_columns, join_key = parse_feature_columns(app_context.model.augmenter_sql_snapshot)
            app_context.feature_columns = feature_columns
            app_context.join_key = join_key
            logger.info(f"Feature Store ì¡°íšŒ ì¤€ë¹„ ì™„ë£Œ: {len(feature_columns)}ê°œ ì»¬ëŸ¼, JOIN í‚¤: {join_key}")

            # 5. ë™ì  Pydantic ëª¨ë¸ ìƒì„±
            app_context.PredictionRequest = create_dynamic_prediction_request(
                model_name="dynamic", pk_fields=pk_fields
            )
            app_context.BatchPredictionRequest = create_batch_prediction_request(
                app_context.PredictionRequest
            )
            logger.info("ë™ì  API ìŠ¤í‚¤ë§ˆ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ë˜ëŠ” API ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            app_context.model = None
        
        yield
        
        logger.info("FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ.")

    app = FastAPI(
        title=f"Uplift Model API (Run ID: {run_id})",
        description="ê°€ìƒ ì¿ í° ë°œì†¡ íš¨ê³¼ ì˜ˆì¸¡ API - Blueprint v13.0",
        version="13.0.0",
        lifespan=lifespan,
    )

    @app.get("/", tags=["General"])
    async def root() -> Dict[str, str]:
        return {
            "message": "Uplift Model Prediction API",
            "status": "ready" if app_context.model else "error",
            "model_uri": app_context.model_uri,
        }

    @app.get("/health", response_model=HealthCheckResponse, tags=["General"])
    async def health() -> HealthCheckResponse:
        if not app_context.model or not app_context.settings:
            raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ëª¨ë¸ ì •ë³´ë¥¼ Wrapperì˜ recipe_snapshotì—ì„œ ê°€ì ¸ì˜¤ê¸°
        model_info = "unknown"
        if app_context.model and hasattr(app_context.model, 'recipe_snapshot'):
            model_info = app_context.model.recipe_snapshot.get('class_path', 'unknown')
        
        return HealthCheckResponse(
            status="healthy",
            model_uri=app_context.model_uri,
            model_name=model_info,
        )

    @app.post("/predict", response_model=PredictionResponse, tags=["Prediction"])
    async def predict(request: app_context.PredictionRequest) -> PredictionResponse:
        if not app_context.model or not app_context.settings:
            raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        try:
            input_df = pd.DataFrame([request.dict()])
            predict_params = {
                "run_mode": "serving",
                "feature_store_config": app_context.feature_store_config,
                "feature_columns": app_context.feature_columns,
            }
            predictions = app_context.model.predict(input_df, params=predict_params)
            
            uplift_score = predictions["uplift_score"].iloc[0]
            
            # ğŸ†• Blueprint v17.0: ìµœì í™” ì •ë³´ í¬í•¨
            hpo_info = app_context.model.hyperparameter_optimization
            optimization_enabled = hpo_info.get("enabled", False)
            best_score = hpo_info.get("best_score", 0.0) if optimization_enabled else 0.0
            
            return PredictionResponse(
                uplift_score=uplift_score, 
                model_uri=app_context.model_uri,
                optimization_enabled=optimization_enabled,
                best_score=best_score,
            )
        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

    @app.post("/predict_batch", response_model=BatchPredictionResponse, tags=["Prediction"])
    async def predict_batch(
        request: app_context.BatchPredictionRequest,
    ) -> BatchPredictionResponse:
        if not app_context.model or not app_context.settings:
            raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        try:
            input_df = pd.DataFrame([sample.dict() for sample in request.samples])
            if input_df.empty:
                raise HTTPException(status_code=400, detail="ì…ë ¥ ìƒ˜í”Œì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            predict_params = {
                "run_mode": "serving",
                "feature_store_config": app_context.settings.serving.realtime_feature_store,
            }
            predictions_df = app_context.model.predict(input_df, params=predict_params)
            
            # ğŸ†• Blueprint v17.0: ìµœì í™” ì •ë³´ í¬í•¨
            hpo_info = app_context.model.hyperparameter_optimization
            optimization_enabled = hpo_info.get("enabled", False)
            best_score = hpo_info.get("best_score", 0.0) if optimization_enabled else 0.0
            
            return BatchPredictionResponse(
                predictions=predictions_df.to_dict(orient="records"),
                model_uri=app_context.model_uri,
                sample_count=len(predictions_df),
                optimization_enabled=optimization_enabled,
                best_score=best_score,
            )
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

    # ğŸ†• Blueprint v17.0: ëª¨ë¸ ë©”íƒ€ë°ì´í„° ìê¸° ê¸°ìˆ  ì—”ë“œí¬ì¸íŠ¸ë“¤
    
    @app.get("/model/metadata", response_model=ModelMetadataResponse, tags=["Model Metadata"])
    async def get_model_metadata() -> ModelMetadataResponse:
        """
        ëª¨ë¸ì˜ ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ë°˜í™˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”, Data Leakage ë°©ì§€ ì •ë³´ í¬í•¨)
        """
        try:
            if app_context.model is None:
                raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì •ë³´ êµ¬ì„±
            hpo_info = app_context.model.hyperparameter_optimization
            hyperparameter_optimization = HyperparameterOptimizationInfo(
                enabled=hpo_info.get("enabled", False),
                engine=hpo_info.get("engine", ""),
                best_params=hpo_info.get("best_params", {}),
                best_score=hpo_info.get("best_score", 0.0),
                total_trials=hpo_info.get("total_trials", 0),
                pruned_trials=hpo_info.get("pruned_trials", 0),
                optimization_time=str(hpo_info.get("optimization_time", "")),
            )
            
            # í•™ìŠµ ë°©ë²•ë¡  ì •ë³´ êµ¬ì„±
            tm_info = app_context.model.training_methodology
            training_methodology = TrainingMethodologyInfo(
                train_test_split_method=tm_info.get("train_test_split_method", ""),
                train_ratio=tm_info.get("train_ratio", 0.8),
                validation_strategy=tm_info.get("validation_strategy", ""),
                preprocessing_fit_scope=tm_info.get("preprocessing_fit_scope", ""),
                random_state=tm_info.get("random_state", 42),
            )
            
            # API ìŠ¤í‚¤ë§ˆ ì •ë³´ êµ¬ì„±
            api_schema = {
                "input_fields": [field for field in app_context.PredictionRequest.__fields__.keys()],
                "sql_source": "loader_sql_snapshot",
                "feature_columns": app_context.feature_columns,
                "join_key": app_context.join_key,
            }
            
            return ModelMetadataResponse(
                model_uri=app_context.model_uri,
                model_class_path=getattr(app_context.model, "model_class_path", ""),
                hyperparameter_optimization=hyperparameter_optimization,
                training_methodology=training_methodology,
                training_metadata=app_context.model.training_metadata,
                api_schema=api_schema,
            )
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/model/optimization", response_model=OptimizationHistoryResponse, tags=["Model Metadata"])
    async def get_optimization_history() -> OptimizationHistoryResponse:
        """
        í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê³¼ì •ì˜ ìƒì„¸ íˆìŠ¤í† ë¦¬ ë°˜í™˜
        """
        try:
            if app_context.model is None:
                raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            hpo_info = app_context.model.hyperparameter_optimization
            
            if not hpo_info.get("enabled", False):
                return OptimizationHistoryResponse(
                    enabled=False,
                    optimization_history=[],
                    search_space={},
                    convergence_info={"message": "í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤."},
                    timeout_occurred=False,
                )
            
            return OptimizationHistoryResponse(
                enabled=True,
                optimization_history=hpo_info.get("optimization_history", []),
                search_space=hpo_info.get("search_space", {}),
                convergence_info={
                    "best_score": hpo_info.get("best_score", 0.0),
                    "total_trials": hpo_info.get("total_trials", 0),
                    "pruned_trials": hpo_info.get("pruned_trials", 0),
                    "optimization_time": str(hpo_info.get("optimization_time", "")),
                },
                timeout_occurred=hpo_info.get("timeout_occurred", False),
            )
            
        except Exception as e:
            logger.error(f"ìµœì í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/model/schema", tags=["Model Metadata"])
    async def get_api_schema() -> Dict[str, Any]:
        """
        ë™ì ìœ¼ë¡œ ìƒì„±ëœ API ìŠ¤í‚¤ë§ˆ ì •ë³´ ë°˜í™˜
        """
        try:
            if app_context.model is None:
                raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            return {
                "prediction_request_schema": app_context.PredictionRequest.schema(),
                "batch_prediction_request_schema": app_context.BatchPredictionRequest.schema(),
                "loader_sql_snapshot": app_context.model.loader_sql_snapshot,
                "extracted_fields": [field for field in app_context.PredictionRequest.__fields__.keys()],
                "feature_store_info": {
                    "feature_columns": app_context.feature_columns,
                    "join_key": app_context.join_key,
                    "feature_store_config": app_context.feature_store_config,
                },
            }
            
        except Exception as e:
            logger.error(f"API ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

    return app

def run_api_server(run_id: str, host: str = "0.0.0.0", port: int = 8000):
    """
    run_id ê¸°ë°˜ API ì„œë²„ ì‹¤í–‰
    Blueprint v13.0 ì™„ì „ êµ¬í˜„: ì •í™•í•œ ëª¨ë¸ ì‹ë³„ê³¼ ì¬í˜„ì„± ë³´ì¥
    """
    app = create_app(run_id)
    uvicorn.run(app, host=host, port=port)
