#!/usr/bin/env python3
"""
Week 1 ë³€ê²½ì‚¬í•­ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- Recipe Schemaì˜ task_choice í•„ë“œ
- Catalog ê¸°ë°˜ DataHandler ì„ íƒ
- Factoryì˜ task_choice í™œìš©
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.settings.recipe import Recipe
from src.settings import Settings
from src.factory.factory import Factory

def test_recipe_schema_with_task_choice():
    """ìƒˆë¡œìš´ Recipe Schema (task_choice) í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Test 1: Recipe Schema with task_choice")
    
    recipe_data = {
        "name": "test_classification",
        "task_choice": "classification",  # âœ… ìƒˆë¡œìš´ í•„ë“œ
        "model": {
            "class_path": "sklearn.ensemble.RandomForestClassifier",
            "library": "sklearn",
            "hyperparameters": {
                "tuning_enabled": False,
                "values": {"n_estimators": 100, "random_state": 42}
            }
        },
        "data": {
            "loader": {
                "source_uri": "test_data.csv"
            },
            "fetcher": {
                "type": "pass_through"
            },
            "data_interface": {
                # task_type ì œê±°ë¨! âœ…
                "target_column": "target",
                "entity_columns": ["id"]
            }
        },
        "evaluation": {
            "metrics": ["accuracy", "f1"],
            "validation": {
                "method": "train_test_split",
                "test_size": 0.2,
                "random_state": 42
            }
        }
    }
    
    try:
        recipe = Recipe(**recipe_data)
        print(f"   âœ… Recipe ìƒì„± ì„±ê³µ")
        print(f"   ğŸ“‹ task_choice: {recipe.task_choice}")
        print(f"   ğŸ“‹ get_task_type(): {recipe.get_task_type()}")
        
        # task_choiceì™€ get_task_type()ê°€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        assert recipe.task_choice == recipe.get_task_type()
        print(f"   âœ… task_choiceì™€ get_task_type() ì¼ì¹˜ í™•ì¸")
        
        return recipe
        
    except Exception as e:
        print(f"   âŒ Recipe ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def test_catalog_based_datahandler():
    """Catalog ê¸°ë°˜ DataHandler ì„ íƒ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test 2: Catalog-based DataHandler Selection")
    
    from src.components.datahandler.registry import DataHandlerRegistry
    
    # 1. sklearn ëª¨ë¸ â†’ tabular handler
    tabular_handler = DataHandlerRegistry._get_data_handler_from_catalog(
        "sklearn.ensemble.RandomForestClassifier"
    )
    print(f"   ğŸ“Š sklearn.RandomForestClassifier â†’ {tabular_handler}")
    assert tabular_handler == "tabular"
    
    # 2. LSTM ëª¨ë¸ â†’ deeplearning handler
    dl_handler = DataHandlerRegistry._get_data_handler_from_catalog(
        "src.models.custom.lstm_timeseries.LSTMTimeSeries"
    )
    print(f"   ğŸ§  LSTM TimeSeries â†’ {dl_handler}")
    assert dl_handler == "deeplearning"
    
    # 3. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ â†’ ê¸°ë³¸ê°’
    default_handler = DataHandlerRegistry._get_data_handler_from_catalog(
        "unknown.model.Class"
    )
    print(f"   â“ Unknown Model â†’ {default_handler}")
    assert default_handler == "tabular"
    
    print("   âœ… Catalog ê¸°ë°˜ Handler ì„ íƒ ë™ì‘ í™•ì¸")

def test_factory_integration():
    """Factoryì˜ task_choice í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test 3: Factory Integration with task_choice")
    
    # Classification + sklearn ëª¨ë¸ í…ŒìŠ¤íŠ¸
    recipe_data = {
        "name": "factory_test",
        "task_choice": "classification",
        "model": {
            "class_path": "sklearn.ensemble.RandomForestClassifier", 
            "library": "sklearn",
            "hyperparameters": {
                "tuning_enabled": False,
                "values": {"n_estimators": 10, "random_state": 42}
            }
        },
        "data": {
            "loader": {"source_uri": "test.csv"},
            "fetcher": {"type": "pass_through"},
            "data_interface": {
                "target_column": "target",
                "entity_columns": ["id"]
            }
        },
        "evaluation": {
            "metrics": ["accuracy"],
            "validation": {"method": "train_test_split"}
        }
    }
    
    try:
        from src.settings.config import Config
        
        recipe = Recipe(**recipe_data)
        
        # ìµœì†Œí•œì˜ Config ìƒì„± (í•„ìˆ˜ í•„ë“œ í¬í•¨)
        mock_config_data = {
            "environment": {"name": "local", "debug": True},
            "mlflow": {
                "tracking_uri": "sqlite:///test.db",
                "experiment_name": "test_experiment"
            },
            "data_source": {
                "provider": "local", 
                "connection_string": "test.db",
                "name": "test_datasource",
                "adapter_type": "storage"
            },
            "feature_store": {"provider": "none"}
        }
        config = Config(**mock_config_data)
        
        settings = Settings(config=config, recipe=recipe)
        factory = Factory(settings)
        
        print(f"   âœ… Factory ìƒì„± ì„±ê³µ")
        print(f"   ğŸ“‹ Recipe task_choice: {recipe.task_choice}")
        
        # DataHandler ìƒì„± í…ŒìŠ¤íŠ¸
        try:
            datahandler = factory.create_datahandler()
            print(f"   âœ… DataHandler ìƒì„± ì„±ê³µ: {type(datahandler).__name__}")
        except Exception as e:
            print(f"   âš ï¸  DataHandler ìƒì„± ì˜¤ë¥˜ (ì˜ˆìƒë¨): {e}")
        
        # Evaluator ìƒì„± í…ŒìŠ¤íŠ¸  
        try:
            evaluator = factory.create_evaluator()
            print(f"   âœ… Evaluator ìƒì„± ì„±ê³µ: {type(evaluator).__name__}")
        except Exception as e:
            print(f"   âš ï¸  Evaluator ìƒì„± ì˜¤ë¥˜ (ì˜ˆìƒë¨): {e}")
        
        # Model ìƒì„± í…ŒìŠ¤íŠ¸
        try:
            model = factory.create_model()
            print(f"   âœ… Model ìƒì„± ì„±ê³µ: {type(model).__name__}")
        except Exception as e:
            print(f"   âš ï¸  Model ìƒì„± ì˜¤ë¥˜ (ì˜ˆìƒë¨): {e}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Factory í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_timeseries_lstm_integration():
    """TimeSeries + LSTM í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Test 4: TimeSeries LSTM Integration")
    
    recipe_data = {
        "name": "lstm_timeseries_test",
        "task_choice": "timeseries",  # âœ… task_choice ì‚¬ìš©
        "model": {
            "class_path": "src.models.custom.lstm_timeseries.LSTMTimeSeries",
            "library": "pytorch", 
            "hyperparameters": {
                "tuning_enabled": False,
                "values": {
                    "hidden_dim": 64,
                    "num_layers": 2,
                    "epochs": 5,  # í…ŒìŠ¤íŠ¸ìš© ì§§ì€ epoch
                    "batch_size": 16
                }
            }
        },
        "data": {
            "loader": {"source_uri": "timeseries_data.csv"},
            "fetcher": {"type": "pass_through"},
            "data_interface": {
                "target_column": "value",
                "entity_columns": ["id"],
                "timestamp_column": "timestamp"  # timeseries í•„ìˆ˜
            }
        },
        "evaluation": {
            "metrics": ["mse", "mae"],
            "validation": {"method": "train_test_split"}
        }
    }
    
    try:
        recipe = Recipe(**recipe_data)
        print(f"   âœ… TimeSeries Recipe ìƒì„± ì„±ê³µ")
        print(f"   ğŸ“‹ Task choice: {recipe.task_choice}")
        print(f"   ğŸ• Timestamp column: {recipe.data.data_interface.timestamp_column}")
        
        # ê²€ì¦ ë¡œì§ í™•ì¸
        assert recipe.task_choice == "timeseries"
        assert recipe.data.data_interface.timestamp_column is not None
        
        # Catalogì—ì„œ deeplearning handler í™•ì¸
        from src.components.datahandler.registry import DataHandlerRegistry
        handler = DataHandlerRegistry._get_data_handler_from_catalog(
            "src.models.custom.lstm_timeseries.LSTMTimeSeries"
        )
        print(f"   ğŸ§  LSTM â†’ {handler} handler")
        assert handler == "deeplearning"
        
        print(f"   âœ… TimeSeries LSTM ì„¤ì • ê²€ì¦ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"   âŒ TimeSeries LSTM í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ Week 1 ë³€ê²½ì‚¬í•­ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    tests = [
        test_recipe_schema_with_task_choice,
        test_catalog_based_datahandler,  
        test_factory_integration,
        test_timeseries_lstm_integration
    ]
    
    passed = 0
    total = len(tests)
    
    for test_func in tests:
        try:
            result = test_func()
            if result is not False:
                passed += 1
        except Exception as e:
            print(f"   ğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ê²°ê³¼: {passed}/{total} í†µê³¼")
    
    if passed == total:
        print("âœ… ëª¨ë“  Week 1 ë³€ê²½ì‚¬í•­ì´ ì •ìƒ ë™ì‘í•©ë‹ˆë‹¤!")
        print("\nğŸ“‹ ë‹¬ì„±í•œ ê²ƒ:")
        print("   âœ… Recipe Schemaì— task_choice ì¶”ê°€")
        print("   âœ… DataInterfaceì—ì„œ task_type ì œê±°") 
        print("   âœ… ëª¨ë“  Catalogì— data_handler í•„ë“œ ì¶”ê°€")
        print("   âœ… DataHandler Registry ë‹¨ìˆœí™”")
        print("   âœ… Factoryê°€ task_choice ê¸°ë°˜ìœ¼ë¡œ ë™ì‘")
        return True
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì¶”ê°€ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)