"""
Trainer ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸

í•™ìŠµ í”„ë¡œì„¸ìŠ¤, ì»´í¬ë„ŒíŠ¸ ì¡°í•©, ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
"""

import pytest
import pandas as pd
from unittest.mock import Mock, patch, MagicMock
from src.core.trainer import Trainer
from src.settings.settings import Settings


class TestTrainer:
    """Trainer ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸"""
    
    def test_trainer_initialization(self, xgboost_settings: Settings):
        """Trainerê°€ ì˜¬ë°”ë¥¸ ì„¤ì •ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
        trainer = Trainer(xgboost_settings)
        assert trainer.settings == xgboost_settings
        assert trainer.settings.model.name == "xgboost_x_learner"
    
    @patch('src.core.trainer.Factory')
    def test_trainer_component_creation(self, mock_factory, xgboost_settings: Settings):
        """Trainerê°€ í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ìƒì„±í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
        # Mock Factory ì„¤ì •
        mock_factory_instance = Mock()
        mock_augmenter = Mock()
        mock_preprocessor = Mock()
        mock_model = Mock()
        
        mock_factory_instance.create_augmenter.return_value = mock_augmenter
        mock_factory_instance.create_preprocessor.return_value = mock_preprocessor
        mock_factory_instance.create_model.return_value = mock_model
        mock_factory.return_value = mock_factory_instance
        
        trainer = Trainer(xgboost_settings)
        
        # Factoryê°€ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_factory.assert_called_once_with(xgboost_settings)
        assert trainer.factory == mock_factory_instance
    
    def test_train_method(self, xgboost_settings: Settings):
        """train ë©”ì„œë“œì˜ ì „ì²´ í•™ìŠµ ê³¼ì • í…ŒìŠ¤íŠ¸"""
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b', 'c', 'd'],
            'feature1': [1, 2, 3, 4],
            'feature2': [0.1, 0.2, 0.3, 0.4],
            'outcome': [0, 1, 0, 1]
        })
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_preprocessor = Mock()
        mock_model = Mock()
        
        # ì¦ê°•ëœ ë°ì´í„°
        augmented_data = sample_data.copy()
        augmented_data['feature3'] = [10, 20, 30, 40]
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„°
        preprocessed_data = pd.DataFrame({
            'feature1_scaled': [0.1, 0.2, 0.3, 0.4],
            'feature2_scaled': [0.1, 0.2, 0.3, 0.4],
            'feature3_scaled': [0.1, 0.2, 0.3, 0.4]
        })
        
        # Mock ë™ì‘ ì„¤ì •
        mock_augmenter.augment.return_value = augmented_data
        mock_preprocessor.fit.return_value = None
        mock_preprocessor.transform.return_value = preprocessed_data
        mock_model.fit.return_value = None
        
        # Factory mock ì„¤ì •
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        trainer.factory.create_model.return_value = mock_model
        
        # í•™ìŠµ ì‹¤í–‰
        trained_model, trained_preprocessor, metrics = trainer.train(sample_data)
        
        # ê° ë‹¨ê³„ê°€ ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_augmenter.augment.assert_called_once_with(
            sample_data, 
            run_mode="batch", 
            context_params={}
        )
        mock_preprocessor.fit.assert_called_once()
        mock_preprocessor.transform.assert_called_once()
        mock_model.fit.assert_called_once()
        
        # ë°˜í™˜ê°’ í™•ì¸
        assert trained_model == mock_model
        assert trained_preprocessor == mock_preprocessor
        assert isinstance(metrics, dict)
    
    def test_train_with_context_params(self, xgboost_settings: Settings):
        """ì»¨í…ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜ í•™ìŠµ í…ŒìŠ¤íŠ¸"""
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b'],
            'feature1': [1, 2],
            'outcome': [0, 1]
        })
        
        context_params = {
            'start_date': '2023-01-01',
            'end_date': '2023-12-31'
        }
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = Mock()
        trainer.factory.create_model.return_value = Mock()
        
        # ì»¨í…ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜ í•™ìŠµ ì‹¤í–‰
        trainer.train(sample_data, context_params=context_params)
        
        # ì»¨í…ìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ì „ë‹¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_augmenter.augment.assert_called_once_with(
            sample_data, 
            run_mode="batch", 
            context_params=context_params
        )
    
    def test_train_augmentation_error_handling(self, xgboost_settings: Settings):
        """ë°ì´í„° ì¦ê°• ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        sample_data = pd.DataFrame({'member_id': ['a']})
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.side_effect = Exception("Augmentation failed")
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        
        # ì˜¤ë¥˜ê°€ ì ì ˆíˆ ì „íŒŒë˜ëŠ”ì§€ í™•ì¸
        with pytest.raises(Exception, match="Augmentation failed"):
            trainer.train(sample_data)
    
    def test_train_preprocessing_error_handling(self, xgboost_settings: Settings):
        """ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        sample_data = pd.DataFrame({'member_id': ['a']})
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.side_effect = Exception("Preprocessing failed")
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        
        # ì˜¤ë¥˜ê°€ ì ì ˆíˆ ì „íŒŒë˜ëŠ”ì§€ í™•ì¸
        with pytest.raises(Exception, match="Preprocessing failed"):
            trainer.train(sample_data)
    
    def test_train_model_fitting_error_handling(self, xgboost_settings: Settings):
        """ëª¨ë¸ í•™ìŠµ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        sample_data = pd.DataFrame({'member_id': ['a']})
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.return_value = None
        mock_preprocessor.transform.return_value = pd.DataFrame()
        
        mock_model = Mock()
        mock_model.fit.side_effect = Exception("Model training failed")
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        trainer.factory.create_model.return_value = mock_model
        
        # ì˜¤ë¥˜ê°€ ì ì ˆíˆ ì „íŒŒë˜ëŠ”ì§€ í™•ì¸
        with pytest.raises(Exception, match="Model training failed"):
            trainer.train(sample_data)
    
    def test_train_empty_data_handling(self, xgboost_settings: Settings):
        """ë¹ˆ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        empty_data = pd.DataFrame()
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = empty_data
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = Mock()
        trainer.factory.create_model.return_value = Mock()
        
        # ë¹ˆ ë°ì´í„°ê°€ ì ì ˆíˆ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸
        trained_model, trained_preprocessor, metrics = trainer.train(empty_data)
        
        # ê° ì»´í¬ë„ŒíŠ¸ê°€ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_augmenter.augment.assert_called_once()
        assert trained_model is not None
        assert trained_preprocessor is not None
        assert isinstance(metrics, dict)
    
    def test_blueprint_principle_context_injection(self, xgboost_settings: Settings):
        """Blueprint ì›ì¹™ ê²€ì¦: ì»¨í…ìŠ¤íŠ¸ ì£¼ì…"""
        trainer = Trainer(xgboost_settings)
        sample_data = pd.DataFrame({'member_id': ['a']})
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = Mock()
        trainer.factory.create_model.return_value = Mock()
        
        trainer.train(sample_data)
        
        # Augmenterê°€ ì˜¬ë°”ë¥¸ ì»¨í…ìŠ¤íŠ¸(run_mode="batch")ë¡œ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_augmenter.augment.assert_called_once_with(
            sample_data, 
            run_mode="batch", 
            context_params={}
        )
    
    def test_metrics_collection(self, xgboost_settings: Settings):
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b', 'c'],
            'feature1': [1, 2, 3],
            'outcome': [0, 1, 0]
        })
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.return_value = None
        mock_preprocessor.transform.return_value = pd.DataFrame([[1, 2], [3, 4], [5, 6]])
        
        mock_model = Mock()
        mock_model.fit.return_value = None
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        trainer.factory.create_model.return_value = mock_model
        
        # í•™ìŠµ ì‹¤í–‰
        trained_model, trained_preprocessor, metrics = trainer.train(sample_data)
        
        # ë©”íŠ¸ë¦­ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€ í™•ì¸
        assert isinstance(metrics, dict)
        assert 'training_samples' in metrics
        assert 'training_features' in metrics
        assert metrics['training_samples'] == 3
        assert metrics['training_features'] == 2
    
    def test_component_lifecycle(self, xgboost_settings: Settings):
        """ì»´í¬ë„ŒíŠ¸ ë¼ì´í”„ì‚¬ì´í´ í…ŒìŠ¤íŠ¸"""
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b'],
            'feature1': [1, 2],
            'outcome': [0, 1]
        })
        
        trainer = Trainer(xgboost_settings)
        
        # Mock ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ í˜¸ì¶œë˜ëŠ”ì§€ í™•ì¸
        call_order = []
        
        def track_augment(*args, **kwargs):
            call_order.append('augment')
            return sample_data
        
        def track_fit(*args, **kwargs):
            call_order.append('fit')
            return None
        
        def track_transform(*args, **kwargs):
            call_order.append('transform')
            return pd.DataFrame([[1, 2], [3, 4]])
        
        def track_model_fit(*args, **kwargs):
            call_order.append('model_fit')
            return None
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.side_effect = track_augment
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.side_effect = track_fit
        mock_preprocessor.transform.side_effect = track_transform
        
        mock_model = Mock()
        mock_model.fit.side_effect = track_model_fit
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        trainer.factory.create_model.return_value = mock_model
        
        # í•™ìŠµ ì‹¤í–‰
        trainer.train(sample_data)
        
        # ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        expected_order = ['augment', 'fit', 'transform', 'model_fit']
        assert call_order == expected_order


# ğŸ†• Blueprint v17.0: í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤
class TestTrainerHyperparameterOptimization:
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê´€ë ¨ í…ŒìŠ¤íŠ¸"""
    
    def test_hyperparameter_optimization_disabled_by_default(self, xgboost_settings: Settings):
        """ê¸°ë³¸ì ìœ¼ë¡œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ ë¹„í™œì„±í™”ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„±)"""
        trainer = Trainer(xgboost_settings)
        
        # ê¸°ë³¸ ì„¤ì •ì—ì„œëŠ” hyperparameter_tuningì´ Noneì´ê±°ë‚˜ ë¹„í™œì„±í™”
        assert xgboost_settings.hyperparameter_tuning is None or not xgboost_settings.hyperparameter_tuning.enabled
        assert xgboost_settings.model.hyperparameter_tuning is None or not xgboost_settings.model.hyperparameter_tuning.enabled
    
    @patch('src.core.trainer.Factory')
    def test_fixed_hyperparameters_when_optimization_disabled(self, mock_factory, xgboost_settings: Settings):
        """ìµœì í™” ë¹„í™œì„±í™” ì‹œ ê¸°ì¡´ ê³ ì • í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°©ì‹ ì‚¬ìš© í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_factory_instance = Mock()
        mock_preprocessor = Mock()
        mock_model = Mock()
        mock_evaluator = Mock()
        
        mock_factory_instance.create_preprocessor.return_value = mock_preprocessor
        mock_factory_instance.create_evaluator.return_value = mock_evaluator
        mock_evaluator.evaluate.return_value = {"accuracy": 0.85}
        mock_factory.return_value = mock_factory_instance
        
        # ìƒ˜í”Œ ë°ì´í„°
        sample_data = pd.DataFrame({
            'feature1': [1, 2, 3, 4, 5, 6],
            'feature2': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],
            'outcome': [0, 1, 0, 1, 0, 1]
        })
        
        trainer = Trainer(xgboost_settings)
        
        with patch.object(trainer, '_train_with_fixed_hyperparameters') as mock_fixed_train:
            mock_fixed_train.return_value = (mock_preprocessor, mock_model, {"metrics": {"accuracy": 0.85}, "hyperparameter_optimization": {"enabled": False}})
            
            # í•™ìŠµ ì‹¤í–‰
            result = trainer.train(sample_data, mock_model)
            
            # ê³ ì • í•˜ì´í¼íŒŒë¼ë¯¸í„° ë°©ì‹ì´ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
            mock_fixed_train.assert_called_once()
            
            # ê²°ê³¼ì— ìµœì í™” ë¹„í™œì„±í™” ë©”íƒ€ë°ì´í„° í¬í•¨ í™•ì¸
            assert result[2]["hyperparameter_optimization"]["enabled"] is False
    
    @patch('src.core.trainer.optuna')
    @patch('src.core.trainer.Factory')  
    def test_hyperparameter_optimization_enabled(self, mock_factory, mock_optuna, xgboost_settings: Settings):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” í™œì„±í™” ì‹œ Optuna ê¸°ë°˜ ìµœì í™” í…ŒìŠ¤íŠ¸"""
        # ìµœì í™” í™œì„±í™” ì„¤ì •
        from src.settings.settings import HyperparameterTuningSettings
        xgboost_settings.hyperparameter_tuning = HyperparameterTuningSettings(
            enabled=True, n_trials=10, metric="accuracy", direction="maximize"
        )
        xgboost_settings.model.hyperparameter_tuning = HyperparameterTuningSettings(
            enabled=True, n_trials=5, metric="roc_auc", direction="maximize"
        )
        
        # Mock ì„¤ì •
        mock_factory_instance = Mock()
        mock_study = Mock()
        mock_optuna.create_study.return_value = mock_study
        mock_optuna.pruners.MedianPruner.return_value = Mock()
        mock_factory.return_value = mock_factory_instance
        
        # ìƒ˜í”Œ ë°ì´í„°
        sample_data = pd.DataFrame({
            'feature1': [1, 2, 3, 4, 5, 6, 7, 8],
            'feature2': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8],
            'outcome': [0, 1, 0, 1, 0, 1, 0, 1]
        })
        
        trainer = Trainer(xgboost_settings)
        
        with patch.object(trainer, '_train_with_hyperparameter_optimization') as mock_hpo_train:
            mock_hpo_train.return_value = (
                Mock(), Mock(), 
                {
                    "metrics": {"roc_auc": 0.92}, 
                    "hyperparameter_optimization": {
                        "enabled": True,
                        "best_params": {"learning_rate": 0.1, "n_estimators": 100},
                        "best_score": 0.92,
                        "total_trials": 5
                    }
                }
            )
            
            # í•™ìŠµ ì‹¤í–‰
            result = trainer.train(sample_data, Mock())
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë°©ì‹ì´ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
            mock_hpo_train.assert_called_once()
            
            # ê²°ê³¼ì— ìµœì í™” ë©”íƒ€ë°ì´í„° í¬í•¨ í™•ì¸
            hpo_result = result[2]["hyperparameter_optimization"]
            assert hpo_result["enabled"] is True
            assert "best_params" in hpo_result
            assert "best_score" in hpo_result
    
    @patch('src.core.trainer.train_test_split')
    @patch('src.core.trainer.Factory')
    def test_data_leakage_prevention(self, mock_factory, mock_split, xgboost_settings: Settings):
        """Data Leakage ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜ í…ŒìŠ¤íŠ¸ (Train-only fit)"""
        # Mock ì„¤ì •
        mock_factory_instance = Mock()
        mock_preprocessor = Mock()
        mock_factory_instance.create_preprocessor.return_value = mock_preprocessor
        mock_factory.return_value = mock_factory_instance
        
        # ë¶„í• ëœ ë°ì´í„° Mock
        train_data = pd.DataFrame({
            'feature1': [1, 2, 3, 4],
            'feature2': [0.1, 0.2, 0.3, 0.4],
            'outcome': [0, 1, 0, 1]
        })
        val_data = pd.DataFrame({
            'feature1': [5, 6],
            'feature2': [0.5, 0.6],
            'outcome': [1, 0]
        })
        mock_split.return_value = (train_data, val_data)
        
        trainer = Trainer(xgboost_settings)
        
        # _single_training_iteration í˜¸ì¶œë¡œ Data Leakage ë°©ì§€ í…ŒìŠ¤íŠ¸
        with patch.object(trainer, '_prepare_training_data') as mock_prepare:
            mock_prepare.side_effect = [
                (train_data[['feature1', 'feature2']], train_data['outcome'], {}),
                (val_data[['feature1', 'feature2']], val_data['outcome'], {})
            ]
            
            with patch.object(trainer, '_create_model_with_params') as mock_create_model:
                mock_model = Mock()
                mock_create_model.return_value = mock_model
                
                with patch.object(trainer, '_fit_model'):
                    with patch.object(trainer, '_extract_optimization_score', return_value=0.85):
                        # ë‹¨ì¼ í•™ìŠµ ë°˜ë³µ ì‹¤í–‰
                        result = trainer._single_training_iteration(train_data, {"param": "value"}, 42)
                        
                        # Preprocessorê°€ Train ë°ì´í„°ì—ë§Œ fitë˜ì—ˆëŠ”ì§€ í™•ì¸
                        mock_preprocessor.fit.assert_called_once()
                        # Transformì€ trainê³¼ validation ëª¨ë‘ì— ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸  
                        assert mock_preprocessor.transform.call_count == 2
                        
                        # ê²°ê³¼ì— Data Leakage ë°©ì§€ ë©”íƒ€ë°ì´í„° í¬í•¨ í™•ì¸
                        assert result['training_methodology']['preprocessing_fit_scope'] == 'train_only'
    
    def test_training_results_structure(self, xgboost_settings: Settings):
        """í•™ìŠµ ê²°ê³¼ êµ¬ì¡°ì²´ê°€ ì˜¬ë°”ë¥´ê²Œ ë°˜í™˜ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""
        trainer = Trainer(xgboost_settings)
        
        # Mockì„ ì‚¬ìš©í•œ í•™ìŠµ ì‹¤í–‰
        with patch.object(trainer, '_train_with_fixed_hyperparameters') as mock_train:
            expected_result = {
                "metrics": {"accuracy": 0.85, "precision": 0.80},
                "hyperparameter_optimization": {"enabled": False},
                "training_methodology": {
                    "train_test_split_method": "stratified",
                    "preprocessing_fit_scope": "train_only"
                }
            }
            mock_train.return_value = (Mock(), Mock(), expected_result)
            
            result = trainer.train(pd.DataFrame({'a': [1, 2], 'b': [3, 4]}), Mock())
            
            # ë°˜í™˜ê°’ êµ¬ì¡° í™•ì¸
            assert len(result) == 3  # preprocessor, model, training_results
            assert isinstance(result[2], dict)
            assert "metrics" in result[2]
            assert "hyperparameter_optimization" in result[2]
            assert "training_methodology" in result[2]
    
    @patch('src.core.trainer.importlib')
    def test_dynamic_model_creation(self, mock_importlib, xgboost_settings: Settings):
        """ë™ì  ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸ (class_path ê¸°ë°˜)"""
        # Mock ëª¨ë¸ í´ë˜ìŠ¤
        mock_model_class = Mock()
        mock_model_instance = Mock()
        mock_model_class.return_value = mock_model_instance
        
        # Mock ëª¨ë“ˆ
        mock_module = Mock()
        mock_module.XGBTRegressor = mock_model_class
        mock_importlib.import_module.return_value = mock_module
        
        trainer = Trainer(xgboost_settings)
        
        # ë™ì  ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
        params = {"learning_rate": 0.1, "n_estimators": 100}
        model = trainer._create_model_with_params("causalml.inference.meta.XGBTRegressor", params)
        
        # ì˜¬ë°”ë¥¸ ëª¨ë“ˆê³¼ í´ë˜ìŠ¤ê°€ importë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_importlib.import_module.assert_called_with("causalml.inference.meta")
        
        # ëª¨ë¸ì´ íŒŒë¼ë¯¸í„°ì™€ í•¨ê»˜ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
        mock_model_class.assert_called_with(**params)
        assert model == mock_model_instance 