"""
Phase 3 Step 3: Feature Store ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ íŒ¨ë¦¬í‹°(Parity) ê²€ì¦

ë™ì¼í•œ ì—”í‹°í‹° í‚¤ì— ëŒ€í•´ ì˜¤í”„ë¼ì¸ ì €ì¥ì†Œì—ì„œ ì¡°íšŒí•œ í”¼ì²˜ì™€ ì˜¨ë¼ì¸ ì €ì¥ì†Œì—ì„œ 
ì¡°íšŒí•œ í”¼ì²˜ê°€ ë°ì´í„° íƒ€ì…ê³¼ ê°’ ëª¨ë‘ì—ì„œ ì™„ë²½í•˜ê²Œ ì¼ì¹˜í•˜ëŠ”ì§€ ê²€ì¦í•˜ëŠ” í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.

Blueprint ì›ì¹™ ê²€ì¦:
- ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ ì €ì¥ì†Œ ê°„ 100% íŒ¨ë¦¬í‹° ë³´ì¥
- ë°ì´í„° íƒ€ì… ë° ê°’ì˜ ì™„ë²½í•œ ì¼ì¹˜ì„± ê²€ì¦
- ì‹¤ì‹œê°„ ì„œë¹™ê³¼ ë°°ì¹˜ ì²˜ë¦¬ì˜ ì¼ê´€ì„± í™•ë³´
- Feature Store ì‹ ë¢°ì„± ë° ì •í™•ì„± ë³´ì¥
"""

import pytest
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from decimal import Decimal

from src.engine.factory import Factory
from src.components.augmenter import Augmenter
from src.settings import Settings

# DEV í™˜ê²½ Feature Store íŒ¨ë¦¬í‹° í…ŒìŠ¤íŠ¸
pytestmark = [
    pytest.mark.integration,
    pytest.mark.requires_dev_stack,
    pytest.mark.feature_store_parity
]

@pytest.fixture(scope="module")
def parity_test_entities():
    """íŒ¨ë¦¬í‹° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í‘œì¤€ ì—”í‹°í‹° ì„¸íŠ¸"""
    base_time = datetime.now()
    
    return [
        {"user_id": "u1001", "product_id": "p2001", "event_timestamp": base_time},
        {"user_id": "u1002", "product_id": "p2002", "event_timestamp": base_time},
        {"user_id": "u1003", "product_id": "p2003", "event_timestamp": base_time},
        {"user_id": "u1001", "product_id": "p2003", "event_timestamp": base_time},  # êµì°¨ ì¡°í•©
        {"user_id": "u1002", "product_id": "p2001", "event_timestamp": base_time},  # êµì°¨ ì¡°í•©
    ]

@pytest.fixture(scope="module")
def comprehensive_feature_list():
    """ê²€ì¦í•  ì „ì²´ í”¼ì²˜ ëª©ë¡"""
    return [
        # ì‚¬ìš©ì í”¼ì²˜
        "user_demographics:age",
        "user_demographics:country_code",
        
        # ì œí’ˆ í”¼ì²˜
        "product_details:price",
        "product_details:category", 
        "product_details:brand",
        
        # êµ¬ë§¤ ìš”ì•½ í”¼ì²˜ (ì‹œê³„ì—´)
        "user_purchase_summary:user_total_purchase_amount_7d",
        "user_purchase_summary:user_total_purchase_amount_30d"
    ]


class TestFeatureStoreParityValidation:
    """
    Feature Store ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ íŒ¨ë¦¬í‹° ì‹¬ì¸µ ê²€ì¦
    Phase 3 Step 3: ì™„ë²½í•œ ì¼ì¹˜ì„± ë³´ì¥
    """

    def test_basic_offline_online_parity(self, dev_test_settings: Settings, parity_test_entities, comprehensive_feature_list):
        """
        [ê¸°ë³¸ íŒ¨ë¦¬í‹°] ì˜¤í”„ë¼ì¸ê³¼ ì˜¨ë¼ì¸ ì €ì¥ì†Œì—ì„œ ì¡°íšŒí•œ ë™ì¼ ì—”í‹°í‹° í”¼ì²˜ì˜ ì™„ë²½í•œ ì¼ì¹˜ì„± ê²€ì¦
        """
        factory = Factory(dev_test_settings)
        feature_store_adapter = factory.create_feature_store_adapter()
        
        spine_df = pd.DataFrame(parity_test_entities)
        
        # 1. ì˜¤í”„ë¼ì¸ ì €ì¥ì†Œì—ì„œ í”¼ì²˜ ì¡°íšŒ
        offline_features = feature_store_adapter.get_historical_features(
            spine_df, comprehensive_feature_list
        )
        
        # 2. ì˜¨ë¼ì¸ ì €ì¥ì†Œì—ì„œ í”¼ì²˜ ì¡°íšŒ
        online_features = feature_store_adapter.get_online_features(
            spine_df, comprehensive_feature_list
        )
        
        # 3. ê¸°ë³¸ ê²€ì¦
        assert not offline_features.empty, "ì˜¤í”„ë¼ì¸ í”¼ì²˜ ì¡°íšŒê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        assert not online_features.empty, "ì˜¨ë¼ì¸ í”¼ì²˜ ì¡°íšŒê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        assert len(offline_features) == len(online_features), \
            f"ì¡°íšŒ ê²°ê³¼ ê±´ìˆ˜ ë¶ˆì¼ì¹˜: ì˜¤í”„ë¼ì¸ {len(offline_features)}, ì˜¨ë¼ì¸ {len(online_features)}"
        
        # 4. ì—”í‹°í‹°ë³„ íŒ¨ë¦¬í‹° ê²€ì¦
        mismatches = []
        
        for i in range(len(spine_df)):
            entity = spine_df.iloc[i]
            user_id = entity["user_id"]
            product_id = entity["product_id"]
            
            # í•´ë‹¹ ì—”í‹°í‹°ì˜ ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ í”¼ì²˜ ì°¾ê¸°
            offline_row = offline_features[
                (offline_features["user_id"] == user_id) & 
                (offline_features["product_id"] == product_id)
            ]
            online_row = online_features[
                (online_features["user_id"] == user_id) & 
                (online_features["product_id"] == product_id)
            ]
            
            if len(offline_row) > 0 and len(online_row) > 0:
                offline_data = offline_row.iloc[0]
                online_data = online_row.iloc[0]
                
                # í”¼ì²˜ë³„ ì •í™•í•œ ì¼ì¹˜ì„± ê²€ì¦
                for feature in comprehensive_feature_list:
                    feature_name = feature.split(":")[-1]  # í”¼ì²˜ëª…ë§Œ ì¶”ì¶œ
                    
                    if feature_name in offline_data and feature_name in online_data:
                        offline_val = offline_data[feature_name]
                        online_val = online_data[feature_name]
                        
                        # NULL/NaN ì²˜ë¦¬
                        if pd.isna(offline_val) and pd.isna(online_val):
                            continue  # ë‘˜ ë‹¤ NULLì´ë©´ ì¼ì¹˜
                        
                        # íƒ€ì… ë° ê°’ ì •í™•ì„± ê²€ì¦
                        if offline_val != online_val:
                            mismatches.append({
                                "entity": f"{user_id}/{product_id}",
                                "feature": feature_name,
                                "offline_value": offline_val,
                                "online_value": online_val,
                                "offline_type": type(offline_val).__name__,
                                "online_type": type(online_val).__name__
                            })
        
        # 5. íŒ¨ë¦¬í‹° ê²€ì¦ ê²°ê³¼
        if mismatches:
            mismatch_details = "\n".join([
                f"  {m['entity']} {m['feature']}: ì˜¤í”„ë¼ì¸={m['offline_value']}({m['offline_type']}) != ì˜¨ë¼ì¸={m['online_value']}({m['online_type']})"
                for m in mismatches[:5]  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            ])
            pytest.fail(f"ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ íŒ¨ë¦¬í‹° ìœ„ë°˜ ë°œê²¬ ({len(mismatches)}ê±´):\n{mismatch_details}")
        
        print(f"âœ… ê¸°ë³¸ ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ: {len(spine_df)}ê°œ ì—”í‹°í‹°, {len(comprehensive_feature_list)}ê°œ í”¼ì²˜")

    def test_data_type_consistency_parity(self, dev_test_settings: Settings, parity_test_entities):
        """
        [íƒ€ì… ì¼ê´€ì„±] ì˜¤í”„ë¼ì¸ê³¼ ì˜¨ë¼ì¸ ì €ì¥ì†Œ ê°„ ë°ì´í„° íƒ€ì…ì˜ ì™„ë²½í•œ ì¼ì¹˜ì„± ê²€ì¦
        """
        factory = Factory(dev_test_settings)
        feature_store_adapter = factory.create_feature_store_adapter()
        
        spine_df = pd.DataFrame(parity_test_entities[:3])  # ì²˜ìŒ 3ê°œë§Œ ì‚¬ìš©
        
        # íƒ€ì… ê²€ì¦ì— ì¤‘ì ì„ ë‘” í”¼ì²˜ ì„ íƒ
        type_critical_features = [
            "user_demographics:age",           # int
            "product_details:price",           # float/decimal
            "product_details:brand",           # string
            "user_purchase_summary:user_total_purchase_amount_7d"  # numeric
        ]
        
        offline_features = feature_store_adapter.get_historical_features(
            spine_df, type_critical_features
        )
        online_features = feature_store_adapter.get_online_features(
            spine_df, type_critical_features
        )
        
        assert not offline_features.empty and not online_features.empty, \
            "ì˜¤í”„ë¼ì¸ ë˜ëŠ” ì˜¨ë¼ì¸ í”¼ì²˜ ì¡°íšŒ ì‹¤íŒ¨"
        
        # ì—”í‹°í‹°ë³„ íƒ€ì… ì¼ê´€ì„± ê²€ì¦
        type_mismatches = []
        
        for i in range(len(spine_df)):
            entity = spine_df.iloc[i]
            user_id = entity["user_id"]
            product_id = entity["product_id"]
            
            offline_row = offline_features[
                (offline_features["user_id"] == user_id) & 
                (offline_features["product_id"] == product_id)
            ]
            online_row = online_features[
                (online_features["user_id"] == user_id) & 
                (online_features["product_id"] == product_id)
            ]
            
            if len(offline_row) > 0 and len(online_row) > 0:
                offline_data = offline_row.iloc[0]
                online_data = online_row.iloc[0]
                
                for feature in type_critical_features:
                    feature_name = feature.split(":")[-1]
                    
                    if feature_name in offline_data and feature_name in online_data:
                        offline_val = offline_data[feature_name]
                        online_val = online_data[feature_name]
                        
                        # NULLì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ íƒ€ì… ê²€ì¦
                        if not pd.isna(offline_val) and not pd.isna(online_val):
                            offline_type = type(offline_val)
                            online_type = type(online_val)
                            
                            # íƒ€ì… í˜¸í™˜ì„± ê²€ì¦ (intì™€ floatëŠ” ìˆ«ìí˜•ìœ¼ë¡œ í˜¸í™˜)
                            if not self._types_compatible(offline_type, online_type):
                                type_mismatches.append({
                                    "entity": f"{user_id}/{product_id}",
                                    "feature": feature_name,
                                    "offline_type": offline_type.__name__,
                                    "online_type": online_type.__name__,
                                    "offline_value": offline_val,
                                    "online_value": online_val
                                })
        
        if type_mismatches:
            type_details = "\n".join([
                f"  {m['entity']} {m['feature']}: {m['offline_type']} != {m['online_type']}"
                for m in type_mismatches
            ])
            pytest.fail(f"ë°ì´í„° íƒ€ì… ì¼ê´€ì„± ìœ„ë°˜ ({len(type_mismatches)}ê±´):\n{type_details}")
        
        print("âœ… ë°ì´í„° íƒ€ì… ì¼ê´€ì„± íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ")

    def _types_compatible(self, type1, type2):
        """íƒ€ì… í˜¸í™˜ì„± ê²€ì‚¬ í—¬í¼ ë©”ì„œë“œ"""
        # ìˆ«ìí˜• íƒ€ì…ë“¤ì€ ì„œë¡œ í˜¸í™˜
        numeric_types = {int, float, np.int64, np.float64, Decimal}
        if type1 in numeric_types and type2 in numeric_types:
            return True
        
        # ë¬¸ìì—´ íƒ€ì…ë“¤ì€ ì„œë¡œ í˜¸í™˜
        string_types = {str, np.str_}
        if type1 in string_types and type2 in string_types:
            return True
        
        # ì •í™•íˆ ë™ì¼í•œ íƒ€ì…
        return type1 == type2

    def test_augmenter_parity_through_pipeline(self, dev_test_settings: Settings, parity_test_entities):
        """
        [íŒŒì´í”„ë¼ì¸ íŒ¨ë¦¬í‹°] Augmenterë¥¼ í†µí•œ ë°°ì¹˜/ì„œë¹™ ëª¨ë“œ ê°„ íŒ¨ë¦¬í‹° ê²€ì¦
        """
        factory = Factory(dev_test_settings)
        augmenter: Augmenter = factory.create_augmenter()
        
        spine_df = pd.DataFrame(parity_test_entities[:3])
        
        # 1. ë°°ì¹˜ ëª¨ë“œë¡œ í”¼ì²˜ ì¦ê°•
        batch_augmented = augmenter.augment(spine_df, run_mode="batch")
        
        # 2. ì„œë¹™ ëª¨ë“œë¡œ í”¼ì²˜ ì¦ê°•
        serving_augmented = augmenter.augment(spine_df, run_mode="serving")
        
        # 3. ê¸°ë³¸ ê²€ì¦
        assert not batch_augmented.empty, "ë°°ì¹˜ ëª¨ë“œ í”¼ì²˜ ì¦ê°• ì‹¤íŒ¨"
        assert not serving_augmented.empty, "ì„œë¹™ ëª¨ë“œ í”¼ì²˜ ì¦ê°• ì‹¤íŒ¨"
        assert len(batch_augmented) == len(serving_augmented), \
            f"Augmenter ëª¨ë“œë³„ ê²°ê³¼ ê±´ìˆ˜ ë¶ˆì¼ì¹˜: ë°°ì¹˜ {len(batch_augmented)}, ì„œë¹™ {len(serving_augmented)}"
        
        # 4. ì—”í‹°í‹°ë³„ Augmenter íŒ¨ë¦¬í‹° ê²€ì¦
        augmenter_mismatches = []
        
        for i in range(len(spine_df)):
            entity = spine_df.iloc[i]
            user_id = entity["user_id"]
            product_id = entity["product_id"]
            
            batch_row = batch_augmented[
                (batch_augmented["user_id"] == user_id) & 
                (batch_augmented["product_id"] == product_id)
            ]
            serving_row = serving_augmented[
                (serving_augmented["user_id"] == user_id) & 
                (serving_augmented["product_id"] == product_id)
            ]
            
            if len(batch_row) > 0 and len(serving_row) > 0:
                batch_data = batch_row.iloc[0]
                serving_data = serving_row.iloc[0]
                
                # ê³µí†µ í”¼ì²˜ ì»¬ëŸ¼ ì°¾ê¸°
                common_columns = set(batch_data.index) & set(serving_data.index)
                feature_columns = [col for col in common_columns 
                                 if col not in ["user_id", "product_id", "event_timestamp"]]
                
                for col in feature_columns:
                    batch_val = batch_data[col]
                    serving_val = serving_data[col]
                    
                    # NULL ì²˜ë¦¬
                    if pd.isna(batch_val) and pd.isna(serving_val):
                        continue
                    
                    # ê°’ ì¼ì¹˜ì„± ê²€ì¦
                    if batch_val != serving_val:
                        augmenter_mismatches.append({
                            "entity": f"{user_id}/{product_id}",
                            "feature": col,
                            "batch_value": batch_val,
                            "serving_value": serving_val
                        })
        
        if augmenter_mismatches:
            augmenter_details = "\n".join([
                f"  {m['entity']} {m['feature']}: ë°°ì¹˜={m['batch_value']} != ì„œë¹™={m['serving_value']}"
                for m in augmenter_mismatches[:5]
            ])
            pytest.fail(f"Augmenter ë°°ì¹˜/ì„œë¹™ ëª¨ë“œ íŒ¨ë¦¬í‹° ìœ„ë°˜ ({len(augmenter_mismatches)}ê±´):\n{augmenter_details}")
        
        print("âœ… Augmenter íŒŒì´í”„ë¼ì¸ íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ")

    def test_timestamp_handling_parity(self, dev_test_settings: Settings):
        """
        [íƒ€ì„ìŠ¤íƒ¬í”„ íŒ¨ë¦¬í‹°] ë™ì¼ ì‹œì  ì¡°íšŒ ì‹œ ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬ ì¼ê´€ì„± ê²€ì¦
        """
        factory = Factory(dev_test_settings)
        feature_store_adapter = factory.create_feature_store_adapter()
        
        # ì •í™•í•œ ì‹œì  ì§€ì •
        precise_time = datetime.now().replace(microsecond=0) - timedelta(hours=1)
        
        test_spine = pd.DataFrame([{
            "user_id": "u1001",
            "product_id": "p2001", 
            "event_timestamp": precise_time
        }])
        
        # ì˜¤í”„ë¼ì¸/ì˜¨ë¼ì¸ ë™ì¼ ì‹œì  ì¡°íšŒ
        offline_result = feature_store_adapter.get_historical_features(
            test_spine, ["user_demographics:age", "product_details:price"]
        )
        online_result = feature_store_adapter.get_online_features(
            test_spine, ["user_demographics:age", "product_details:price"]
        )
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¼ê´€ì„± ê²€ì¦
        if not offline_result.empty and not online_result.empty:
            offline_timestamp = offline_result.iloc[0].get("event_timestamp")
            online_timestamp = online_result.iloc[0].get("event_timestamp")
            
            if offline_timestamp is not None and online_timestamp is not None:
                # ë‘ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ëª¨ë‘ ì§€ì •ëœ ì‹œì  ì´ì „ì´ì–´ì•¼ í•¨
                assert offline_timestamp <= precise_time, \
                    f"ì˜¤í”„ë¼ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ë¥˜: {offline_timestamp} > {precise_time}"
                assert online_timestamp <= precise_time, \
                    f"ì˜¨ë¼ì¸ íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ë¥˜: {online_timestamp} > {precise_time}"
                
                print(f"  ì˜¤í”„ë¼ì¸ íƒ€ì„ìŠ¤íƒ¬í”„: {offline_timestamp}")
                print(f"  ì˜¨ë¼ì¸ íƒ€ì„ìŠ¤íƒ¬í”„: {online_timestamp}")
                print(f"  ì¿¼ë¦¬ íƒ€ì„ìŠ¤íƒ¬í”„: {precise_time}")
        
        print("âœ… íƒ€ì„ìŠ¤íƒ¬í”„ ì²˜ë¦¬ íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ")

    def test_large_scale_parity_validation(self, dev_test_settings: Settings):
        """
        [ëŒ€ê·œëª¨ íŒ¨ë¦¬í‹°] ëŒ€ëŸ‰ ì—”í‹°í‹°ì— ëŒ€í•œ ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ íŒ¨ë¦¬í‹° ê²€ì¦
        """
        factory = Factory(dev_test_settings)
        feature_store_adapter = factory.create_feature_store_adapter()
        
        # ëŒ€ëŸ‰ ì—”í‹°í‹° ìƒì„± (ì¡°í•© í™•ì¥)
        users = [f"u{1000 + i}" for i in range(20)]
        products = [f"p{2000 + i}" for i in range(10)]
        base_time = datetime.now()
        
        large_entities = []
        for i in range(100):  # 100ê°œ ì—”í‹°í‹°
            user_id = users[i % len(users)]
            product_id = products[i % len(products)]
            large_entities.append({
                "user_id": user_id,
                "product_id": product_id,
                "event_timestamp": base_time - timedelta(minutes=i % 60)
            })
        
        large_spine = pd.DataFrame(large_entities)
        
        # í•µì‹¬ í”¼ì²˜ì— ëŒ€í•´ì„œë§Œ ëŒ€ê·œëª¨ íŒ¨ë¦¬í‹° ê²€ì¦
        key_features = [
            "user_demographics:age",
            "product_details:price",
            "product_details:brand"
        ]
        
        # ëŒ€ëŸ‰ ì¡°íšŒ ìˆ˜í–‰
        offline_large = feature_store_adapter.get_historical_features(
            large_spine, key_features
        )
        online_large = feature_store_adapter.get_online_features(
            large_spine, key_features
        )
        
        # ëŒ€ê·œëª¨ íŒ¨ë¦¬í‹° í†µê³„ ë¶„ì„
        if not offline_large.empty and not online_large.empty:
            total_comparisons = 0
            parity_violations = 0
            
            # ìƒ˜í”Œë§ì„ í†µí•œ íŒ¨ë¦¬í‹° ê²€ì¦ (ì „ì²´ë¥¼ ë‹¤ í™•ì¸í•˜ë©´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼)
            sample_size = min(50, len(large_spine))
            sample_entities = large_spine.head(sample_size)
            
            for _, entity in sample_entities.iterrows():
                user_id = entity["user_id"]
                product_id = entity["product_id"]
                
                offline_matches = offline_large[
                    (offline_large["user_id"] == user_id) & 
                    (offline_large["product_id"] == product_id)
                ]
                online_matches = online_large[
                    (online_large["user_id"] == user_id) & 
                    (online_large["product_id"] == product_id)
                ]
                
                if len(offline_matches) > 0 and len(online_matches) > 0:
                    offline_data = offline_matches.iloc[0]
                    online_data = online_matches.iloc[0]
                    
                    for feature in key_features:
                        feature_name = feature.split(":")[-1]
                        
                        if feature_name in offline_data and feature_name in online_data:
                            total_comparisons += 1
                            
                            offline_val = offline_data[feature_name]
                            online_val = online_data[feature_name]
                            
                            # NULL ì²˜ë¦¬
                            if pd.isna(offline_val) and pd.isna(online_val):
                                continue
                            
                            if offline_val != online_val:
                                parity_violations += 1
            
            # íŒ¨ë¦¬í‹° ìœ„ë°˜ìœ¨ ê³„ì‚°
            if total_comparisons > 0:
                violation_rate = (parity_violations / total_comparisons) * 100
                assert violation_rate < 1.0, \
                    f"ëŒ€ê·œëª¨ íŒ¨ë¦¬í‹° ìœ„ë°˜ìœ¨ì´ í—ˆìš© ê¸°ì¤€ ì´ˆê³¼: {violation_rate:.2f}% (ê¸°ì¤€: 1.0%)"
                
                print(f"  ì „ì²´ ë¹„êµ: {total_comparisons}ê±´")
                print(f"  íŒ¨ë¦¬í‹° ìœ„ë°˜: {parity_violations}ê±´")
                print(f"  ìœ„ë°˜ìœ¨: {violation_rate:.2f}%")
        
        print(f"âœ… ëŒ€ê·œëª¨ íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ: {len(large_spine)}ê°œ ì—”í‹°í‹° ìƒ˜í”Œë§ ê²€ì¦")

    def test_edge_case_parity_validation(self, dev_test_settings: Settings):
        """
        [ì—£ì§€ ì¼€ì´ìŠ¤ íŒ¨ë¦¬í‹°] íŠ¹ìˆ˜í•œ ìƒí™©ì—ì„œì˜ ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ íŒ¨ë¦¬í‹° ê²€ì¦
        """
        factory = Factory(dev_test_settings)
        feature_store_adapter = factory.create_feature_store_adapter()
        
        # Edge Case 1: ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”í‹°í‹°
        nonexistent_spine = pd.DataFrame([{
            "user_id": "u9999_nonexistent",
            "product_id": "p9999_nonexistent",
            "event_timestamp": datetime.now()
        }])
        
        offline_nonexistent = feature_store_adapter.get_historical_features(
            nonexistent_spine, ["user_demographics:age"]
        )
        online_nonexistent = feature_store_adapter.get_online_features(
            nonexistent_spine, ["user_demographics:age"]
        )
        
        # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”í‹°í‹°ì— ëŒ€í•´ì„œëŠ” ë‘˜ ë‹¤ ë¹„ì–´ìˆê±°ë‚˜ NULLì´ì–´ì•¼ í•¨
        if not offline_nonexistent.empty and not online_nonexistent.empty:
            offline_age = offline_nonexistent.iloc[0].get("age")
            online_age = online_nonexistent.iloc[0].get("age")
            
            # ë‘˜ ë‹¤ NULLì´ê±°ë‚˜ ë‘˜ ë‹¤ ë™ì¼í•œ ê¸°ë³¸ê°’ì´ì–´ì•¼ í•¨
            if not (pd.isna(offline_age) and pd.isna(online_age)):
                assert offline_age == online_age, \
                    f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”í‹°í‹° ì²˜ë¦¬ ë¶ˆì¼ì¹˜: ì˜¤í”„ë¼ì¸={offline_age}, ì˜¨ë¼ì¸={online_age}"
        
        # Edge Case 2: ë§¤ìš° ë¨¼ ê³¼ê±° ì‹œì 
        old_time_spine = pd.DataFrame([{
            "user_id": "u1001",
            "product_id": "p2001",
            "event_timestamp": datetime(2020, 1, 1)  # ë§¤ìš° ì˜›ë‚ 
        }])
        
        offline_old = feature_store_adapter.get_historical_features(
            old_time_spine, ["user_demographics:age"]
        )
        online_old = feature_store_adapter.get_online_features(
            old_time_spine, ["user_demographics:age"]
        )
        
        # ì˜¤ë˜ëœ ì‹œì ì— ëŒ€í•´ì„œë„ ì¼ê´€ëœ ì²˜ë¦¬ê°€ ë˜ì–´ì•¼ í•¨
        if not offline_old.empty and not online_old.empty:
            offline_age_old = offline_old.iloc[0].get("age")
            online_age_old = online_old.iloc[0].get("age")
            
            # ê°’ì´ ìˆë‹¤ë©´ ì¼ì¹˜í•´ì•¼ í•¨
            if not (pd.isna(offline_age_old) and pd.isna(online_age_old)):
                assert offline_age_old == online_age_old, \
                    f"ì˜¤ë˜ëœ ì‹œì  ë°ì´í„° ì²˜ë¦¬ ë¶ˆì¼ì¹˜: ì˜¤í”„ë¼ì¸={offline_age_old}, ì˜¨ë¼ì¸={online_age_old}"
        
        print("âœ… ì—£ì§€ ì¼€ì´ìŠ¤ íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ")

    def test_comprehensive_parity_report(self, dev_test_settings: Settings, parity_test_entities, comprehensive_feature_list):
        """
        [ì¢…í•© ë¦¬í¬íŠ¸] ì „ì²´ Feature Store íŒ¨ë¦¬í‹° ìƒíƒœì— ëŒ€í•œ ì¢…í•©ì ì¸ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
        """
        factory = Factory(dev_test_settings)
        feature_store_adapter = factory.create_feature_store_adapter()
        
        spine_df = pd.DataFrame(parity_test_entities)
        
        # ì „ì²´ í”¼ì²˜ì— ëŒ€í•œ íŒ¨ë¦¬í‹° ê²€ì¦
        offline_features = feature_store_adapter.get_historical_features(
            spine_df, comprehensive_feature_list
        )
        online_features = feature_store_adapter.get_online_features(
            spine_df, comprehensive_feature_list
        )
        
        # ì¢…í•© íŒ¨ë¦¬í‹° ë¦¬í¬íŠ¸ ìƒì„±
        parity_report = {
            "total_entities": len(spine_df),
            "total_features": len(comprehensive_feature_list),
            "offline_results": len(offline_features),
            "online_results": len(online_features),
            "feature_parity_status": {},
            "overall_parity_score": 0.0
        }
        
        total_checks = 0
        successful_checks = 0
        
        # í”¼ì²˜ë³„ íŒ¨ë¦¬í‹° ìƒíƒœ ë¶„ì„
        for feature in comprehensive_feature_list:
            feature_name = feature.split(":")[-1]
            feature_status = {
                "matches": 0,
                "mismatches": 0,
                "nulls": 0,
                "type_errors": 0
            }
            
            for i in range(len(spine_df)):
                entity = spine_df.iloc[i]
                user_id = entity["user_id"]
                product_id = entity["product_id"]
                
                offline_row = offline_features[
                    (offline_features["user_id"] == user_id) & 
                    (offline_features["product_id"] == product_id)
                ]
                online_row = online_features[
                    (online_features["user_id"] == user_id) & 
                    (online_features["product_id"] == product_id)
                ]
                
                if len(offline_row) > 0 and len(online_row) > 0:
                    offline_val = offline_row.iloc[0].get(feature_name)
                    online_val = online_row.iloc[0].get(feature_name)
                    
                    total_checks += 1
                    
                    if pd.isna(offline_val) and pd.isna(online_val):
                        feature_status["nulls"] += 1
                        successful_checks += 1
                    elif pd.isna(offline_val) or pd.isna(online_val):
                        feature_status["mismatches"] += 1
                    elif type(offline_val) != type(online_val):
                        feature_status["type_errors"] += 1
                    elif offline_val == online_val:
                        feature_status["matches"] += 1
                        successful_checks += 1
                    else:
                        feature_status["mismatches"] += 1
            
            parity_report["feature_parity_status"][feature] = feature_status
        
        # ì „ì²´ íŒ¨ë¦¬í‹° ì ìˆ˜ ê³„ì‚°
        if total_checks > 0:
            parity_report["overall_parity_score"] = (successful_checks / total_checks) * 100
        
        # ë¦¬í¬íŠ¸ ì¶œë ¥
        print("\nğŸ“Š Feature Store íŒ¨ë¦¬í‹° ì¢…í•© ë¦¬í¬íŠ¸:")
        print(f"  ì´ ì—”í‹°í‹°: {parity_report['total_entities']}ê°œ")
        print(f"  ì´ í”¼ì²˜: {parity_report['total_features']}ê°œ")
        print(f"  ì „ì²´ íŒ¨ë¦¬í‹° ì ìˆ˜: {parity_report['overall_parity_score']:.2f}%")
        
        # í”¼ì²˜ë³„ ìƒíƒœ ìš”ì•½
        for feature, status in parity_report["feature_parity_status"].items():
            total_feature_checks = sum(status.values())
            if total_feature_checks > 0:
                match_rate = (status["matches"] / total_feature_checks) * 100
                print(f"  {feature}: {match_rate:.1f}% ì¼ì¹˜ (matches: {status['matches']}, mismatches: {status['mismatches']})")
        
        # íŒ¨ë¦¬í‹° ê¸°ì¤€ ê²€ì¦
        assert parity_report["overall_parity_score"] >= 95.0, \
            f"ì „ì²´ íŒ¨ë¦¬í‹° ì ìˆ˜ê°€ ê¸°ì¤€ ë¯¸ë‹¬: {parity_report['overall_parity_score']:.2f}% (ê¸°ì¤€: 95.0%)"
        
        print(f"âœ… ì¢…í•© íŒ¨ë¦¬í‹° ê²€ì¦ ì™„ë£Œ: {parity_report['overall_parity_score']:.2f}% íŒ¨ë¦¬í‹° ë‹¬ì„±") 