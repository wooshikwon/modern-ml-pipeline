"""
End-to-End í†µí•© í…ŒìŠ¤íŠ¸

ì „ì²´ ì‹œìŠ¤í…œì˜ ë™ì‘ê³¼ Blueprint 6ëŒ€ ì›ì¹™ ì¤€ìˆ˜ë¥¼ ê²€ì¦í•˜ëŠ” í…ŒìŠ¤íŠ¸
"""

import pytest
import pandas as pd
from unittest.mock import Mock, patch
from src.engine.factory import Factory
from src.components._trainer import Trainer
from src.pipelines.train_pipeline import run_training
from src.settings import Settings
from src.settings.loaders import load_settings


class TestEndToEndIntegration:
    """End-to-End í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def test_blueprint_principle_1_recipe_vs_config_separation(self):
        """Blueprint ì›ì¹™ 1: ë ˆì‹œí”¼ëŠ” ë…¼ë¦¬, ì„¤ì •ì€ ì¸í”„ë¼"""
        # ì„¤ì • ë¡œë”©ì´ ë ˆì‹œí”¼ì™€ configë¥¼ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¦¬í•˜ëŠ”ì§€ í™•ì¸
        settings = load_settings("xgboost_x_learner")
        
        # ë ˆì‹œí”¼ ì •ë³´ (ëª¨ë¸ ë…¼ë¦¬)
        assert hasattr(settings.model, 'name')
        assert hasattr(settings.model, 'hyperparameters')
        assert hasattr(settings.model, 'loader')
        assert hasattr(settings.model, 'augmenter')
        
        # ì¸í”„ë¼ ì •ë³´ (í™˜ê²½ ì„¤ì •)
        assert hasattr(settings, 'data_sources')
        assert hasattr(settings, 'mlflow')
        
        # ë ˆì‹œí”¼ì— ì¸í”„ë¼ ì •ë³´ê°€ ì§ì ‘ í¬í•¨ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
        assert not hasattr(settings.model, 'mlflow')
        assert not hasattr(settings.model, 'data_sources')
    
    def test_blueprint_principle_2_unified_data_adapter(self, xgboost_settings: Settings):
        """Blueprint ì›ì¹™ 2: í†µí•© ë°ì´í„° ì–´ëŒ‘í„°"""
        factory = Factory(xgboost_settings)
        
        # ëª¨ë“  ì–´ëŒ‘í„°ê°€ í†µí•©ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì§€ëŠ”ì§€ í™•ì¸
        from src.interface.base_data_adapter import BaseDataAdapter
        
        adapters = [
            factory.create_data_adapter("bq"),
            factory.create_data_adapter("gs"),
            factory.create_data_adapter("s3"),
            factory.create_data_adapter("file")
        ]
        
        for adapter in adapters:
            assert isinstance(adapter, BaseDataAdapter)
            assert hasattr(adapter, 'read')
            assert hasattr(adapter, 'write')
            assert adapter.settings == xgboost_settings
    
    def test_blueprint_principle_3_uri_driven_operation(self, xgboost_settings: Settings):
        """Blueprint ì›ì¹™ 3: URI ê¸°ë°˜ ë™ì‘ ë° ë™ì  íŒ©í† ë¦¬"""
        factory = Factory(xgboost_settings)
        
        # URI ìŠ¤í‚´ì— ë”°ë¼ ì˜¬ë°”ë¥¸ ì–´ëŒ‘í„°ê°€ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
        uri_to_adapter = {
            "bq": "BigQueryAdapter",
            "gs": "GCSAdapter",
            "s3": "S3Adapter",
            "file": "FileSystemAdapter"
        }
        
        for scheme, expected_class in uri_to_adapter.items():
            adapter = factory.create_data_adapter(scheme)
            assert adapter.__class__.__name__ == expected_class
    
    def test_blueprint_principle_4_pure_logic_artifact(self, xgboost_settings: Settings):
        """Blueprint ì›ì¹™ 4: ìˆœìˆ˜ ë¡œì§ ì•„í‹°íŒ©íŠ¸"""
        factory = Factory(xgboost_settings)
        
        # ìƒì„±ëœ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ìˆœìˆ˜ ë¡œì§ë§Œ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸
        augmenter = factory.create_augmenter()
        preprocessor = factory.create_preprocessor()
        model = factory.create_model()
        
        # ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì„¤ì •ì„ ì°¸ì¡°í•˜ì§€ë§Œ ì¸í”„ë¼ ì •ë³´ë¥¼ ì§ì ‘ í¬í•¨í•˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
        assert augmenter.settings == xgboost_settings
        assert preprocessor.settings == xgboost_settings
        assert model.settings == xgboost_settings
        
        # ì¸í”„ë¼ ì •ë³´ëŠ” ì„¤ì •ì„ í†µí•´ì„œë§Œ ì ‘ê·¼ ê°€ëŠ¥
        assert not hasattr(augmenter, 'mlflow_uri')
        assert not hasattr(preprocessor, 'data_source_uri')
        assert not hasattr(model, 'database_config')
    
    def test_blueprint_principle_5_single_augmenter_context_injection(self, xgboost_settings: Settings):
        """Blueprint ì›ì¹™ 5: ë‹¨ì¼ Augmenter, ì»¨í…ìŠ¤íŠ¸ ì£¼ì…"""
        factory = Factory(xgboost_settings)
        augmenter = factory.create_augmenter()
        
        # ë‹¨ì¼ Augmenter ì¸ìŠ¤í„´ìŠ¤ê°€ ë‹¤ë¥¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
        sample_data = pd.DataFrame({'member_id': ['a', 'b']})
        
        with patch.object(augmenter, '_augment_batch') as mock_batch:
            mock_batch.return_value = sample_data
            augmenter.augment(sample_data, run_mode="batch")
            
        with patch.object(augmenter, '_augment_realtime') as mock_realtime:
            mock_realtime.return_value = sample_data
            augmenter.augment(
                sample_data, 
                run_mode="realtime",
                feature_store_config={}
            )
        
        # ë™ì¼í•œ ì¸ìŠ¤í„´ìŠ¤ê°€ ë‹¤ë¥¸ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë™ì‘í–ˆëŠ”ì§€ í™•ì¸
        mock_batch.assert_called_once()
        mock_realtime.assert_called_once()
    
    def test_blueprint_principle_6_self_describing_api(self, xgboost_settings: Settings):
        """Blueprint ì›ì¹™ 6: ìê¸° ê¸°ìˆ  API"""
        # API ìŠ¤í‚¤ë§ˆ ìƒì„±ì´ ëª¨ë¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ”ì§€ í™•ì¸
        from serving.schemas import create_dynamic_prediction_request
        
        # ëª¨ë¸ì˜ loader SQLì„ ê¸°ë°˜ìœ¼ë¡œ API ìŠ¤í‚¤ë§ˆê°€ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
        # (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” SQL íŒŒì‹±ì„ í†µí•´ PK ì¶”ì¶œ)
        
        with patch('src.utils.sql_utils.get_selected_columns') as mock_get_columns:
            mock_get_columns.return_value = ['member_id']
            
            # ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„±
            schema_class = create_dynamic_prediction_request(['member_id'])
            
            # ìŠ¤í‚¤ë§ˆê°€ ëª¨ë¸ ì •ë³´ë¥¼ ë°˜ì˜í•˜ëŠ”ì§€ í™•ì¸
            assert hasattr(schema_class, '__fields__')
            assert 'member_id' in schema_class.__fields__
    
    @patch('src.pipelines.train_pipeline.mlflow')
    def test_complete_training_workflow(self, mock_mlflow, xgboost_settings: Settings):
        """ì™„ì „í•œ í•™ìŠµ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # Mock MLflow ì„¤ì •
        mock_mlflow.set_tracking_uri.return_value = None
        mock_mlflow.set_experiment.return_value = None
        mock_mlflow.start_run.return_value = None
        mock_mlflow.log_params.return_value = None
        mock_mlflow.log_metrics.return_value = None
        mock_mlflow.pyfunc.log_model.return_value = None
        mock_mlflow.set_tag.return_value = None
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b', 'c', 'd'],
            'feature1': [1, 2, 3, 4],
            'feature2': [0.1, 0.2, 0.3, 0.4],
            'treatment': [0, 1, 0, 1],
            'outcome': [0.5, 1.5, 0.3, 1.2]
        })
        
        # ë°ì´í„° ë¡œë”© Mock
        with patch('src.pipelines.train_pipeline.get_dataset_loader') as mock_loader:
            mock_loader_instance = Mock()
            mock_loader_instance.load.return_value = sample_data
            mock_loader.return_value = mock_loader_instance
            
            # í•™ìŠµ ì‹¤í–‰
            run_training(xgboost_settings)
            
            # MLflow ì›Œí¬í”Œë¡œìš°ê°€ ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
            mock_mlflow.set_tracking_uri.assert_called_once()
            mock_mlflow.set_experiment.assert_called_once()
            mock_mlflow.start_run.assert_called_once()
            mock_mlflow.pyfunc.log_model.assert_called_once()
    
    def test_component_interaction_flow(self, xgboost_settings: Settings):
        """ì»´í¬ë„ŒíŠ¸ ê°„ ìƒí˜¸ì‘ìš© íë¦„ í…ŒìŠ¤íŠ¸"""
        trainer = Trainer(xgboost_settings)
        
        # ìƒ˜í”Œ ë°ì´í„°
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b', 'c'],
            'feature1': [1, 2, 3],
            'feature2': [0.1, 0.2, 0.3],
            'treatment': [0, 1, 0],
            'outcome': [0.5, 1.5, 0.3]
        })
        
        # ì»´í¬ë„ŒíŠ¸ ê°„ ë°ì´í„° íë¦„ ì¶”ì 
        call_order = []
        
        def track_augment(*args, **kwargs):
            call_order.append('augment')
            return sample_data
        
        def track_fit(*args, **kwargs):
            call_order.append('preprocess_fit')
            return None
        
        def track_transform(*args, **kwargs):
            call_order.append('preprocess_transform')
            return pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
        
        def track_model_fit(*args, **kwargs):
            call_order.append('model_fit')
            return None
        
        # Mock ì»´í¬ë„ŒíŠ¸ ì„¤ì •
        mock_augmenter = Mock()
        mock_augmenter.augment.side_effect = track_augment
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.side_effect = track_fit
        mock_preprocessor.transform.side_effect = track_transform
        
        mock_model = Mock()
        mock_model.fit.side_effect = track_model_fit
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        trainer.factory.create_model.return_value = mock_model
        
        # í•™ìŠµ ì‹¤í–‰
        trainer.train(sample_data)
        
        # ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì»´í¬ë„ŒíŠ¸ê°€ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
        expected_order = ['augment', 'preprocess_fit', 'preprocess_transform', 'model_fit']
        assert call_order == expected_order
    
    def test_error_propagation_and_handling(self, xgboost_settings: Settings):
        """ì˜¤ë¥˜ ì „íŒŒ ë° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        trainer = Trainer(xgboost_settings)
        sample_data = pd.DataFrame({'member_id': ['a']})
        
        # ê° ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì „íŒŒë˜ëŠ”ì§€ í™•ì¸
        
        # 1. Augmenter ì˜¤ë¥˜
        mock_augmenter = Mock()
        mock_augmenter.augment.side_effect = Exception("Augmentation failed")
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        
        with pytest.raises(Exception, match="Augmentation failed"):
            trainer.train(sample_data)
        
        # 2. Preprocessor ì˜¤ë¥˜
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.side_effect = Exception("Preprocessing failed")
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        
        with pytest.raises(Exception, match="Preprocessing failed"):
            trainer.train(sample_data)
        
        # 3. Model ì˜¤ë¥˜
        mock_augmenter = Mock()
        mock_augmenter.augment.return_value = sample_data
        
        mock_preprocessor = Mock()
        mock_preprocessor.fit.return_value = None
        mock_preprocessor.transform.return_value = pd.DataFrame()
        
        mock_model = Mock()
        mock_model.fit.side_effect = Exception("Model training failed")
        
        trainer.factory = Mock()
        trainer.factory.create_augmenter.return_value = mock_augmenter
        trainer.factory.create_preprocessor.return_value = mock_preprocessor
        trainer.factory.create_model.return_value = mock_model
        
        with pytest.raises(Exception, match="Model training failed"):
            trainer.train(sample_data)
    
    def test_system_resilience(self, xgboost_settings: Settings):
        """ì‹œìŠ¤í…œ íšŒë³µë ¥ í…ŒìŠ¤íŠ¸"""
        factory = Factory(xgboost_settings)
        
        # 1. ì„ íƒì  ì˜ì¡´ì„± ì²˜ë¦¬ (Redis)
        try:
            redis_adapter = factory.create_data_adapter("redis")
            # Redisê°€ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            assert redis_adapter is not None
        except (ImportError, ValueError):
            # Redisê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì ì ˆí•œ ì²˜ë¦¬
            pass
        
        # 2. ì¸ì¦ ì‹¤íŒ¨ ì‹œ graceful degradation
        bigquery_adapter = factory.create_data_adapter("bq")
        
        # ì¸ì¦ ì‹¤íŒ¨ ì‹œì—ë„ ì–´ëŒ‘í„°ê°€ ìƒì„±ë˜ê³  ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜
        result = bigquery_adapter.read("bq://project.dataset.table", params={})
        assert isinstance(result, pd.DataFrame)
        
        # 3. ì„¤ì • íŒŒì¼ ëˆ„ë½ ì‹œ ì²˜ë¦¬
        try:
            load_settings("non_existent_model")
            assert False, "Should have raised an exception"
        except Exception as e:
            # ì ì ˆí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ í™•ì¸
            assert "non_existent_model" in str(e) or "not found" in str(e).lower()
    
    def test_data_pipeline_integrity(self, xgboost_settings: Settings):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸ ë¬´ê²°ì„± í…ŒìŠ¤íŠ¸"""
        factory = Factory(xgboost_settings)
        
        # ë°ì´í„° ë³€í™˜ ê³¼ì •ì—ì„œ ë¬´ê²°ì„±ì´ ìœ ì§€ë˜ëŠ”ì§€ í™•ì¸
        sample_data = pd.DataFrame({
            'member_id': ['a', 'b', 'c'],
            'feature1': [1, 2, 3],
            'feature2': [0.1, 0.2, 0.3],
            'outcome': [0, 1, 0]
        })
        
        # 1. Augmenter ì²˜ë¦¬
        augmenter = factory.create_augmenter()
        with patch.object(augmenter, '_augment_batch') as mock_augment:
            mock_augment.return_value = sample_data
            augmented_data = augmenter.augment(sample_data, run_mode="batch")
            
            # ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
            assert len(augmented_data) == len(sample_data)
            assert 'member_id' in augmented_data.columns
        
        # 2. Preprocessor ì²˜ë¦¬
        preprocessor = factory.create_preprocessor()
        with patch.object(preprocessor, 'fit') as mock_fit, \
             patch.object(preprocessor, 'transform') as mock_transform:
            
            mock_fit.return_value = None
            mock_transform.return_value = pd.DataFrame([[1, 2], [3, 4], [5, 6]])
            
            preprocessor.fit(sample_data)
            processed_data = preprocessor.transform(sample_data)
            
            # ë°ì´í„° ë³€í™˜ í›„ ìƒ˜í”Œ ìˆ˜ ìœ ì§€
            assert len(processed_data) == len(sample_data)
    
    def test_configuration_flexibility(self):
        """ì„¤ì • ìœ ì—°ì„± í…ŒìŠ¤íŠ¸"""
        # ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì„¤ì •ì´ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸
        
        # 1. XGBoost ëª¨ë¸ ì„¤ì •
        xgboost_settings = load_settings("xgboost_x_learner")
        assert xgboost_settings.model.name == "xgboost_x_learner"
        
        # 2. CausalForest ëª¨ë¸ ì„¤ì •
        causal_forest_settings = load_settings("causal_forest")
        assert causal_forest_settings.model.name == "causal_forest"
        
        # 3. ê° ëª¨ë¸ì´ ê³ ìœ í•œ ì„¤ì •ì„ ê°€ì§€ëŠ”ì§€ í™•ì¸
        assert xgboost_settings.model.hyperparameters != causal_forest_settings.model.hyperparameters
    
    def test_blueprint_compliance_summary(self, xgboost_settings: Settings):
        """Blueprint ì¤€ìˆ˜ ìš”ì•½ í…ŒìŠ¤íŠ¸"""
        factory = Factory(xgboost_settings)
        
        # ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸ê°€ Blueprint ì›ì¹™ì„ ì¤€ìˆ˜í•˜ëŠ”ì§€ ì¢…í•© í™•ì¸
        
        # 1. ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
        components = {
            'augmenter': factory.create_augmenter(),
            'preprocessor': factory.create_preprocessor(),
            'trainer': factory.create_trainer(),
            'model': factory.create_model()
        }
        
        for name, component in components.items():
            assert component is not None, f"{name} should be created"
            assert hasattr(component, 'settings'), f"{name} should have settings"
            assert component.settings == xgboost_settings, f"{name} should have correct settings"
        
        # 2. ëª¨ë“  ë°ì´í„° ì–´ëŒ‘í„°ê°€ ì˜¬ë°”ë¥´ê²Œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
        adapters = {
            'bigquery': factory.create_data_adapter("bq"),
            'gcs': factory.create_data_adapter("gs"),
            's3': factory.create_data_adapter("s3"),
            'file': factory.create_data_adapter("file")
        }
        
        for name, adapter in adapters.items():
            assert adapter is not None, f"{name} adapter should be created"
            assert hasattr(adapter, 'settings'), f"{name} adapter should have settings"
            assert adapter.settings == xgboost_settings, f"{name} adapter should have correct settings"
        
        # 3. Blueprint 6ëŒ€ ì›ì¹™ ì¤€ìˆ˜ í™•ì¸
        principles_check = {
            'recipe_config_separation': hasattr(xgboost_settings, 'model') and hasattr(xgboost_settings, 'data_sources'),
            'unified_data_adapter': all(hasattr(adapter, 'read') and hasattr(adapter, 'write') for adapter in adapters.values()),
            'uri_driven_operation': len(adapters) == 4,  # 4ê°œì˜ ìŠ¤í‚´ ì§€ì›
            'pure_logic_artifact': all(hasattr(comp, 'settings') for comp in components.values()),
            'single_augmenter': components['augmenter'] is not None,
            'self_describing_api': True  # API ìŠ¤í‚¤ë§ˆ ìƒì„± ê¸°ëŠ¥ ì¡´ì¬
        }
        
        for principle, check in principles_check.items():
            assert check, f"Blueprint principle '{principle}' should be satisfied" 

def test_blueprint_v13_complete_workflow():
    """
    Blueprint v13.0 "The Perfect Balance" ì™„ì „í•œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
    train â†’ batch-inference â†’ serve-api ì „ì²´ í”Œë¡œìš° ê²€ì¦
    """
    # 1. í•™ìŠµ ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜
    
    # Mock settings ìƒì„± (class_path ê¸°ë°˜)
    with patch('src.settings.loaders.load_settings_by_file') as mock_load_settings:  # ğŸ”„ ìˆ˜ì •: settings â†’ loaders
        mock_settings = Mock()
        mock_settings.model.class_path = "src.models.xgboost_x_learner.XGBoostXLearner"
        mock_settings.model.computed = {
            "run_name": "XGBoostXLearner_test_experiment_20240115_120000",
            "model_class_name": "XGBoostXLearner",
            "recipe_file": "test_experiment",
            "timestamp": "20240115_120000"
        }
        mock_load_settings.return_value = mock_settings
        
        # í•™ìŠµ ê²°ê³¼ Mock
        with patch('src.pipelines.train_pipeline.run_training') as mock_training:
            mock_training.return_value = "test_run_id_12345"
            
            # 1ë‹¨ê³„: í•™ìŠµ ì‹¤í–‰
            from src.pipelines.train_pipeline import run_training
            run_id = run_training(mock_settings)
            
            # í•™ìŠµì´ ì˜¬ë°”ë¥¸ ì„¤ì •ìœ¼ë¡œ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
            mock_training.assert_called_once_with(mock_settings)
            assert run_id == "test_run_id_12345"

def test_blueprint_v13_batch_inference_complete():
    """
    Blueprint v13.0 ë°°ì¹˜ ì¶”ë¡  ì™„ì „ì„± í…ŒìŠ¤íŠ¸
    run_id ê¸°ë°˜ ì™„ì „í•œ ì¬í˜„ì„± ê²€ì¦
    """
    run_id = "test_run_id_12345"
    context_params = {"start_date": "2024-01-01", "end_date": "2024-01-31"}
    
    # Mock Wrapped Artifact
    mock_wrapper = Mock()
    mock_wrapper.loader_sql_snapshot = "SELECT member_id, created_at FROM users"
    mock_wrapper.augmenter_sql_snapshot = "SELECT member_id, feature1 FROM features"
    mock_wrapper.recipe_snapshot = {"class_path": "src.models.xgboost_x_learner.XGBoostXLearner"}
    
    # Mock ì˜ˆì¸¡ ê²°ê³¼ (ì¤‘ê°„ ì‚°ì¶œë¬¼ í¬í•¨)
    mock_prediction_results = {
        "final_results": pd.DataFrame({"member_id": [1, 2], "uplift_score": [0.5, 0.7]}),
        "augmented_data": pd.DataFrame({"member_id": [1, 2], "feature1": [10, 20]}),
        "preprocessed_data": pd.DataFrame({"member_id": [1, 2], "processed_feature": [1.0, 2.0]})
    }
    mock_wrapper.predict.return_value = mock_prediction_results
    
    with patch('mlflow.pyfunc.load_model', return_value=mock_wrapper):
        with patch('src.pipelines.inference_pipeline._save_dataset') as mock_save:
            with patch('src.settings.loaders.load_settings') as mock_load_settings:  # ğŸ”„ ìˆ˜ì •: settings â†’ loaders
                mock_settings = Mock()
                mock_load_settings.return_value = mock_settings
                
                from src.pipelines.inference_pipeline import run_batch_inference
                
                # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
                run_batch_inference(run_id, context_params)
                
                # ì˜¬ë°”ë¥¸ run_idë¡œ ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                import mlflow.pyfunc
                mlflow.pyfunc.load_model.assert_called_once_with(f"runs:/{run_id}/model")
                
                # ì˜ˆì¸¡ì´ ì˜¬ë°”ë¥¸ íŒŒë¼ë¯¸í„°ë¡œ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
                mock_wrapper.predict.assert_called_once()
                call_args = mock_wrapper.predict.call_args
                assert call_args[1]["params"]["run_mode"] == "batch"
                assert call_args[1]["params"]["return_intermediate"]
                
                # ì¤‘ê°„ ì‚°ì¶œë¬¼ë“¤ì´ ëª¨ë‘ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                assert mock_save.call_count == 3  # augmented, preprocessed, final

def test_blueprint_v13_api_serving_dynamic_schema():
    """
    Blueprint v13.0 API ì„œë¹™ ë™ì  ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸
    run_id ê¸°ë°˜ ì •í™•í•œ ì„œë¹™ ë° ìë™ ìŠ¤í‚¤ë§ˆ ìƒì„± ê²€ì¦
    """
    run_id = "test_run_id_12345"
    
    # Mock Wrapped Artifact
    mock_wrapper = Mock()
    mock_wrapper.loader_sql_snapshot = "SELECT member_id, product_id, created_at FROM users"
    mock_wrapper.augmenter_sql_snapshot = "SELECT member_id, user_score, engagement FROM features"
    mock_wrapper.predict.return_value = pd.DataFrame({"uplift_score": [0.85]})
    
    with patch('mlflow.pyfunc.load_model', return_value=mock_wrapper):
        with patch('src.settings.loaders.load_settings') as mock_load_settings:  # ğŸ”„ ìˆ˜ì •: settings â†’ loaders
            mock_settings = Mock()
            mock_settings.serving.realtime_feature_store = {"store_type": "redis"}
            mock_load_settings.return_value = mock_settings
            
            with patch('serving.schemas.get_pk_from_loader_sql') as mock_get_pk:
                mock_get_pk.return_value = ["member_id", "product_id", "created_at"]
                
                with patch('src.utils.system.sql_utils.parse_feature_columns') as mock_parse_features:
                    mock_parse_features.return_value = (["user_score", "engagement"], "member_id")
                    
                    from serving.api import create_app
                    
                    # API ì•± ìƒì„±
                    create_app(run_id)
                    
                    # ì˜¬ë°”ë¥¸ run_idë¡œ ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    import mlflow.pyfunc
                    mlflow.pyfunc.load_model.assert_called_once_with(f"runs:/{run_id}/model")
                    
                    # ë™ì  ìŠ¤í‚¤ë§ˆ ìƒì„± í•¨ìˆ˜ë“¤ì´ í˜¸ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
                    mock_get_pk.assert_called_once_with(mock_wrapper.loader_sql_snapshot)
                    mock_parse_features.assert_called_once_with(mock_wrapper.augmenter_sql_snapshot)

def test_blueprint_v13_seven_principles_compliance():
    """
    Blueprint v13.0 7ëŒ€ í•µì‹¬ ì„¤ê³„ ì›ì¹™ ì¤€ìˆ˜ ê²€ì¦ í…ŒìŠ¤íŠ¸
    """
    # ì›ì¹™ 1: ë ˆì‹œí”¼ëŠ” ë…¼ë¦¬, ì„¤ì •ì€ ì¸í”„ë¼
    with patch('src.settings.loaders.load_settings_by_file') as mock_load:  # ğŸ”„ ìˆ˜ì •: settings â†’ loaders
        mock_settings = Mock()
        mock_settings.model.class_path = "external.model.ExternalModel"  # ì™¸ë¶€ ëª¨ë¸ë„ ì§€ì›
        mock_settings.environment.app_env = "prod"  # í™˜ê²½ ë¶„ë¦¬
        mock_load.return_value = mock_settings
        
        from src.settings import load_settings_by_file
        settings = load_settings_by_file("test_recipe")
        
        # ë ˆì‹œí”¼(ë…¼ë¦¬)ì™€ í™˜ê²½(ì¸í”„ë¼)ì´ ë¶„ë¦¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        assert "external.model" in settings.model.class_path  # ë…¼ë¦¬
        assert settings.environment.app_env == "prod"  # ì¸í”„ë¼
    
    # ì›ì¹™ 2: í†µí•© ë°ì´í„° ì–´ëŒ‘í„°
    from src.core.factory import Factory
    factory = Factory(Mock())
    
    # ë‹¤ì–‘í•œ ìŠ¤í‚´ì— ëŒ€í•´ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ ì œê³µ í™•ì¸
    schemes = ["bq", "gs", "s3", "file"]
    for scheme in schemes:
        adapter = factory.create_data_adapter(scheme)
        assert hasattr(adapter, "read")  # í†µì¼ëœ read ì¸í„°í˜ì´ìŠ¤
        assert hasattr(adapter, "write")  # í†µì¼ëœ write ì¸í„°í˜ì´ìŠ¤
    
    # ì›ì¹™ 3: URI ê¸°ë°˜ ë™ì‘ ë° ë™ì  íŒ©í† ë¦¬ (ì´ë¯¸ ìœ„ì—ì„œ ê²€ì¦)
    
    # ì›ì¹™ 4: ì‹¤í–‰ ì‹œì ì— ì¡°ë¦½ë˜ëŠ” ìˆœìˆ˜ ë¡œì§ ì•„í‹°íŒ©íŠ¸
    from src.core.factory import PyfuncWrapper
    wrapper = PyfuncWrapper(
        trained_model=Mock(),
        trained_preprocessor=Mock(),
        trained_augmenter=Mock(),
        loader_sql_snapshot="SELECT test",
        augmenter_sql_snapshot="SELECT features",
        recipe_yaml_snapshot="model: test",
        training_metadata={"timestamp": "2024-01-01"}
    )
    
    # ìˆœìˆ˜ ë¡œì§ë§Œ í¬í•¨ë˜ê³  ì¸í”„ë¼ ì„¤ì •ì€ ì—†ëŠ”ì§€ í™•ì¸
    assert hasattr(wrapper, "loader_sql_snapshot")  # ë¡œì§ í¬í•¨
    assert hasattr(wrapper, "training_metadata")  # ë©”íƒ€ë°ì´í„° í¬í•¨
    assert "timestamp" in wrapper.training_metadata  # ìˆœìˆ˜ ì •ë³´ë§Œ
    
    # ì›ì¹™ 5: ë‹¨ì¼ Augmenter, ì»¨í…ìŠ¤íŠ¸ ì£¼ì… (ì´ë¯¸ augmenter í…ŒìŠ¤íŠ¸ì—ì„œ ê²€ì¦)
    
    # ì›ì¹™ 6: ìê¸° ê¸°ìˆ  API (ë™ì  ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸ì—ì„œ ê²€ì¦)
    
    # ì›ì¹™ 7: SQL ê¸°ë°˜ í†µí•© ì¸í„°í˜ì´ìŠ¤ (ì¼ê´€ì„± í…ŒìŠ¤íŠ¸ì—ì„œ ê²€ì¦) 