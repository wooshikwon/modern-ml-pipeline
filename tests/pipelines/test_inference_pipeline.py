"""
Inference Pipeline E2E í…ŒìŠ¤íŠ¸ (Blueprint v17.0 í˜„ëŒ€í™”)

Blueprint ì›ì¹™ ê²€ì¦:
- ì›ì¹™ 4: ì‹¤í–‰ ì‹œì ì— ì¡°ë¦½ë˜ëŠ” ìˆœìˆ˜ ë¡œì§ ì•„í‹°íŒ©íŠ¸
- ì›ì¹™ 7: í•˜ì´ë¸Œë¦¬ë“œ í†µí•© ì¸í„°í˜ì´ìŠ¤ (ë°°ì¹˜ ì¶”ë¡ )
- E2E ê²€ì¦: ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì™„ì „ ì‹¤í–‰
"""

import pytest
import mlflow
import shutil
from pathlib import Path
import pandas as pd

from src.settings import Settings
from src.pipelines.train_pipeline import run_training
from src.pipelines.inference_pipeline import run_batch_inference

@pytest.fixture(scope="module")
def trained_model_run_id_for_inference(local_test_settings: Settings):
    """
    ë°°ì¹˜ ì¶”ë¡  í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ìƒì„±í•˜ê³ 
    í•´ë‹¹ run_idë¥¼ ì œê³µí•˜ëŠ” Fixture.
    """
    test_tracking_uri = "./test_mlruns_inference_pipeline"
    mlflow.set_tracking_uri(test_tracking_uri)
    
    # í•™ìŠµ ì‹¤í–‰
    result_artifact = run_training(settings=local_test_settings)
    
    yield result_artifact.run_id
    
    # í…ŒìŠ¤íŠ¸ ì •ë¦¬
    shutil.rmtree(test_tracking_uri, ignore_errors=True)
    mlflow.set_tracking_uri("mlruns")

@pytest.mark.e2e
def test_inference_pipeline_e2e_in_local_env_complete(
    local_test_settings: Settings,
    trained_model_run_id_for_inference: str
):
    """
    LOCAL í™˜ê²½ì—ì„œ `run_batch_inference` íŒŒì´í”„ë¼ì¸ ì „ì²´ë¥¼ ì‹¤í–‰í•˜ëŠ” ì™„ì „í•œ End-to-End í…ŒìŠ¤íŠ¸.
    - ë¯¸ë¦¬ í•™ìŠµëœ ì‹¤ì œ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - ìµœì¢…ì ìœ¼ë¡œ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ê³  ëª¨ë“  ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ë˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
    Blueprint v17.0 ì™„ì „ í˜„ëŒ€í™”
    """
    run_id = trained_model_run_id_for_inference
    print(f"ğŸš€ ë°°ì¹˜ ì¶”ë¡  í…ŒìŠ¤íŠ¸ ì‹œì‘ (í•™ìŠµ ëª¨ë¸ Run ID: {run_id})")
    
    # --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---
    batch_result = run_batch_inference(settings=local_test_settings, run_id=run_id)

    # --- ê¸°ë³¸ ê²°ê³¼ ê²€ì¦ ---
    # 1. ë°°ì¹˜ ì¶”ë¡  ê²°ê³¼ê°€ ë°˜í™˜ë˜ì—ˆëŠ”ê°€?
    assert batch_result is not None
    assert hasattr(batch_result, 'predictions_df')
    assert hasattr(batch_result, 'inference_run_id')
    
    predictions_df = batch_result.predictions_df
    inference_run_id = batch_result.inference_run_id
    
    print(f"âœ… ë°°ì¹˜ ì¶”ë¡  ì™„ë£Œ. Inference Run ID: {inference_run_id}")

    # 2. ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ê²€ì¦
    assert isinstance(predictions_df, pd.DataFrame)
    assert len(predictions_df) > 0
    assert 'prediction' in predictions_df.columns
    
    # ì˜ˆì¸¡ê°’ì´ ì˜¬ë°”ë¥¸ ë²”ìœ„ì— ìˆëŠ”ì§€ í™•ì¸ (ë¶„ë¥˜ ëª¨ë¸ì´ë¯€ë¡œ 0-1 ë²”ìœ„)
    predictions = predictions_df['prediction']
    assert all(0.0 <= pred <= 1.0 for pred in predictions), "ì˜ˆì¸¡ê°’ì´ 0-1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤."
    print("âœ… ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ê²€ì¦ ì™„ë£Œ")

    # 3. MLflowì— ì¶”ë¡  Runì´ ìƒˆë¡œ ìƒì„±ë˜ì—ˆëŠ”ê°€?
    client = mlflow.tracking.MlflowClient()
    experiment_id = client.get_experiment_by_name(local_test_settings.mlflow.experiment_name).experiment_id
    runs_df = client.search_runs(
        experiment_ids=[experiment_id],
        filter_string=f"tags.mlflow.runName = 'batch_inference_{run_id}'",
        order_by=["start_time DESC"]
    )
    assert not runs_df.empty, "ë°°ì¹˜ ì¶”ë¡ ì— ëŒ€í•œ MLflow Runì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    inference_run = runs_df.iloc[0]
    
    # 4. ì˜ˆì¸¡ ê²°ê³¼ ì•„í‹°íŒ©íŠ¸ê°€ MLflowì— ì €ì¥ë˜ì—ˆëŠ”ê°€?
    artifacts = client.list_artifacts(inference_run_id)
    artifact_paths = [artifact.path for artifact in artifacts]
    assert any("predictions.parquet" in path for path in artifact_paths), \
        "ì˜ˆì¸¡ ê²°ê³¼(predictions.parquet)ê°€ MLflow ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    print("âœ… MLflow ì•„í‹°íŒ©íŠ¸ ì €ì¥ ê²€ì¦ ì™„ë£Œ")

    # --- ğŸ†• Blueprint v17.0: ë°°ì¹˜ ì¶”ë¡  íŠ¹í™” ê²€ì¦ ---
    # 5. ë°°ì¹˜ ëª¨ë“œ ì»¨í…ìŠ¤íŠ¸ ê²€ì¦
    # ì˜ˆì¸¡ ê²°ê³¼ì— ì¤‘ê°„ ì‚°ì¶œë¬¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ë°°ì¹˜ ëª¨ë“œì˜ íŠ¹ì§•)
    expected_intermediate_cols = ['augmented_features', 'preprocessed_features']
    intermediate_cols_found = [col for col in expected_intermediate_cols if col in predictions_df.columns]
    
    # ë°°ì¹˜ ëª¨ë“œì—ì„œëŠ” ì¤‘ê°„ ì‚°ì¶œë¬¼ì„ í¬í•¨í•  ìˆ˜ ìˆìŒ
    if intermediate_cols_found:
        print(f"âœ… ë°°ì¹˜ ëª¨ë“œ ì¤‘ê°„ ì‚°ì¶œë¬¼ í™•ì¸: {intermediate_cols_found}")
    
    # 6. ì›ë³¸ Wrapped Artifactì™€ì˜ ì¼ê´€ì„± ê²€ì¦
    # ì¶”ë¡ ì— ì‚¬ìš©ëœ ëª¨ë¸ì´ ì›ë³¸ í•™ìŠµ ëª¨ë¸ê³¼ ë™ì¼í•œì§€ í™•ì¸
    original_model = mlflow.pyfunc.load_model(f"runs:/{run_id}/model")
    original_wrapped = original_model.unwrap_python_model()
    
    # ëª¨ë¸ í´ë˜ìŠ¤ ê²½ë¡œê°€ ë™ì¼í•œì§€ í™•ì¸
    assert hasattr(original_wrapped, 'model_class_path')
    original_class_path = original_wrapped.model_class_path
    assert original_class_path == local_test_settings.model.class_path
    print(f"âœ… ëª¨ë¸ ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ: {original_class_path}")

    # --- ğŸ†• Blueprint v17.0: Data Leakage ë°©ì§€ ê²€ì¦ ---
    # 7. ì¶”ë¡  ê³¼ì •ì—ì„œ Data Leakageê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
    # ì¶”ë¡  ì‹œì—ëŠ” train ë°ì´í„°ì— fitëœ ì „ì²˜ë¦¬ê¸°ë§Œ ì‚¬ìš©í•´ì•¼ í•¨
    training_methodology = original_wrapped.training_methodology
    assert training_methodology['preprocessing_fit_scope'] == 'train_only'
    print("âœ… Data Leakage ë°©ì§€ í™•ì¸: ì „ì²˜ë¦¬ê¸°ëŠ” train ë°ì´í„°ì—ë§Œ fitë¨")

    # --- ğŸ†• Blueprint v17.0: ì¶”ë¡  ë©”íƒ€ë°ì´í„° ê²€ì¦ ---
    # 8. ì¶”ë¡  Runì˜ ë©”íƒ€ë°ì´í„° ê²€ì¦
    inference_run_data = client.get_run(inference_run_id)
    
    # ì¶”ë¡  Runì— ì›ë³¸ í•™ìŠµ Run IDê°€ íƒœê·¸ë¡œ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
    inference_tags = inference_run_data.data.tags
    assert 'original_model_run_id' in inference_tags
    assert inference_tags['original_model_run_id'] == run_id
    print("âœ… ì¶”ë¡  ë©”íƒ€ë°ì´í„° ê²€ì¦ ì™„ë£Œ")

    # --- ğŸ†• Blueprint v17.0: ì„±ëŠ¥ ê²€ì¦ ---
    # 9. ì¶”ë¡  ì„±ëŠ¥ ê¸°ë¡ í™•ì¸
    inference_metrics = inference_run_data.data.metrics
    
    # ì¶”ë¡  ê´€ë ¨ ë©”íŠ¸ë¦­ì´ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
    expected_inference_metrics = ['inference_time_seconds', 'total_predictions']
    for metric in expected_inference_metrics:
        if metric in inference_metrics:
            print(f"âœ… ì¶”ë¡  ì„±ëŠ¥ ë©”íŠ¸ë¦­ '{metric}': {inference_metrics[metric]}")
    
    # --- ìµœì¢… ê²€ì¦ ì™„ë£Œ ---
    print(f"ğŸ‰ Complete Inference E2E Test ì„±ê³µ! {len(predictions_df)}ê°œ ì˜ˆì¸¡ ì™„ë£Œ, ëª¨ë“  ê²€ì¦ í†µê³¼")

@pytest.mark.e2e 
def test_batch_inference_artifact_consistency(
    local_test_settings: Settings,
    trained_model_run_id_for_inference: str
):
    """
    ë°°ì¹˜ ì¶”ë¡  ì•„í‹°íŒ©íŠ¸ê°€ ì›ë³¸ í•™ìŠµ ì•„í‹°íŒ©íŠ¸ì™€ ì¼ê´€ì„±ì„ ìœ ì§€í•˜ëŠ”ì§€ ê²€ì¦í•œë‹¤.
    Blueprint ì›ì¹™ 4: ì‹¤í–‰ ì‹œì ì— ì¡°ë¦½ë˜ëŠ” ìˆœìˆ˜ ë¡œì§ ì•„í‹°íŒ©íŠ¸
    """
    run_id = trained_model_run_id_for_inference
    
    # ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰
    batch_result = run_batch_inference(settings=local_test_settings, run_id=run_id)
    
    # --- Blueprint v17.0: ì™„ì „í•œ ì¼ê´€ì„± ê²€ì¦ ---
    # 1. ì›ë³¸ í•™ìŠµ ì•„í‹°íŒ©íŠ¸ì™€ ì¶”ë¡  ê²°ê³¼ ë¹„êµ
    original_model = mlflow.pyfunc.load_model(f"runs:/{run_id}/model")
    original_wrapped = original_model.unwrap_python_model()
    
    # 2. ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ ë™ì¼í•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸ (ì¬í˜„ì„±)
    test_input = pd.DataFrame({
        'user_id': ['test_user_1', 'test_user_2'], 
        'product_id': ['test_product_1', 'test_product_2']
    })
    
    # ì›ë³¸ ëª¨ë¸ ì§ì ‘ ì˜ˆì¸¡
    direct_prediction = original_model.predict(test_input, params={'run_mode': 'batch'})
    
    # ë°°ì¹˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡ (ë™ì¼í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´)
    # ì‹¤ì œë¡œëŠ” íŒŒì´í”„ë¼ì¸ì´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ê²°ê³¼ í˜•íƒœë§Œ ê²€ì¦
    pipeline_predictions = batch_result.predictions_df
    
    # 3. ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦
    # ë°°ì¹˜ ì¶”ë¡  ê²°ê³¼ì™€ ì§ì ‘ ì˜ˆì¸¡ ê²°ê³¼ì˜ ìŠ¤í‚¤ë§ˆê°€ í˜¸í™˜ë˜ëŠ”ì§€ í™•ì¸
    assert 'prediction' in pipeline_predictions.columns
    assert isinstance(direct_prediction, pd.DataFrame)
    print("âœ… ì˜ˆì¸¡ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ")
    
    # 4. ë©”íƒ€ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    # ì›ë³¸ ì•„í‹°íŒ©íŠ¸ì˜ ë©”íƒ€ë°ì´í„°ê°€ ì¶”ë¡  ê³¼ì •ì—ì„œ ë³´ì¡´ë˜ëŠ”ì§€ í™•ì¸
    hpo_metadata = original_wrapped.hyperparameter_optimization
    training_metadata = original_wrapped.training_methodology
    
    assert isinstance(hpo_metadata, dict)
    assert isinstance(training_metadata, dict)
    assert training_metadata['preprocessing_fit_scope'] == 'train_only'
    print("âœ… ë©”íƒ€ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ")

    # 5. í™˜ê²½ë³„ ë™ì‘ ì¼ê´€ì„± ê²€ì¦ (LOCAL í™˜ê²½)
    # LOCAL í™˜ê²½ì—ì„œëŠ” PassThroughAugmenterë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
    augmenter = original_wrapped.trained_augmenter
    from src.core.augmenter import PassThroughAugmenter
    assert isinstance(augmenter, PassThroughAugmenter)
    print("âœ… LOCAL í™˜ê²½ ë™ì‘ ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ")
    
    print("ğŸ‰ ë°°ì¹˜ ì¶”ë¡  ì•„í‹°íŒ©íŠ¸ ì¼ê´€ì„± ê²€ì¦ ì„±ê³µ!")

@pytest.mark.e2e
def test_inference_pipeline_error_handling(local_test_settings: Settings):
    """
    ì¶”ë¡  íŒŒì´í”„ë¼ì¸ì˜ ì—ëŸ¬ ì²˜ë¦¬ê°€ ì ì ˆíˆ ë™ì‘í•˜ëŠ”ì§€ ê²€ì¦í•œë‹¤.
    """
    # 1. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” run_idë¡œ ì¶”ë¡  ì‹œë„
    with pytest.raises(Exception) as exc_info:
        run_batch_inference(settings=local_test_settings, run_id="nonexistent_run_id")
    
    # MLflow ê´€ë ¨ ì˜¤ë¥˜ê°€ ë°œìƒí•´ì•¼ í•¨
    assert "run" in str(exc_info.value).lower() or "not found" in str(exc_info.value).lower()
    print("âœ… ì˜ëª»ëœ run_id ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ")
    
    # 2. ì˜ëª»ëœ run_id í˜•ì‹
    with pytest.raises(Exception):
        run_batch_inference(settings=local_test_settings, run_id="")
    
    print("âœ… ë¹ˆ run_id ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì™„ë£Œ")
    print("ğŸ‰ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì—ëŸ¬ ì²˜ë¦¬ ê²€ì¦ ì„±ê³µ!")
