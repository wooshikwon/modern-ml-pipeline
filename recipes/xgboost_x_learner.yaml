# recipes/xgboost_x_learner.yaml
# XGBoost X-Learner 모델을 위한 모든 정의가 포함된 "올인원" 레시피
# 🆕 Blueprint v17.0 호환: Dictionary 형식 hyperparameters + 자동 튜닝 지원

# 1. 모델 기본 정보
class_path: "causalml.inference.meta.XGBTRegressor"

# 2. 데이터 로더 정의
loader:
  name: "campaign_users"
  # 기본 소스: bq 스킴을 사용하여 BigQuery SQL 파일임을 명시
  source_uri: "bq://recipes/sql/loader/user_features.sql"
  # 로컬 재정의: file 스킴을 사용하여 로컬 파일임을 명시
  local_override_uri: "file://local/data/sample_user_features.csv"

# 3. 피처 증강기 정의 (🆕 Blueprint v17.0 - Feature Store 방식)
augmenter:
  # 🆕 선언적 Feature Store 방식 (Blueprint v17.0)
  type: "feature_store"  # 환경별 Feature Store 사용 명시
  features:
    # user_id(member_id) 엔티티에 결합할 피처 목록
    - feature_namespace: "user_demographics"
      features: ["gender", "age_group"]
    - feature_namespace: "user_behavior_summary"
      features: ["days_since_last_visit", "lifetime_purchase_count"]
    - feature_namespace: "user_purchase_summary_90d"
      features: ["avg_purchase_amount_90d"]
    - feature_namespace: "user_session_summary_30d" 
      features: ["avg_session_duration_30d"]

  # 💾 기존 방식 호환성 (하위 호환성 유지 - 주석 처리됨)
  # name: "point_in_time_features"
  # source_uri: "bq://recipes/sql/features/user_summary.sql"
  # local_override_uri: "file://local/data/sample_user_features.parquet"

# 4. 전처리기 정의
preprocessor:
  name: "simple_scaler"
  params:
    criterion_col: null
    exclude_cols: ["member_id", "event_timestamp"]

# 5. 모델 인터페이스
data_interface:
  # Task type 지정 (causal inference/uplift modeling)
  task_type: "causal"
  
  # 모델이 기대하는 최종 피처의 스키마 (이름: 타입)
  features:
    gender: "category"
    age_group: "category"
    days_since_last_visit: "numeric"
    lifetime_purchase_count: "numeric"
    avg_purchase_amount_90d: "numeric"
    avg_session_duration_30d: "numeric"
  
  target_col: "outcome"
  treatment_col: "grp"
  treatment_value: "treatment"

# 🆕 6. 하이퍼파라미터 (Blueprint v17.0 - Dictionary 형식 + 고정값 혼합)
hyperparameters:
  # 🔥 Dictionary 형식: Optuna 자동 탐색 범위 정의
  learning_rate: {type: "float", low: 0.01, high: 0.3, log: true}
  n_estimators: {type: "int", low: 50, high: 1000}
  max_depth: {type: "int", low: 3, high: 10}
  subsample: {type: "float", low: 0.5, high: 1.0}
  colsample_bytree: {type: "float", low: 0.5, high: 1.0}
  min_child_weight: {type: "int", low: 1, high: 10}
  gamma: {type: "float", low: 0.0, high: 1.0}
  
  # 🔧 고정값: 변경하지 않을 하이퍼파라미터
  random_state: 42
  objective: "reg:squarederror"
  eval_metric: "rmse"

# 🆕 7. 하이퍼파라미터 튜닝 설정 (Optional - 실험 논리)
hyperparameter_tuning:
  enabled: true          # 이 실험에서는 자동 최적화 활성화
  n_trials: 50           # "이 실험은 50번 시도할 가치가 있다"
  metric: "roc_auc"      # "이 지표로 최적화한다"
  direction: "maximize"  # "높을수록 좋다"
