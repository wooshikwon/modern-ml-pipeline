# src/utils/system/mlflow_utils.py

import mlflow
import json
from contextlib import contextmanager
import pandas as pd
from mlflow.models.signature import ModelSignature
from mlflow.types import Schema, ColSpec, ParamSpec, ParamSchema
from typing import Optional, List

# ìˆœí™˜ ì°¸ì¡°ë¥¼ í”¼í•˜ê¸° ìœ„í•´ íƒ€ì… íŒíŠ¸ë§Œ ì„í¬íŠ¸
from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from src.settings import Settings
    from mlflow.entities import Run
    from mlflow.pyfunc import PyFuncModel

from src.utils.system.logger import logger

def setup_mlflow(settings: "Settings") -> None:
    """
    ì£¼ì…ëœ settings ê°ì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ MLflow í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    mlflow.set_tracking_uri(settings.mlflow.tracking_uri)
    mlflow.set_experiment(settings.mlflow.experiment_name)
    
    logger.info(f"MLflow ì„¤ì • ì™„ë£Œ:")
    logger.info(f"  - Tracking URI: {settings.mlflow.tracking_uri}")
    logger.info(f"  - Experiment: {settings.mlflow.experiment_name}")
    logger.info(f"  - Environment: {settings.environment.app_env}")

@contextmanager
def start_run(settings: "Settings", run_name: str) -> "Run":
    """
    MLflow ì‹¤í–‰ì„ ì‹œì‘í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €.
    ì™¸ë¶€ í™˜ê²½ ë³€ìˆ˜ì˜ ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ tracking_urië¥¼ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    # ì™¸ë¶€ì—ì„œ ì§€ì •ëœ tracking_uri(ì˜ˆ: í…ŒìŠ¤íŠ¸)ê°€ ìˆë‹¤ë©´ ì¡´ì¤‘í•˜ê³ , ì‹¤í—˜ëª…ë§Œ ì„¤ì •
    mlflow.set_experiment(settings.mlflow.experiment_name)
    with mlflow.start_run(run_name=run_name) as run:
        logger.info(f"MLflow Run started: {run.info.run_id} ({run_name}) for experiment '{settings.mlflow.experiment_name}'")
        try:
            yield run
            mlflow.set_tag("status", "success")
            logger.info("MLflow Run finished successfully.")
        except Exception as e:
            mlflow.set_tag("status", "failed")
            logger.error(f"MLflow Run failed: {e}", exc_info=True)
            raise

def get_latest_run_id(settings: "Settings", experiment_name: str) -> str:
    """
    ì§€ì •ëœ experimentì—ì„œ ê°€ì¥ ìµœê·¼ì— ì„±ê³µí•œ runì˜ IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    setup_mlflow(settings)
    try:
        experiment = mlflow.get_experiment_by_name(experiment_name)
        if not experiment:
            raise ValueError(f"Experiment '{experiment_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        runs_df = mlflow.search_runs(
            experiment_ids=[experiment.experiment_id],
            filter_string="tags.status = 'success'",
            order_by=["start_time DESC"],
            max_results=1
        )
        
        if runs_df.empty:
            raise ValueError(f"Experiment '{experiment_name}'ì—ì„œ ì„±ê³µí•œ runì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        latest_run_id = runs_df.iloc[0]['run_id']
        logger.info(f"ê°€ì¥ ìµœê·¼ì— ì„±ê³µí•œ Run ID ì¡°íšŒ: {latest_run_id} (Experiment: {experiment_name})")
        return latest_run_id
        
    except Exception as e:
        logger.error(f"ìµœê·¼ Run ID ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise

def get_model_uri(run_id: str, artifact_path: str = "model") -> str:
    """
    Run IDì™€ ì•„í‹°íŒ©íŠ¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ URIë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    uri = f"runs:/{run_id}/{artifact_path}"
    logger.debug(f"ìƒì„±ëœ ëª¨ë¸ URI: {uri}")
    return uri

def load_pyfunc_model(settings: "Settings", model_uri: str) -> "PyFuncModel":
    """
    ì§€ì •ëœ URIì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ Pyfunc ëª¨ë¸ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ì™¸ë¶€ í™˜ê²½ ë³€ìˆ˜ì˜ ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ MlflowClientë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    logger.info(f"MLflow ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_uri}")
    try:
        if model_uri.startswith("runs:/"):
            # MlflowClientë¥¼ ëª…ì‹œì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ
            from mlflow.tracking import MlflowClient
            import re

            def _parse_runs_uri(uri: str) -> tuple[str, str]:
                """'runs:/<run_id>/<artifact_path>' URIë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
                match = re.match(r"runs:/([^/]+)/(.+)", uri)
                if not match:
                    raise ValueError(f"'{uri}'ëŠ” ì˜¬ë°”ë¥¸ 'runs:/' URIê°€ ì•„ë‹™ë‹ˆë‹¤.")
                return match.group(1), match.group(2)

            client = MlflowClient(tracking_uri=settings.mlflow.tracking_uri)
            run_id, artifact_path = _parse_runs_uri(model_uri)
            
            local_path = client.download_artifacts(run_id=run_id, path=artifact_path)
            logger.info(f"ì•„í‹°íŒ©íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {local_path}")
            return mlflow.pyfunc.load_model(model_uri=local_path)
        else:
            # ì¼ë°˜ ê²½ë¡œ(local file, GCS, S3 ë“±)ëŠ” ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            mlflow.set_tracking_uri(settings.mlflow.tracking_uri)
            return mlflow.pyfunc.load_model(model_uri=model_uri)
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {model_uri}, ì˜¤ë¥˜: {e}", exc_info=True)
        raise

def download_artifacts(settings: "Settings", run_id: str, artifact_path: str, dst_path: str = None) -> str:
    """
    ì§€ì •ëœ Run IDì—ì„œ íŠ¹ì • ì•„í‹°íŒ©íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , ë¡œì»¬ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    mlflow.set_tracking_uri(settings.mlflow.tracking_uri)
    logger.info(f"ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘: '{artifact_path}' (Run ID: '{run_id}')")
    try:
        local_path = mlflow.artifacts.download_artifacts(
            run_id=run_id,
            artifact_path=artifact_path,
            dst_path=dst_path
        )
        logger.info(f"ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
        return local_path
    except Exception as e:
        logger.error(f"ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)
        raise

def create_model_signature(input_df: pd.DataFrame, output_df: pd.DataFrame, params: dict = None) -> ModelSignature:
    """
    ì…ë ¥ ë° ì¶œë ¥ ë°ì´í„°í”„ë ˆì„ì„ ê¸°ë°˜ìœ¼ë¡œ MLflow ModelSignatureë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        input_df (pd.DataFrame): ëª¨ë¸ ì…ë ¥ ë°ì´í„°í”„ë ˆì„ (í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í˜•íƒœ)
        output_df (pd.DataFrame): ëª¨ë¸ ì¶œë ¥ ë°ì´í„°í”„ë ˆì„ (ì˜ˆì¸¡ ê²°ê³¼ í˜•íƒœ)
    
    Returns:
        ModelSignature: run_mode, return_intermediate íŒŒë¼ë¯¸í„°ë¥¼ í¬í•¨í•œ ì™„ì „í•œ signature
    """
    try:
        # ì…ë ¥ ìŠ¤í‚¤ë§ˆ ìƒì„±
        input_schema = Schema([
            ColSpec(
                type=_infer_pandas_dtype_to_mlflow_type(input_df[col].dtype),
                name=col
            )
            for col in input_df.columns
        ])
        
        # ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ìƒì„±
        output_schema = Schema([
            ColSpec(
                type=_infer_pandas_dtype_to_mlflow_type(output_df[col].dtype),
                name=col
            )
            for col in output_df.columns
        ])
        
        # íŒŒë¼ë¯¸í„° ìŠ¤í‚¤ë§ˆ ìƒì„± (run_mode, return_intermediate ì§€ì›)
        params_schema = ParamSchema([
            ParamSpec(
                name="run_mode",
                dtype="string",
                default="batch",
                shape=None
            ),
            ParamSpec(
                name="return_intermediate",
                dtype="boolean", 
                default=False,
                shape=None
            )
        ])
        
        # ModelSignature ìƒì„±
        signature = ModelSignature(
            inputs=input_schema,
            outputs=output_schema,
            params=params_schema
        )
        
        logger.info(f"ModelSignature ìƒì„± ì™„ë£Œ:")
        logger.info(f"  - ì…ë ¥ ì»¬ëŸ¼: {len(input_schema.inputs)}ê°œ")
        logger.info(f"  - ì¶œë ¥ ì»¬ëŸ¼: {len(output_schema.inputs)}ê°œ")
        logger.info(f"  - íŒŒë¼ë¯¸í„°: run_mode, return_intermediate")
        
        return signature
        
    except Exception as e:
        logger.error(f"ModelSignature ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise

def _infer_pandas_dtype_to_mlflow_type(pandas_dtype) -> str:
    """
    pandas dtypeì„ MLflow typeìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        pandas_dtype: pandas ì»¬ëŸ¼ì˜ dtype
    
    Returns:
        str: MLflow í˜¸í™˜ íƒ€ì… ë¬¸ìì—´
    """
    dtype_str = str(pandas_dtype)
    
    # ì •ìˆ˜í˜•
    if pandas_dtype.name in ['int8', 'int16', 'int32', 'int64', 'uint8', 'uint16', 'uint32', 'uint64']:
        return "long"
    
    # ì‹¤ìˆ˜í˜•
    elif pandas_dtype.name in ['float16', 'float32', 'float64']:
        return "double"
    
    # ë¶ˆë¦°í˜•
    elif pandas_dtype.name == 'bool':
        return "boolean"
    
    # ë¬¸ìì—´í˜•
    elif pandas_dtype.name == 'object' or 'string' in dtype_str:
        return "string"
    
    # ë‚ ì§œ/ì‹œê°„í˜•
    elif pandas_dtype.name.startswith('datetime'):
        return "datetime"
    
    # ê¸°ë³¸ê°’ (ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…)
    else:
        logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” pandas dtype: {pandas_dtype}, 'string'ìœ¼ë¡œ ì²˜ë¦¬")
        return "string" 


# ğŸ†• Phase 5: ì™„ì „ ìê¸° ê¸°ìˆ  Artifact - Enhanced MLflow í†µí•© í•¨ìˆ˜ë“¤

def create_enhanced_model_signature_with_schema(
    training_df: pd.DataFrame, 
    data_interface_config: dict
) -> tuple[ModelSignature, dict]:
    """
    ğŸ†• Phase 5: ê¸°ì¡´ create_model_signature + ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„° ìƒì„±
    
    ê¸°ì¡´ MLflow í†µí•© ê¸°ëŠ¥ì„ í™•ì¥í•˜ì—¬ ì°¨ì„¸ëŒ€ ìê¸° ê¸°ìˆ ì  Artifact êµ¬í˜„.
    Phase 1-4ì˜ ëª¨ë“  í˜ì‹  ê¸°ëŠ¥ì„ í†µí•©í•œ ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ìƒì„±.
    
    Args:
        training_df (pd.DataFrame): Training ë°ì´í„° (ìŠ¤í‚¤ë§ˆ ìƒì„±ìš©)
        data_interface_config (dict): EntitySchema ì„¤ì • ì •ë³´
        
    Returns:
        tuple[ModelSignature, dict]: Enhanced Signatureì™€ ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°
    """
    
    # 1. ì…ë ¥ ìŠ¤í‚¤ë§ˆëŠ” 'inference_columns'(entity + timestamp) ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
    logger.info("ğŸ”„ Inference ì…ë ¥ ìŠ¤í‚¤ë§ˆ(ì—”í‹°í‹°+íƒ€ì„ìŠ¤íƒ¬í”„) ê¸°ì¤€ìœ¼ë¡œ MLflow Signature ìƒì„±...")
    from src.utils.system.schema_utils import generate_training_schema_metadata
    provisional_schema = generate_training_schema_metadata(training_df, data_interface_config)
    inference_cols = list(provisional_schema.get('inference_columns') or [])
    input_example = training_df.head(5).copy()
    # íƒ€ì… ì¼ì¹˜: timestampë¥¼ datetimeìœ¼ë¡œ
    ts_col = provisional_schema.get('timestamp_column')
    if ts_col and ts_col in input_example.columns:
        try:
            input_example[ts_col] = pd.to_datetime(input_example[ts_col], errors='coerce')
        except Exception:
            pass
    input_example = input_example[inference_cols] if inference_cols else input_example
    sample_output = pd.DataFrame({'prediction': [0.0] * len(input_example)})
    signature = create_model_signature(input_example, sample_output)
    
    # 2. ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„° ìƒì„±
    data_schema = provisional_schema
    
    # 3. ğŸ†• Phase 5 íŠ¹í™”: MLflow ë° í†µí•© ì •ë³´ ì¶”ê°€
    data_schema.update({
        # MLflow í™˜ê²½ ì •ë³´
        'mlflow_version': mlflow.__version__,
        'signature_created_at': pd.Timestamp.now().isoformat(),
        
        # Phase í†µí•© ì •ë³´
        'phase_integration': {
            'phase_1_schema_first': True,  # Entity+Timestamp í•„ìˆ˜í™”
            'phase_2_point_in_time': True,  # ASOF JOIN ë³´ì¥
            'phase_3_secure_sql': True,  # SQL Injection ë°©ì§€
            'phase_4_auto_validation': True,  # ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦
            'phase_5_enhanced_artifact': True  # ì™„ì „í•œ ìê¸° ê¸°ìˆ ì  Artifact
        },
        
        # ì•ˆì „ì„± ë³´ì¥ ì •ë³´
        'point_in_time_safe': True,
        'sql_injection_safe': True, 
        'schema_validation_enabled': True,
        
        # Artifact ìê¸° ê¸°ìˆ  ì •ë³´
        'artifact_self_descriptive': True,
        'reproduction_guaranteed': True
    })
    
    logger.info(f"âœ… Enhanced Model Signature + ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ")
    logger.info(f"   - ìŠ¤í‚¤ë§ˆ ë²„ì „: {data_schema['schema_version']}")
    logger.info(f"   - Inference ì»¬ëŸ¼: {len(data_schema['inference_columns'])}ê°œ")
    logger.info(f"   - Phase 1-5 í†µí•©: ëª¨ë“  í˜ì‹  ê¸°ëŠ¥ í¬í•¨")
    
    return signature, data_schema


def log_enhanced_model_with_schema(
    python_model, 
    signature: ModelSignature,
    data_schema: dict,
    input_example: pd.DataFrame,
    pip_requirements: Optional[List[str]] = None
):
    """
    ğŸ†• Phase 5: ê¸°ì¡´ mlflow.pyfunc.log_model + í™•ì¥ëœ ë©”íƒ€ë°ì´í„° ì €ì¥
    
    ê¸°ì¡´ MLflow ì €ì¥ ê¸°ëŠ¥ì„ ë³´ì¡´í•˜ë©´ì„œ ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥.
    100% ì¬í˜„ì„±ê³¼ ìê¸° ê¸°ìˆ ì„±ì„ ë³´ì¥í•˜ëŠ” Enhanced Artifact êµ¬í˜„.
    
    Args:
        python_model: PyfuncWrapper ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        signature (ModelSignature): Enhanced Model Signature
        data_schema (dict): ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°
        input_example (pd.DataFrame): ì…ë ¥ ì˜ˆì œ ë°ì´í„°
    """
    
    # 1. ê¸°ì¡´ MLflow ì €ì¥ ë¡œì§ í™œìš© (ê²€ì¦ëœ ê¸°ëŠ¥ ë³´ì¡´)
    logger.info("ğŸ”„ ê¸°ì¡´ MLflow ëª¨ë¸ ì €ì¥ ë¡œì§ í™œìš© ì¤‘...")
    mlflow.pyfunc.log_model(
        artifact_path="model",
        python_model=python_model,
        signature=signature,
        pip_requirements=pip_requirements,
        input_example=input_example,
        metadata={"data_schema": json.dumps(data_schema)}
    )
    
    # 2. ğŸ†• ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„° ì €ì¥
    logger.info("ğŸ†• ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘...")
    mlflow.log_dict(data_schema, "model/data_schema.json")
    
    # 3. ğŸ†• í˜¸í™˜ì„± ë° ë²„ì „ ì •ë³´ ì €ì¥
    logger.info("ğŸ†• í˜¸í™˜ì„± ë° ë²„ì „ ì •ë³´ ì €ì¥ ì¤‘...")
    compatibility_info = {
        'artifact_version': '2.0',
        'creation_timestamp': pd.Timestamp.now().isoformat(),
        'mlflow_version': mlflow.__version__,
        'schema_validator_version': '2.0',
        
        # Phaseë³„ ê¸°ëŠ¥ í™œì„±í™” ìƒíƒœ
        'features_enabled': {
            'entity_timestamp_schema': True,  # Phase 1
            'point_in_time_correctness': True,  # Phase 2
            'sql_injection_protection': True,  # Phase 3
            'automatic_schema_validation': True,  # Phase 4
            'self_descriptive_artifact': True  # Phase 5
        },
        
        # í˜¸í™˜ì„± ì •ë³´
        'backward_compatibility': {
            'supports_legacy_models': False,  # Phase 5ëŠ” ì™„ì „í•œ ìƒˆ êµ¬ì¡°ë§Œ ì§€ì›
            'requires_enhanced_pipeline': True
        },
        
        # í’ˆì§ˆ ë³´ì¦ ì •ë³´
        'quality_assurance': {
            'schema_drift_protection': True,
            'data_leakage_prevention': True,
            'reproducibility_guaranteed': True
        }
    }
    mlflow.log_dict(compatibility_info, "model/compatibility_info.json")
    
    # 4. ğŸ†• Phase í†µí•© ìš”ì•½ ì •ë³´ ì €ì¥
    phase_summary = {
        'phase_1': {
            'name': 'Schema-First ì„¤ê³„',
            'achievements': ['Entity+Timestamp í•„ìˆ˜í™”', 'EntitySchema êµ¬í˜„', 'Recipe êµ¬ì¡° í˜„ëŒ€í™”']
        },
        'phase_2': {
            'name': 'Point-in-Time ì•ˆì „ì„±', 
            'achievements': ['ASOF JOIN ê²€ì¦', 'Augmenter í˜„ëŒ€í™”', 'ë¯¸ë˜ ë°ì´í„° ëˆ„ì¶œ ë°©ì§€']
        },
        'phase_3': {
            'name': 'ë³´ì•ˆ ê°•í™” Dynamic SQL',
            'achievements': ['SQL Injection ë°©ì§€', 'í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê²€ì¦', 'ë³´ì•ˆ í…œí”Œë¦¿ í‘œì¤€í™”']
        },
        'phase_4': {
            'name': 'ì¼ê´€ì„± ìë™ ê²€ì¦',
            'achievements': ['Schema Drift ì¡°ê¸° ë°œê²¬', 'íƒ€ì… í˜¸í™˜ì„± ì—”ì§„', 'ìë™ ê²€ì¦ í†µí•©']
        },
        'phase_5': {
            'name': 'ì™„ì „ ìê¸° ê¸°ìˆ  Artifact',
            'achievements': ['100% ì¬í˜„ì„± ë³´ì¥', 'ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ìº¡ìŠí™”', 'ìê¸° ê¸°ìˆ ì  êµ¬ì¡°']
        }
    }
    mlflow.log_dict(phase_summary, "model/phase_integration_summary.json")
    
    logger.info("âœ… Enhanced Model + ì™„ì „í•œ ë©”íƒ€ë°ì´í„° MLflow ì €ì¥ ì™„ë£Œ")
    logger.info("   - ê¸°ë³¸ ëª¨ë¸: model/ ê²½ë¡œì— ì €ì¥")
    logger.info("   - ìŠ¤í‚¤ë§ˆ ë©”íƒ€ë°ì´í„°: model/data_schema.json")
    logger.info("   - í˜¸í™˜ì„± ì •ë³´: model/compatibility_info.json") 
    logger.info("   - Phase í†µí•© ìš”ì•½: model/phase_integration_summary.json")
    logger.info("   ğŸ‰ ëª¨ë“  Phase í˜ì‹  ê¸°ëŠ¥ì´ í†µí•©ëœ ìê¸° ê¸°ìˆ ì  Artifact ì™„ì„±!") 