from __future__ import annotations
import importlib
from pathlib import Path
from typing import Optional, Dict, Any, TYPE_CHECKING

import mlflow
import pandas as pd

from src.components._augmenter import Augmenter, PassThroughAugmenter, BaseAugmenter
from src.components._preprocessor import Preprocessor, BasePreprocessor
from src.interface import BaseAdapter
from src.settings import Settings
from src.utils.system.logger import logger
from src.engine._registry import AdapterRegistry, EvaluatorRegistry
from src.components._augmenter._augmenter import AugmenterRegistry

if TYPE_CHECKING:
    from src.engine._artifact import PyfuncWrapper


class Factory:
    """
    í˜„ëŒ€í™”ëœ Recipe ì„¤ì •(settings.recipe)ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì•™ íŒ©í† ë¦¬ í´ë˜ìŠ¤.
    """
    def __init__(self, settings: Settings):
        self.settings = settings
        
        # í˜„ëŒ€í™”ëœ Recipe êµ¬ì¡° ê²€ì¦
        if not self.settings.recipe:
            raise ValueError("í˜„ëŒ€í™”ëœ Recipe êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤. settings.recipeê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"Factory initialized with Recipe: {self.settings.recipe.name}")

    @property 
    def model_config(self):
        """í˜„ì¬ ëª¨ë¸ ì„¤ì • ë°˜í™˜ (í˜„ëŒ€í™”ëœ Recipe.model)"""
        return self.settings.recipe.model

    def create_data_adapter(self) -> "BaseAdapter":
        """
        ë ˆì‹œí”¼ì— ëª…ì‹œëœ `adapter` íƒ€ì…ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ì–´ëŒ‘í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        ë” ì´ìƒ `default_loader`ë‚˜ íŒŒì¼ í™•ì¥ìì™€ ê°™ì€ ì•”ë¬µì ì¸ ê·œì¹™ì— ì˜ì¡´í•˜ì§€ ì•Šê³ ,
        ì˜¤ì§ ë ˆì‹œí”¼ì˜ ëª…ì‹œì ì¸ ì„ ì–¸ë§Œì„ ë”°ë¦…ë‹ˆë‹¤.
        """
        # 1. ë ˆì‹œí”¼ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì„ ì–¸ëœ ì–´ëŒ‘í„° íƒ€ì…ì„ ê°€ì ¸ì˜´
        adapter_type = self.settings.recipe.model.loader.adapter
        logger.debug(f"ë ˆì‹œí”¼ì— ëª…ì‹œëœ ì–´ëŒ‘í„° íƒ€ì… '{adapter_type}'ìœ¼ë¡œ DataAdapter ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤.")

        # 2. ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ íƒ€ì…ì˜ ì–´ëŒ‘í„° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±
        try:
            return AdapterRegistry.create(adapter_type, settings=self.settings)
        except KeyError:
            # 3. ìš”ì²­ëœ íƒ€ì…ì´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì—†ìœ¼ë©´ ëª…í™•í•œ ì˜¤ë¥˜ ë°œìƒ
            available = list(AdapterRegistry._adapters.keys())
            raise ValueError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” DataAdapter íƒ€ì…ì…ë‹ˆë‹¤: '{adapter_type}'. "
                f"ì‚¬ìš© ê°€ëŠ¥í•œ ì–´ëŒ‘í„°: {available}"
            )
    
    def create_augmenter(self) -> BaseAugmenter:
        """
        ì„¤ì •(Settings)ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì ˆí•œ Augmenter ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        í™˜ê²½ ì„¤ì •(`settings.feature_store.provider`)ì´ ë ˆì‹œí”¼ ì„¤ì •ë³´ë‹¤ ìš°ì„ í•©ë‹ˆë‹¤.
        ë§Œì•½ providerê°€ 'passthrough'ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤ë©´, ë ˆì‹œí”¼ì˜ augmenter ì„¤ì •ê³¼
        ìƒê´€ì—†ì´ PassThroughAugmenterë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        # 1. í™˜ê²½ì˜ ì¸í”„ë¼ ì œì•½(config)ì„ ìµœìš°ì„ ìœ¼ë¡œ í™•ì¸
        feature_store_provider = self.settings.feature_store.provider
        
        if feature_store_provider == "passthrough":
            logger.debug("í™˜ê²½ ì„¤ì •ì— ë”°ë¼ 'PassThroughAugmenter'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            return PassThroughAugmenter(settings=self.settings)

        # 2. 'passthrough'ê°€ ì•„ë‹ ê²½ìš°, ë ˆì‹œí”¼ì˜ ë…¼ë¦¬ì  ìš”êµ¬ì‚¬í•­ì„ í™•ì¸
        if not self.settings.recipe.model.augmenter:
            logger.debug("ë ˆì‹œí”¼ì— Augmenterê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ 'PassThroughAugmenter'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            return PassThroughAugmenter(settings=self.settings)
            
        augmenter_type = self.settings.recipe.model.augmenter.type
        
        # 3. ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ìš”ì²­ëœ íƒ€ì…ì˜ Augmenter í´ë˜ìŠ¤ë¥¼ ì°¾ì•„ ìƒì„±
        try:
            augmenter_class = AugmenterRegistry.get_augmenter(augmenter_type)
            logger.debug(f"ë ˆì‹œí”¼ ì„¤ì •ì— ë”°ë¼ '{augmenter_class.__name__}'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
            return augmenter_class(settings=self.settings)
        except KeyError:
            # 4. ìš”ì²­ëœ íƒ€ì…ì´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°œìƒ
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Augmenter íƒ€ì…ì…ë‹ˆë‹¤: {augmenter_type}")

    def create_preprocessor(self) -> BasePreprocessor:
        """ì „ì²˜ë¦¬ê¸° ìƒì„±"""
        if not self.model_config.preprocessor: 
            return None
        return Preprocessor(settings=self.settings)

    def create_model(self):
        """ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ ë™ì  ëª¨ë¸ ìƒì„±"""
        class_path = self.model_config.class_path
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            model_class = getattr(module, class_name)
            
            hyperparams = self.model_config.hyperparameters.get_fixed_params() if hasattr(self.model_config.hyperparameters, 'get_fixed_params') else self.model_config.hyperparameters.copy()

            for key, value in hyperparams.items():
                if isinstance(value, str) and "." in value and ("_fn" in key or "_class" in key):
                    try:
                        module_path, class_name = value.rsplit('.', 1)
                        obj_module = importlib.import_module(module_path)
                        hyperparams[key] = getattr(obj_module, class_name)
                        logger.info(f"Hyperparameter '{key}' converted to object: {value}")
                    except (ImportError, AttributeError):
                        logger.warning(f"Could not convert hyperparameter '{key}' to object: {value}. Keeping as string.")

            logger.info(f"Creating model instance from: {class_path}")
            return model_class(**hyperparams)
        except Exception as e:
            logger.error(f"Failed to load model: {class_path}", exc_info=True)
            raise ValueError(f"Could not load model class: {class_path}") from e

    def create_evaluator(self):
        """task_typeì— ë”°ë¼ ë™ì  evaluator ìƒì„±"""
        task_type = self.model_config.data_interface.task_type
        logger.info(f"Creating evaluator for task: {task_type}")
        # í•˜ë“œì½”ë”©ëœ ë§µ ëŒ€ì‹  Registryë¥¼ ì‚¬ìš©
        return EvaluatorRegistry.create(evaluator_type, self.settings)

    def create_feature_store_adapter(self):
        """í™˜ê²½ë³„ Feature Store ì–´ëŒ‘í„° ìƒì„±"""
        if not self.settings.feature_store:
            raise ValueError("Feature Store settings are not configured.")
        logger.info("Creating Feature Store adapter.")
        return AdapterRegistry.create('feature_store', self.settings)
    
    def create_optuna_integration(self):
        """Optuna Integration ìƒì„±"""
        tuning_config = self.model_config.hyperparameter_tuning
        if not tuning_config:
            raise ValueError("Hyperparameter tuning settings are not configured.")
        
        from src.utils.integrations.optuna_integration import OptunaIntegration
        logger.info("Creating Optuna integration.")
        return OptunaIntegration(tuning_config)

    def create_pyfunc_wrapper(
        self, 
        trained_model: Any, 
        trained_preprocessor: Optional[BasePreprocessor],
        trained_augmenter: Optional[BaseAugmenter],
        training_df: Optional[pd.DataFrame] = None,
        training_results: Optional[Dict[str, Any]] = None
    ) -> PyfuncWrapper:
        """ğŸ”„ Phase 5: ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ì •ë³´ê°€ ìº¡ìŠí™”ëœ Enhanced Artifact ìƒì„±"""
        from src.engine._artifact import PyfuncWrapper
        logger.info("Creating PyfuncWrapper artifact...")
        
        signature, data_schema = None, None
        if training_df is not None:
            logger.info("Generating model signature and data schema from training_df...")
            from src.utils.integrations.mlflow_integration import create_enhanced_model_signature_with_schema
            
            entity_schema = self.model_config.loader.entity_schema
            data_interface = self.model_config.data_interface
            
            data_interface_config = {
                'entity_columns': entity_schema.entity_columns,
                'timestamp_column': entity_schema.timestamp_column,
                'task_type': data_interface.task_type,
                'target_column': data_interface.target_column,
                'treatment_column': getattr(data_interface, 'treatment_column', None),
            }
            
            signature, data_schema = create_enhanced_model_signature_with_schema(
                training_df, 
                data_interface_config
            )
            logger.info("âœ… Signature and data schema created successfully.")
        
        return PyfuncWrapper(
            settings=self.settings,
            trained_model=trained_model,
            trained_preprocessor=trained_preprocessor,
            trained_augmenter=trained_augmenter,
            training_results=training_results,
            signature=signature,
            data_schema=data_schema,
        )
