from __future__ import annotations
import importlib
from pathlib import Path
from typing import Optional, Dict, Any, TYPE_CHECKING

import mlflow
import pandas as pd

from src.components._augmenter import Augmenter, PassThroughAugmenter, BaseAugmenter
from src.components._preprocessor import Preprocessor, BasePreprocessor
from src.interface import BaseAdapter
from src.settings import Settings
from src.utils.system.logger import logger
from src.engine._registry import AdapterRegistry, EvaluatorRegistry

if TYPE_CHECKING:
    from src.engine._artifact import PyfuncWrapper


class Factory:
    """
    í˜„ëŒ€í™”ëœ Recipe ì„¤ì •(settings.recipe)ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì•™ íŒ©í† ë¦¬ í´ë˜ìŠ¤.
    """
    def __init__(self, settings: Settings):
        self.settings = settings
        
        # í˜„ëŒ€í™”ëœ Recipe êµ¬ì¡° ê²€ì¦
        if not self.settings.recipe:
            raise ValueError("í˜„ëŒ€í™”ëœ Recipe êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤. settings.recipeê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        logger.info(f"Factory initialized with Recipe: {self.settings.recipe.name}")

    @property 
    def model_config(self):
        """í˜„ì¬ ëª¨ë¸ ì„¤ì • ë°˜í™˜ (í˜„ëŒ€í™”ëœ Recipe.model)"""
        return self.settings.recipe.model

    def create_data_adapter(self, adapter_type: str) -> BaseAdapter:
        """ë°ì´í„° ì–´ëŒ‘í„° ìƒì„±"""
        logger.debug(f"Requesting to create data adapter of type: {adapter_type}")
        return AdapterRegistry.create(adapter_type, self.settings)

    def create_augmenter(self) -> "BaseAugmenter":
        """Augmenter ìƒì„± (í™˜ê²½ë³„ ì°¨ë“± ê¸°ëŠ¥)"""
        # Blueprint ì›ì¹™ 9: í™˜ê²½ë³„ ì°¨ë“±ì  ê¸°ëŠ¥ ë¶„ë¦¬
        if self.settings.environment.app_env == "local":
            logger.info("LOCAL env: Creating PassThroughAugmenter.")
            return PassThroughAugmenter(settings=self.settings)
        else:
            logger.info("DEV/PROD env: Creating standard Augmenter.")
            return Augmenter(settings=self.settings, factory=self)

    def create_preprocessor(self) -> "BasePreprocessor":
        """ì „ì²˜ë¦¬ê¸° ìƒì„±"""
        if not self.model_config.preprocessor: 
            return None
        return Preprocessor(settings=self.settings)

    def create_model(self):
        """ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ ë™ì  ëª¨ë¸ ìƒì„±"""
        class_path = self.model_config.class_path
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            model_class = getattr(module, class_name)
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì²˜ë¦¬ (í˜„ëŒ€í™”ëœ êµ¬ì¡°)
            hyperparams = self.model_config.hyperparameters.get_fixed_params() if hasattr(self.model_config.hyperparameters, 'get_fixed_params') else self.model_config.hyperparameters
            
            logger.info(f"Creating model instance from: {class_path}")
            return model_class(**hyperparams)
        except Exception as e:
            logger.error(f"Failed to load model: {class_path}", exc_info=True)
            raise ValueError(f"Could not load model class: {class_path}") from e

    def create_evaluator(self):
        """task_typeì— ë”°ë¼ ë™ì  evaluator ìƒì„±"""
        task_type = self.model_config.data_interface.task_type
        logger.info(f"Creating evaluator for task: {task_type}")
        # í•˜ë“œì½”ë”©ëœ ë§µ ëŒ€ì‹  Registryë¥¼ ì‚¬ìš©
        return EvaluatorRegistry.create(task_type, self.model_config.data_interface)

    def create_feature_store_adapter(self):
        """í™˜ê²½ë³„ Feature Store ì–´ëŒ‘í„° ìƒì„±"""
        if not self.settings.feature_store:
            raise ValueError("Feature Store settings are not configured.")
        logger.info("Creating Feature Store adapter.")
        return AdapterRegistry.create('feature_store', self.settings)
    
    def create_optuna_integration(self):
        """Optuna Integration ìƒì„±"""
        tuning_config = self.model_config.hyperparameter_tuning
        if not tuning_config:
            raise ValueError("Hyperparameter tuning settings are not configured.")
        
        from src.utils.integrations.optuna_integration import OptunaIntegration
        logger.info("Creating Optuna integration.")
        return OptunaIntegration(tuning_config)

    def create_pyfunc_wrapper(
        self, 
        trained_model: Any, 
        trained_preprocessor: Optional[BasePreprocessor],
        trained_augmenter: Optional[BaseAugmenter],
        training_df: Optional[pd.DataFrame] = None,
        training_results: Optional[Dict[str, Any]] = None
    ) -> PyfuncWrapper:
        """ğŸ”„ Phase 5: ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ì •ë³´ê°€ ìº¡ìŠí™”ëœ Enhanced Artifact ìƒì„±"""
        from src.engine._artifact import PyfuncWrapper
        logger.info("Creating PyfuncWrapper artifact...")
        
        signature, data_schema = None, None
        if training_df is not None:
            # Schema generation logic can be added here
            pass
        
        return PyfuncWrapper(
            settings=self.settings,
            trained_model=trained_model,
            trained_preprocessor=trained_preprocessor,
            trained_augmenter=trained_augmenter,
            training_results=training_results,
            signature=signature,
            data_schema=data_schema,
        )
