from __future__ import annotations
import pandas as pd
from typing import Dict, Any, Optional, TYPE_CHECKING

import mlflow
from src.utils.system.logger import logger

if TYPE_CHECKING:
    from src.interface import BasePreprocessor, BaseAugmenter
    from src.settings import Settings

class PyfuncWrapper(mlflow.pyfunc.PythonModel):
    """
    í•™ìŠµëœ ì»´í¬ë„ŒíŠ¸ì™€ ëª¨ë“  ì„¤ì • ì •ë³´ë¥¼ ìº¡ìŠí™”í•˜ëŠ” MLflow PythonModel êµ¬í˜„ì²´.
    """
    def __init__(
        self,
        settings: Settings,
        trained_model: Any,
        trained_preprocessor: Optional[BasePreprocessor],
        trained_augmenter: Optional[BaseAugmenter],
        training_results: Optional[Dict[str, Any]] = None,
        signature: Optional[Any] = None, # mlflow.models.ModelSignature
        data_schema: Optional[Any] = None, # mlflow.types.Schema
    ):
        self.settings = settings
        self.trained_model = trained_model
        self.trained_preprocessor = trained_preprocessor
        self.trained_augmenter = trained_augmenter
        self.training_results = training_results or {}
        self.signature = signature
        self.data_schema = data_schema

    @property
    def model_class_path(self) -> str:
        return self.settings.recipe.model.class_path

    @property
    def loader_sql_snapshot(self) -> str:
        return self.settings.recipe.model.loader.source_uri

    @property
    def augmenter_config_snapshot(self) -> Dict[str, Any]:
        if self.settings.recipe.model.augmenter:
            return self.settings.recipe.model.augmenter.model_dump()
        return {}

    @property
    def recipe_yaml_snapshot(self) -> str:
        # ToDo: Implement a robust way to get original yaml text
        # For now, we can dump the pydantic model back to yaml string
        import yaml
        return yaml.dump(self.settings.recipe.model_dump())

    @property
    def hyperparameter_optimization(self) -> Dict[str, Any]:
        return self.training_results.get('hyperparameter_optimization', {})

    @property
    def training_methodology(self) -> Dict[str, Any]:
        return self.training_results.get('training_methodology', {})

    def predict(self, context, model_input, params=None):
        run_mode = params.get("run_mode", "batch") if params else "batch"

        if not isinstance(model_input, pd.DataFrame):
            model_input = pd.DataFrame(model_input)

        # 0. ğŸ†• Phase 4: ìë™ ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦
        if run_mode == "batch" and self.data_schema:
            try:
                self.data_schema.validate_inference_consistency(model_input)
                logger.info("âœ… PyfuncWrapper ìë™ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ")
            except ValueError as e:
                # Schema Drift ê°ì§€ â†’ ìƒì„¸í•œ ì§„ë‹¨ ë©”ì‹œì§€
                raise ValueError(f"ğŸš¨ PyfuncWrapper Schema Drift ê°ì§€: {e}")
        elif run_mode != "batch":
            # API ì„œë¹™ ëª¨ë“œì—ì„œë„ ê²€ì¦ (ì„±ëŠ¥ìƒ ê°„ë‹¨í•œ ê²€ì¦ë§Œ)
            if self.data_schema and 'inference_columns' in self.data_schema:
                missing_cols = set(self.data_schema['inference_columns']) - set(model_input.columns)
                if missing_cols:
                    raise ValueError(f"ğŸš¨ API ìš”ì²­ ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ {missing_cols}")

        # 1. í”¼ì²˜ ì¦ê°• (Augmenter)
        augmented_df = self.trained_augmenter.augment(model_input, run_mode=run_mode)

        # 2. ë°ì´í„° ì „ì²˜ë¦¬ (Preprocessor)
        preprocessed_df = self.trained_preprocessor.transform(augmented_df) if self.trained_preprocessor else augmented_df

        # 3. ì˜ˆì¸¡ (Model)
        # ì „ì²˜ë¦¬ê¸°ê°€ ëª¨ë¸ì´ ì‚¬ìš©í•  í”¼ì²˜ë§Œ ë°˜í™˜í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
        predictions = self.trained_model.predict(preprocessed_df)

        # 4. ê²°ê³¼ í¬ë§·íŒ…
        # ì…ë ¥ ë°ì´í„°ì— ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        result_df = pd.DataFrame(predictions, columns=['prediction'], index=model_input.index)
        return result_df
