# src/components/datahandler/modules/tabular_handler.py
import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple
from sklearn.model_selection import train_test_split

from src.interface import BaseDataHandler
from ..registry import DataHandlerRegistry
from src.utils.system.logger import logger
from src.utils.system.console_manager import UnifiedConsole


class TabularDataHandler(BaseDataHandler):
    """ì „í†µì ì¸ í…Œì´ë¸” í˜•íƒœ MLì„ ìœ„í•œ ë°ì´í„° í•¸ë“¤ëŸ¬ (classification, regression, clustering, causal)"""
    
    def __init__(self, settings, data_interface):
        super().__init__(settings, data_interface)
        self.console = UnifiedConsole(settings)
    
    def split_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Train/Test ë¶„í•  (ì¡°ê±´ë¶€ stratify) - ê¸°ì¡´ split_data() ë¡œì§"""
        test_size = 0.2
        stratify_series = None
        
        if self.data_interface.task_type == "classification":
            target_col = self.data_interface.target_column
            if target_col in df.columns:
                counts = df[target_col].value_counts()
                # ê° í´ë˜ìŠ¤ ìµœì†Œ 2ê°œ, í…ŒìŠ¤íŠ¸ ì…‹ì— ìµœì†Œ 1ê°œ ì´ìƒ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
                if len(counts) >= 2 and counts.min() >= 2 and int(len(df) * test_size) >= 1:
                    stratify_series = df[target_col]
        elif self.data_interface.task_type == "causal":
            treatment_col = self.data_interface.treatment_column
            if treatment_col in df.columns:
                counts = df[treatment_col].value_counts()
                if len(counts) >= 2 and counts.min() >= 2 and int(len(df) * test_size) >= 1:
                    stratify_series = df[treatment_col]

        train_df, test_df = train_test_split(
            df, test_size=test_size, random_state=42, stratify=stratify_series
        )
        return train_df, test_df
    
    def prepare_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, Dict[str, Any]]:
        """í…Œì´ë¸” í˜•íƒœ ë°ì´í„° ì¤€ë¹„ (ê¸°ì¡´ prepare_training_data ë¡œì§)"""
        task_type = self.data_interface.task_type
        exclude_cols = self._get_exclude_columns(df)
        
        if task_type in ["classification", "regression"]:
            return self._prepare_supervised_data(df, exclude_cols)
        elif task_type == "clustering":
            return self._prepare_clustering_data(df, exclude_cols)  
        elif task_type == "causal":
            return self._prepare_causal_data(df, exclude_cols)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” task_type: {task_type}")
    
    def _prepare_supervised_data(self, df: pd.DataFrame, exclude_cols: list) -> Tuple[pd.DataFrame, pd.Series, Dict[str, Any]]:
        """Classification/Regression ë°ì´í„° ì¤€ë¹„"""
        target_col = self.data_interface.target_column
        
        # âœ… feature_columns null ì²˜ë¦¬ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
        if self.data_interface.feature_columns is None:
            # ìë™ ì„ íƒ: target, treatment, entity ì œì™¸ ëª¨ë“  ì»¬ëŸ¼
            auto_exclude = [target_col] + exclude_cols
            if self.data_interface.treatment_column:
                auto_exclude.append(self.data_interface.treatment_column)
            
            X = df.drop(columns=[c for c in auto_exclude if c in df.columns])
            self.console.info(f"Feature columns ìë™ ì„ íƒ: {list(X.columns)}",
                            rich_message=f"   ğŸ¯ Auto-selected features: [green]{len(X.columns)}[/green] columns")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = [target_col] + exclude_cols
            if self.data_interface.treatment_column:
                forbidden_cols.append(self.data_interface.treatment_column)
            
            forbidden_cols = [c for c in forbidden_cols if c and c in df.columns]
            overlap = set(self.data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"target, treatment, entity, timestamp ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df[self.data_interface.feature_columns]
            
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì…ë ¥ êµ¬ì„±
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        self._check_missing_values_warning(X)
        
        y = df[target_col]
        additional_data = {}
        
        return X, y, additional_data
        
    def _prepare_clustering_data(self, df: pd.DataFrame, exclude_cols: list) -> Tuple[pd.DataFrame, pd.Series, Dict[str, Any]]:
        """Clustering ë°ì´í„° ì¤€ë¹„"""
        # âœ… feature_columns null ì²˜ë¦¬
        if self.data_interface.feature_columns is None:
            auto_exclude = exclude_cols
            X = df.drop(columns=[c for c in auto_exclude if c in df.columns])
            self.console.info(f"Feature columns ìë™ ì„ íƒ (clustering): {list(X.columns)}",
                            rich_message=f"   ğŸ¯ Auto-selected clustering features: [green]{len(X.columns)}[/green] columns")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = exclude_cols  # entity, timestamp ì»¬ëŸ¼ë§Œ
            forbidden_cols = [c for c in forbidden_cols if c and c in df.columns]
            overlap = set(self.data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"entity, timestamp ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df[self.data_interface.feature_columns]
            
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        self._check_missing_values_warning(X)
        
        y = None
        additional_data = {}
        
        return X, y, additional_data
        
    def _prepare_causal_data(self, df: pd.DataFrame, exclude_cols: list) -> Tuple[pd.DataFrame, pd.Series, Dict[str, Any]]:
        """Causal ë°ì´í„° ì¤€ë¹„"""
        target_col = self.data_interface.target_column
        treatment_col = self.data_interface.treatment_column
        
        # âœ… feature_columns null ì²˜ë¦¬
        if self.data_interface.feature_columns is None:
            auto_exclude = [target_col, treatment_col] + exclude_cols
            X = df.drop(columns=[c for c in auto_exclude if c in df.columns])
            self.console.info(f"Feature columns ìë™ ì„ íƒ (causal): {list(X.columns)}",
                            rich_message=f"   ğŸ¯ Auto-selected causal features: [green]{len(X.columns)}[/green] columns")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = [target_col, treatment_col] + exclude_cols
            forbidden_cols = [c for c in forbidden_cols if c and c in df.columns]
            overlap = set(self.data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"target, treatment, entity, timestamp ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df[self.data_interface.feature_columns]
            
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        self._check_missing_values_warning(X)
        
        y = df[target_col]
        additional_data = {
            'treatment': df[treatment_col],
            'treatment_value': getattr(self.data_interface, 'treatment_value', 1)
        }
        
        return X, y, additional_data

    def _get_exclude_columns(self, df: pd.DataFrame) -> list:
        """
        ë°ì´í„°ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜ (ê¸°ì¡´ ë¡œì§)
        Entity columnsì™€ timestamp columnsë§Œ ì œì™¸ (Recipe v3.0 êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
        """
        fetcher_conf = self.settings.recipe.data.fetcher
        
        exclude_columns = []
        
        # Entity columnsëŠ” í•­ìƒ ì œì™¸
        if self.data_interface.entity_columns:
            exclude_columns.extend(self.data_interface.entity_columns)
        
        # Feature Store timestamp columns ì œì™¸ (offline ëª¨ë“œì—ì„œ)
        if fetcher_conf.type == "feature_store" and fetcher_conf.timestamp_column:
            exclude_columns.append(fetcher_conf.timestamp_column)
        
        # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë°˜í™˜
        return [col for col in exclude_columns if col in df.columns]

    def _check_missing_values_warning(self, X: pd.DataFrame, threshold: float = 0.05):
        """
        5% ì´ìƒ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ì„ ê°ì§€í•˜ê³  ê²½ê³ ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. (ê¸°ì¡´ ë¡œì§)
        
        Args:
            X: íŠ¹ì„± ë°ì´í„°í”„ë ˆì„
            threshold: ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.05 = 5%)
        """
        if X.empty:
            return
            
        missing_info = []
        for col in X.columns:
            missing_count = X[col].isnull().sum()
            missing_ratio = missing_count / len(X)
            
            if missing_ratio >= threshold:
                missing_info.append({
                    'column': col,
                    'missing_count': missing_count,
                    'missing_ratio': missing_ratio,
                    'total_rows': len(X)
                })
        
        if missing_info:
            self.console.warning("ê²°ì¸¡ì¹˜ê°€ ë§ì€ ì»¬ëŸ¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤",
                               rich_message=f"âš ï¸  Found [red]{len(missing_info)}[/red] columns with high missing values")
            for info in missing_info:
                self.console.warning(
                    f"   - {info['column']}: {info['missing_count']:,}ê°œ ({info['missing_ratio']:.1%}) / ì „ì²´ {info['total_rows']:,}ê°œ í–‰",
                    rich_message=f"     [yellow]{info['column']}[/yellow]: [red]{info['missing_ratio']:.1%}[/red] missing"
                )
            self.console.warning("ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”",
                               rich_message="ğŸ’¡ Consider handling missing values in preprocessing (Imputation, column removal, etc.)",
                               suggestion="Add imputation steps or remove high-missing columns in preprocessing")
        else:
            self.console.info(f"ëª¨ë“  íŠ¹ì„± ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ {threshold:.0%} ë¯¸ë§Œì…ë‹ˆë‹¤.",
                            rich_message=f"âœ… All feature columns have <{threshold:.0%} missing values")


# Self-registration
DataHandlerRegistry.register("tabular", TabularDataHandler)