# src/components/datahandler/modules/timeseries_handler.py
import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple
from datetime import datetime, timedelta

from src.interface import BaseDataHandler
from ..registry import DataHandlerRegistry
from src.utils.system.logger import logger


class TimeseriesDataHandler(BaseDataHandler):
    """ì‹œê³„ì—´ ë°ì´í„° ì „ìš© í•¸ë“¤ëŸ¬"""
    
    def validate_data(self, df: pd.DataFrame) -> bool:
        """ì‹œê³„ì—´ ë°ì´í„° ê²€ì¦"""
        timestamp_col = self.data_interface.timestamp_column
        target_col = self.data_interface.target_column
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ê²€ì¦
        if timestamp_col not in df.columns:
            raise ValueError(f"Timestamp ì»¬ëŸ¼ '{timestamp_col}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        if target_col not in df.columns:
            raise ValueError(f"Target ì»¬ëŸ¼ '{target_col}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
        # íƒ€ì„ìŠ¤íƒ¬í”„ ë°ì´í„° íƒ€ì… ê²€ì¦
        if not pd.api.types.is_datetime64_any_dtype(df[timestamp_col]):
            try:
                df[timestamp_col] = pd.to_datetime(df[timestamp_col])
                logger.info(f"Timestamp ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤: {timestamp_col}")
            except:
                raise ValueError(f"Timestamp ì»¬ëŸ¼ '{timestamp_col}'ì„ datetimeìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return True
    
    def split_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """ì‹œê°„ ê¸°ì¤€ ë¶„í•  (ì‹œê°„ ìˆœì„œ ìœ ì§€)"""
        timestamp_col = self.data_interface.timestamp_column
        test_size = 0.2
        
        # ì‹œê°„ ìˆœì„œë¡œ ì •ë ¬ (í•„ìˆ˜)
        df_sorted = df.sort_values(timestamp_col).reset_index(drop=True)
        
        # ì‹œê°„ ê¸°ì¤€ ë¶„í• ì  ê³„ì‚°
        split_idx = int(len(df_sorted) * (1 - test_size))
        
        train_df = df_sorted.iloc[:split_idx].copy()
        test_df = df_sorted.iloc[split_idx:].copy()
        
        logger.info(f"ì‹œê³„ì—´ ì‹œê°„ ê¸°ì¤€ ë¶„í• : Train({len(train_df)}) / Test({len(test_df)})")
        logger.info(f"Train ê¸°ê°„: {train_df[timestamp_col].min()} ~ {train_df[timestamp_col].max()}")
        logger.info(f"Test ê¸°ê°„: {test_df[timestamp_col].min()} ~ {test_df[timestamp_col].max()}")
        
        return train_df, test_df
    
    def prepare_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series, Dict[str, Any]]:
        """ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„"""
        # ë°ì´í„° ê²€ì¦
        self.validate_data(df)
        
        timestamp_col = self.data_interface.timestamp_column
        target_col = self.data_interface.target_column
        
        # ì‹œê°„ ìˆœì„œ ì •ë ¬ (í•„ìˆ˜)
        df = df.sort_values(timestamp_col).reset_index(drop=True)
        
        # ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±
        df_with_features = self._generate_time_features(df)
        
        # Feature/Target ë¶„ë¦¬
        exclude_cols = self._get_exclude_columns(df_with_features)
        
        if self.data_interface.feature_columns is None:
            # ìë™ ì„ íƒ: timestamp, target, entity ì œì™¸
            auto_exclude = [timestamp_col, target_col] + exclude_cols
            X = df_with_features.drop(columns=[c for c in auto_exclude if c in df_with_features.columns])
            logger.info(f"Timeseries feature columns ìë™ ì„ íƒ: {list(X.columns)}")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = [timestamp_col, target_col] + exclude_cols
            forbidden_cols = [c for c in forbidden_cols if c and c in df_with_features.columns]
            overlap = set(self.data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"timestamp, target, entity ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df_with_features[self.data_interface.feature_columns]
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        self._check_missing_values_warning(X)
        
        y = df[target_col]
        
        additional_data = {
            'timestamp': df[timestamp_col]
        }
        
        return X, y, additional_data
    
    def _generate_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹œê³„ì—´ ì‹œê°„ ê¸°ë°˜ íŠ¹ì„± ìë™ ìƒì„±"""
        timestamp_col = self.data_interface.timestamp_column
        target_col = self.data_interface.target_column
        df_copy = df.copy()
        
        # ê¸°ë³¸ ì‹œê°„ íŠ¹ì„±
        df_copy['year'] = df_copy[timestamp_col].dt.year
        df_copy['month'] = df_copy[timestamp_col].dt.month
        df_copy['day'] = df_copy[timestamp_col].dt.day
        df_copy['dayofweek'] = df_copy[timestamp_col].dt.dayofweek
        df_copy['quarter'] = df_copy[timestamp_col].dt.quarter
        df_copy['is_weekend'] = df_copy['dayofweek'].isin([5, 6]).astype(int)
        
        # Lag features (1, 2, 3, 7, 14ì¼ ì „)
        for lag in [1, 2, 3, 7, 14]:
            df_copy[f'{target_col}_lag_{lag}'] = df_copy[target_col].shift(lag)
            
        # Rolling features (3, 7, 14ì¼ í‰ê· )
        for window in [3, 7, 14]:
            df_copy[f'{target_col}_rolling_mean_{window}'] = df_copy[target_col].rolling(window=window).mean()
            df_copy[f'{target_col}_rolling_std_{window}'] = df_copy[target_col].rolling(window=window).std()
        
        logger.info(f"ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì™„ë£Œ: {len(df_copy.columns) - len(df)}ê°œ íŠ¹ì„± ì¶”ê°€")
        return df_copy
    
    def _get_exclude_columns(self, df: pd.DataFrame) -> list:
        """
        ë°ì´í„°ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜
        ì‹œê³„ì—´ì—ì„œëŠ” entity columnsë§Œ ì œì™¸ (timestamp, targetì€ prepare_dataì—ì„œ ë³„ë„ ì²˜ë¦¬)
        """
        fetcher_conf = self.settings.recipe.data.fetcher
        exclude_columns = []
        
        # Entity columnsëŠ” í•­ìƒ ì œì™¸
        if self.data_interface.entity_columns:
            exclude_columns.extend(self.data_interface.entity_columns)
        
        # Feature Store timestamp columns ì œì™¸ (offline ëª¨ë“œì—ì„œ)
        if fetcher_conf.feature_store.enabled and fetcher_conf.feature_store.timestamp_columns:
            exclude_columns.extend(fetcher_conf.feature_store.timestamp_columns)
        
        # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë°˜í™˜
        return [col for col in exclude_columns if col in df.columns]

    def _check_missing_values_warning(self, X: pd.DataFrame, threshold: float = 0.05):
        """
        5% ì´ìƒ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ì„ ê°ì§€í•˜ê³  ê²½ê³ ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Args:
            X: íŠ¹ì„± ë°ì´í„°í”„ë ˆì„
            threshold: ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.05 = 5%)
        """
        if X.empty:
            return
            
        missing_info = []
        for col in X.columns:
            missing_count = X[col].isnull().sum()
            missing_ratio = missing_count / len(X)
            
            if missing_ratio >= threshold:
                missing_info.append({
                    'column': col,
                    'missing_count': missing_count,
                    'missing_ratio': missing_ratio,
                    'total_rows': len(X)
                })
        
        if missing_info:
            logger.warning("âš ï¸  ê²°ì¸¡ì¹˜ê°€ ë§ì€ ì»¬ëŸ¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
            for info in missing_info:
                logger.warning(
                    f"   - {info['column']}: {info['missing_count']:,}ê°œ ({info['missing_ratio']:.1%}) "
                    f"/ ì „ì²´ {info['total_rows']:,}ê°œ í–‰"
                )
            logger.warning("   ğŸ’¡ ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš” (Imputation, ì»¬ëŸ¼ ì œê±° ë“±)")
        else:
            logger.info(f"âœ… ëª¨ë“  íŠ¹ì„± ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ {threshold:.0%} ë¯¸ë§Œì…ë‹ˆë‹¤.")


# Self-registration
DataHandlerRegistry.register("timeseries", TimeseriesDataHandler)