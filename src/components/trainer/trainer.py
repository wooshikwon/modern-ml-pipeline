from __future__ import annotations
import pandas as pd
from typing import Dict, Any, Tuple, Optional, TYPE_CHECKING, Callable
from sklearn.model_selection import train_test_split

from src.settings import Settings
from src.utils.system.logger import logger
from src.utils.system.console_manager import get_console
from src.interface import BaseTrainer, BaseModel, BaseFetcher, BasePreprocessor, BaseEvaluator, BaseDataHandler
from .modules.optimizer import OptunaOptimizer

if TYPE_CHECKING:
    pass

class Trainer(BaseTrainer):
    """
    ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì „ì²´ ê³¼ì •ì„ ê´€ì¥í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í´ë˜ìŠ¤.
    """
    def __init__(self, settings: Settings, factory_provider: Optional[Callable[[], Any]] = None):
        self.settings = settings
        self.factory_provider = factory_provider
        self.console = get_console(settings)
        self.console.component_init("Trainer", "success")
        self.training_results = {}

    def _get_factory(self):
        if self.factory_provider is None:
            raise RuntimeError("Factory providerê°€ ì£¼ì…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—”ì§„ ì˜ì¡´ì„±ì€ ì™¸ë¶€ì—ì„œ ì£¼ì…ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return self.factory_provider()

    def train(
        self,
        df: pd.DataFrame,
        model: Any,
        fetcher: BaseFetcher,
        datahandler: BaseDataHandler,
        preprocessor: BasePreprocessor,
        evaluator: BaseEvaluator,
        context_params: Optional[Dict[str, Any]] = None,
    ) -> Tuple[Any, BasePreprocessor, Dict[str, float], Dict[str, Any]]:
        
        # ë°ì´í„° ë¶„í•  ë° ì „ì²˜ë¦¬
        train_df, test_df = datahandler.split_data(df)
        X_train, y_train, additional_train_data = datahandler.prepare_data(train_df)
        X_test, y_test, additional_test_data = datahandler.prepare_data(test_df)

        # ì „ì²˜ë¦¬ ì ìš©
        if preprocessor:
            preprocessor.fit(X_train)
            X_train = preprocessor.transform(X_train)
            X_test = preprocessor.transform(X_test)

        # ì „ì²˜ë¦¬ ì‚°ì¶œë¬¼ ì €ì¥ (ì„ íƒ)
        try:
            output_cfg = getattr(self.settings.config, 'output', None)
            if output_cfg and getattr(output_cfg.preprocessed, 'enabled', True):
                factory = self._get_factory()
                target = output_cfg.preprocessed
                # run_id í™•ë³´ (MLflow í™œì„± ëŸ° ê¸°ì¤€)
                run = mlflow.active_run() if 'mlflow' in globals() else None
                run_id = run.info.run_id if run else "no_run"
                if target.adapter_type == "storage":
                    storage_adapter = factory.create_data_adapter("storage")
                    base_path = target.config.get('base_path', './artifacts/preprocessed')
                    storage_adapter.write(X_train, f"{base_path}/preprocessed_train_{run_id}.parquet")
                    storage_adapter.write(X_test, f"{base_path}/preprocessed_test_{run_id}.parquet")
                elif target.adapter_type == "sql":
                    sql_adapter = factory.create_data_adapter("sql")
                    table = target.config.get('table')
                    if not table:
                        raise ValueError("output.preprocessed.config.tableì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    sql_adapter.write(X_train, f"{table}_train", if_exists='append', index=False)
                    sql_adapter.write(X_test, f"{table}_test", if_exists='append', index=False)
                elif target.adapter_type == "bigquery":
                    bq_adapter = factory.create_data_adapter("bigquery")
                    project_id = target.config.get('project_id')
                    dataset = target.config.get('dataset_id')
                    table = target.config.get('table')
                    location = target.config.get('location')
                    if not (project_id and dataset and table):
                        raise ValueError("BigQuery ì¶œë ¥ì—ëŠ” project_id, dataset_id, tableì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    bq_adapter.write(X_train, f"{dataset}.{table}_train", options={"project_id": project_id, "location": location, "if_exists": "append"})
                    bq_adapter.write(X_test, f"{dataset}.{table}_test", options={"project_id": project_id, "location": location, "if_exists": "append"})
                else:
                    self.console.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” output ì–´ëŒ‘í„° íƒ€ì…: {target.adapter_type}. ì „ì²˜ë¦¬ ì €ì¥ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        except Exception as e:
            self.console.error(f"ì „ì²˜ë¦¬ ì‚°ì¶œë¬¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ë˜ëŠ” ì§ì ‘ í•™ìŠµ (Recipe ì„¤ì •ë§Œ ì‚¬ìš©)
        recipe_hyperparams = self.settings.recipe.model.hyperparameters
        use_tuning = recipe_hyperparams and getattr(recipe_hyperparams, 'tuning_enabled', False)

        if use_tuning:
            self.console.info("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (Recipeì—ì„œ í™œì„±í™”ë¨)", rich_message="ğŸ¯ Hyperparameter optimization started")
            optimizer = OptunaOptimizer(settings=self.settings, factory_provider=self._get_factory)
            best = optimizer.optimize(train_df, lambda train_df, params, seed: self._single_training_iteration(train_df, params, seed, datahandler))
            self.training_results['hyperparameter_optimization'] = best
            trained_model = best['model']
        else:
            self.console.info("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤. ì´ìœ : Recipeì—ì„œ ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.", rich_message="âš™ï¸ Using fixed hyperparameters (optimization disabled)")
            self.console.info("ê³ ì •ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.", rich_message="ğŸ¯ Training with fixed hyperparameters")
            model.fit(X_train, y_train)
            trained_model = model
            self.training_results['hyperparameter_optimization'] = {'enabled': False}

        # 4. ëª¨ë¸ í‰ê°€ (causal taskì˜ ê²½ìš° additional_test_dataì— treatment ì •ë³´ í¬í•¨)
        metrics = evaluator.evaluate(trained_model, X_test, y_test, additional_test_data)
        self.training_results['evaluation_metrics'] = metrics

        # 5. í•™ìŠµ ë°©ë²•ë¡  ë©”íƒ€ë°ì´í„° ì €ì¥
        self.training_results['training_methodology'] = self._get_training_methodology()
        
        self.console.info(f"ëª¨ë¸ í‰ê°€ ì™„ë£Œ. ì£¼ìš” ì§€í‘œ: {metrics}", rich_message=f"ğŸ“Š Model evaluation complete: {len(metrics)} metrics")
        
        return trained_model, preprocessor, metrics, self.training_results

    def _single_training_iteration(self, train_df, params, seed, datahandler):
        """
        Data Leakage ë°©ì§€ë¥¼ ë³´ì¥í•˜ëŠ” ë‹¨ì¼ í•™ìŠµ/ê²€ì¦ ì‚¬ì´í´.
        
        Optuna íŠœë‹ ì‹œì—ë§Œ ì‚¬ìš©ë˜ë©°, ì´ë¯¸ ë¶„í• ëœ Train ë°ì´í„°ë¥¼
        ë‹¤ì‹œ Train(80%) / Validation(20%)ë¡œ ë¶„í• í•˜ì—¬ íŠœë‹í•©ë‹ˆë‹¤.
        """
        train_data, val_data = train_test_split(
            train_df, test_size=0.2, random_state=seed, stratify=train_df.get(self._get_stratify_col())
        )
        
        X_train, y_train, additional_data = datahandler.prepare_data(train_data)
        X_val, y_val, _ = datahandler.prepare_data(val_data)
        
        factory = self._get_factory()
        preprocessor = factory.create_preprocessor()
        
        if preprocessor:
            preprocessor.fit(X_train)
            X_train_processed = preprocessor.transform(X_train)
            X_val_processed = preprocessor.transform(X_val)
        else:
            X_train_processed, X_val_processed = X_train, X_val
        
        model_instance = factory.create_model()
        model_instance.set_params(**params)
        self._fit_model(model_instance, X_train_processed, y_train, additional_data)
        
        evaluator = factory.create_evaluator()
        metrics = evaluator.evaluate(model_instance, X_val_processed, y_val, val_data)
        
        optimization_metric = self.settings.recipe.model.hyperparameters.optimization_metric or "accuracy"
        score = metrics.get(optimization_metric, 0.0)
        
        return {'model': model_instance, 'preprocessor': preprocessor, 'score': score}

    def _fit_model(self, model, X, y, additional_data):
        """task_choiceì— ë”°ë¼ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤."""
        if not isinstance(model, BaseModel):
            from sklearn.base import is_classifier, is_regressor
            if not (is_classifier(model) or is_regressor(model) or hasattr(model, 'fit')):
                 raise TypeError("ì „ë‹¬ëœ ëª¨ë¸ ê°ì²´ëŠ” BaseModel ì¸í„°í˜ì´ìŠ¤ë¥¼ ë”°ë¥´ê±°ë‚˜ scikit-learn í˜¸í™˜ ëª¨ë¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        task_choice = self.settings.recipe.task_choice
        if task_choice in ["classification", "regression"]:
            model.fit(X, y)
        elif task_choice == "clustering":
            model.fit(X)
        elif task_choice == "causal":
            model.fit(X, additional_data['treatment'], y)
        elif task_choice == "timeseries":
            model.fit(X, y)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” task_choice: {task_choice}")

    def _get_training_methodology(self):
        """í•™ìŠµ ë°©ë²•ë¡  ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        validation_config = self.settings.recipe.evaluation.validation
        hyperparams_config = self.settings.recipe.model.hyperparameters
        task_choice = self.settings.recipe.task_choice
        
        # stratification ì—¬ë¶€ ê²°ì •
        stratify_col = self._get_stratify_col()
        split_method = 'stratified' if stratify_col else 'simple'
        
        # validation strategy ê²°ì •
        if hyperparams_config.tuning_enabled:
            validation_strategy = 'train_validation_split'  # Optuna ì‹œ trainì—ì„œ validation ë¶„í• 
            note = f'Optuna ì‚¬ìš© ì‹œ Train({1-validation_config.test_size:.0%})ì„ ë‹¤ì‹œ Train(80%)/Val(20%)ë¡œ ë¶„í• '
        else:
            validation_strategy = validation_config.method
            note = f'Hyperparameter tuning ë¹„í™œì„±í™”, {validation_config.method} ì‚¬ìš©'
        
        return {
            'train_test_split_method': split_method,
            'train_ratio': 1 - validation_config.test_size,
            'test_ratio': validation_config.test_size,
            'validation_strategy': validation_strategy,
            'random_state': validation_config.random_state,
            'stratify_column': stratify_col,
            'task_choice': task_choice,
            'preprocessing_fit_scope': 'train_only',
            'hyperparameter_optimization': hyperparams_config.tuning_enabled,
            'n_trials': hyperparams_config.n_trials if hyperparams_config.tuning_enabled else None,
            'optimization_metric': hyperparams_config.optimization_metric if hyperparams_config.tuning_enabled else None,
            'note': note
        }

    def _get_stratify_col(self):
        di = self.settings.recipe.data.data_interface
        task_choice = self.settings.recipe.task_choice
        return di.target_column if task_choice == "classification" else di.treatment_column if task_choice == "causal" else None

# Self-registration
from .registry import TrainerRegistry
TrainerRegistry.register("default", Trainer)