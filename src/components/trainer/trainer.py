from __future__ import annotations
from typing import Dict, Any, Optional, TYPE_CHECKING, Callable

from src.settings import Settings
from src.utils.system.console_manager import get_console
from src.interface import BaseTrainer, BaseModel
from .modules.optimizer import OptunaOptimizer

if TYPE_CHECKING:
    pass

class Trainer(BaseTrainer):
    """
    ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì „ì²´ ê³¼ì •ì„ ê´€ì¥í•˜ëŠ” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í´ë˜ìŠ¤.
    """
    def __init__(self, settings: Settings, factory_provider: Optional[Callable[[], Any]] = None):
        self.settings = settings
        self.factory_provider = factory_provider
        self.console = get_console(settings)
        self.console.component_init("Trainer", "success")
        self.training_results = {}

    def _get_factory(self):
        if self.factory_provider is None:
            raise RuntimeError("Factory providerê°€ ì£¼ì…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì—”ì§„ ì˜ì¡´ì„±ì€ ì™¸ë¶€ì—ì„œ ì£¼ì…ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return self.factory_provider()

    def train(
        self,
        X_train: Any,
        y_train: Any,
        X_val: Any,
        y_val: Any,
        model: Any,
        additional_data: Optional[Dict[str, Any]] = None,
    ) -> Any:
        """ì¤€ë¹„ëœ ë°ì´í„°ë¡œ ìˆœìˆ˜ í•™ìŠµë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. (HPO í¬í•¨)"""
        additional_data = additional_data or {}

        recipe_hyperparams = self.settings.recipe.model.hyperparameters
        use_tuning = recipe_hyperparams and getattr(recipe_hyperparams, 'tuning_enabled', False)

        if use_tuning:
            self.console.info("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (Recipeì—ì„œ í™œì„±í™”ë¨)", rich_message="ğŸ¯ Hyperparameter optimization started")
            optimizer = OptunaOptimizer(settings=self.settings, factory_provider=self._get_factory)

            def _objective_callback(_ignored_train_df, params, seed):
                # ìƒˆ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í›„ íŒŒë¼ë¯¸í„° ì ìš©
                factory = self._get_factory()
                model_instance = factory.create_model()
                try:
                    model_instance.set_params(**params)
                except Exception:
                    pass
                # í•™ìŠµ
                self._fit_model(model_instance, X_train, y_train, additional_data.get('train'))
                # ê²€ì¦ ì ìˆ˜ ê³„ì‚°
                evaluator = factory.create_evaluator()
                metrics = evaluator.evaluate(model_instance, X_val, y_val, additional_data.get('val'))
                optimization_metric = self.settings.recipe.model.hyperparameters.optimization_metric or "accuracy"
                return {
                    optimization_metric: metrics.get(optimization_metric, 0.0),
                    'score': metrics.get(optimization_metric, 0.0)
                }

            best = optimizer.optimize(train_df=None, training_callback=_objective_callback)  # train_df ë¯¸ì‚¬ìš©
            self.training_results['hyperparameter_optimization'] = best
            trained_model = best['model'] if 'model' in best else model
        else:
            self.console.info("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ê±´ë„ˆëœë‹ˆë‹¤. ì´ìœ : Recipeì—ì„œ ë¹„í™œì„±í™”ë˜ì—ˆê±°ë‚˜ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.", rich_message="âš™ï¸ Using fixed hyperparameters (optimization disabled)")
            self.console.info("ê³ ì •ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.", rich_message="ğŸ¯ Training with fixed hyperparameters")
            self._fit_model(model, X_train, y_train, additional_data.get('train'))
            trained_model = model
            self.training_results['hyperparameter_optimization'] = {'enabled': False}

        return trained_model

    # ê¸°ì¡´ ë‹¨ì¼ í•™ìŠµ/ê²€ì¦ ë¶„í•  ë¡œì§ì€ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì œê±°ë¨

    def _fit_model(self, model, X, y, additional_data):
        """task_choiceì— ë”°ë¼ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤."""
        if not isinstance(model, BaseModel):
            from sklearn.base import is_classifier, is_regressor
            if not (is_classifier(model) or is_regressor(model) or hasattr(model, 'fit')):
                 raise TypeError("ì „ë‹¬ëœ ëª¨ë¸ ê°ì²´ëŠ” BaseModel ì¸í„°í˜ì´ìŠ¤ë¥¼ ë”°ë¥´ê±°ë‚˜ scikit-learn í˜¸í™˜ ëª¨ë¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        
        task_choice = self.settings.recipe.task_choice
        if task_choice in ["classification", "regression"]:
            model.fit(X, y)
        elif task_choice == "clustering":
            model.fit(X)
        elif task_choice == "causal":
            model.fit(X, additional_data['treatment'], y)
        elif task_choice == "timeseries":
            model.fit(X, y)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” task_choice: {task_choice}")

    def _get_training_methodology(self):
        """í•™ìŠµ ë°©ë²•ë¡  ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        validation_config = self.settings.recipe.evaluation.validation
        hyperparams_config = self.settings.recipe.model.hyperparameters
        task_choice = self.settings.recipe.task_choice
        
        # stratification ì—¬ë¶€ ê²°ì •
        stratify_col = self._get_stratify_col()
        split_method = 'stratified' if stratify_col else 'simple'
        
        # validation strategy ê²°ì •
        if hyperparams_config.tuning_enabled:
            validation_strategy = 'train_validation_split'  # Optuna ì‹œ trainì—ì„œ validation ë¶„í• 
            note = f'Optuna ì‚¬ìš© ì‹œ Train({1-validation_config.test_size:.0%})ì„ ë‹¤ì‹œ Train(80%)/Val(20%)ë¡œ ë¶„í• '
        else:
            validation_strategy = validation_config.method
            note = f'Hyperparameter tuning ë¹„í™œì„±í™”, {validation_config.method} ì‚¬ìš©'
        
        return {
            'train_test_split_method': split_method,
            'train_ratio': 1 - validation_config.test_size,
            'test_ratio': validation_config.test_size,
            'validation_strategy': validation_strategy,
            'random_state': validation_config.random_state,
            'stratify_column': stratify_col,
            'task_choice': task_choice,
            'preprocessing_fit_scope': 'train_only',
            'hyperparameter_optimization': hyperparams_config.tuning_enabled,
            'n_trials': hyperparams_config.n_trials if hyperparams_config.tuning_enabled else None,
            'optimization_metric': hyperparams_config.optimization_metric if hyperparams_config.tuning_enabled else None,
            'note': note
        }

    def _get_stratify_col(self):
        di = self.settings.recipe.data.data_interface
        task_choice = self.settings.recipe.task_choice
        return di.target_column if task_choice == "classification" else di.treatment_column if task_choice == "causal" else None

# Self-registration
from .registry import TrainerRegistry
TrainerRegistry.register("default", Trainer)