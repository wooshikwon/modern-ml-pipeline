# src/components/_trainer/_data_handler.py
import pandas as pd
import numpy as np
from typing import Dict, Any, Tuple
from sklearn.model_selection import train_test_split
from src.settings import Settings
from src.utils.system.logger import logger  # âœ… logger import ì¶”ê°€


def split_data(df: pd.DataFrame, settings: Settings) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """Train/Test ë¶„í•  (ì¡°ê±´ë¶€ stratify)"""
    data_interface = settings.recipe.data.data_interface  # âœ… ê²½ë¡œ ìˆ˜ì •
    task_choice = settings.recipe.task_choice
    test_size = 0.2

    stratify_series = None
    if task_choice == "classification":
        target_col = data_interface.target_column
        if target_col in df.columns:
            counts = df[target_col].value_counts()
            # ê° í´ë˜ìŠ¤ ìµœì†Œ 2ê°œ, í…ŒìŠ¤íŠ¸ ì…‹ì— ìµœì†Œ 1ê°œ ì´ìƒ ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
            if len(counts) >= 2 and counts.min() >= 2 and int(len(df) * test_size) >= 1:
                stratify_series = df[target_col]
    elif task_choice == "causal":
        treatment_col = data_interface.treatment_column
        if treatment_col in df.columns:
            counts = df[treatment_col].value_counts()
            if len(counts) >= 2 and counts.min() >= 2 and int(len(df) * test_size) >= 1:
                stratify_series = df[treatment_col]

    train_df, test_df = train_test_split(
        df, test_size=test_size, random_state=42, stratify=stratify_series
    )
    return train_df, test_df


def _get_stratify_column_data(df: pd.DataFrame, settings: Settings):
    """Stratifyìš© ì»¬ëŸ¼ ë°ì´í„° ì¶”ì¶œ"""
    data_interface = settings.recipe.data.data_interface
    task_choice = settings.recipe.task_choice
    
    if task_choice == "classification":
        target_col = data_interface.target_column
        return df[target_col] if target_col in df.columns else None
    elif task_choice == "causal":
        treatment_col = data_interface.treatment_column
        return df[treatment_col] if treatment_col in df.columns else None
    else:
        return None


def _get_exclude_columns(settings: Settings, df: pd.DataFrame) -> list:
    """
    ë°ì´í„°ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ ëª©ë¡ ë°˜í™˜
    Entity columnsì™€ timestamp columnsë§Œ ì œì™¸ (Recipe v3.0 êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
    """
    data_interface = settings.recipe.data.data_interface
    fetcher_conf = settings.recipe.data.fetcher
    
    exclude_columns = []
    
    # Entity columns ì¶”ê°€
    try:
        exclude_columns.extend(data_interface.entity_columns or [])
    except Exception:
        pass
    
    # Timestamp column ì¶”ê°€
    try:
        ts_col = fetcher_conf.timestamp_column if fetcher_conf else None
        if ts_col:
            exclude_columns.append(ts_col)
    except Exception:
        pass

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë°˜í™˜
    return [c for c in exclude_columns if c in df.columns]


def prepare_training_data(df: pd.DataFrame, settings: Settings) -> Tuple[pd.DataFrame, pd.Series, Dict[str, Any]]:
    """ë™ì  ë°ì´í„° ì¤€ë¹„ + feature_columns null ì²˜ë¦¬"""
    data_interface = settings.recipe.data.data_interface  # âœ… ê²½ë¡œ ìˆ˜ì •
    task_choice = settings.recipe.task_choice
    exclude_cols = _get_exclude_columns(settings, df)
    
    if task_choice in ["classification", "regression"]:
        target_col = data_interface.target_column
        
        # âœ… feature_columns null ì²˜ë¦¬ ë¡œì§
        if data_interface.feature_columns is None:
            # ìë™ ì„ íƒ: target, treatment, entity ì œì™¸ ëª¨ë“  ì»¬ëŸ¼
            auto_exclude = [target_col] + exclude_cols
            if data_interface.treatment_column:
                auto_exclude.append(data_interface.treatment_column)
            
            X = df.drop(columns=[c for c in auto_exclude if c in df.columns])
            logger.info(f"Feature columns ìë™ ì„ íƒ: {list(X.columns)}")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = [target_col] + exclude_cols
            if data_interface.treatment_column:
                forbidden_cols.append(data_interface.treatment_column)
            
            forbidden_cols = [c for c in forbidden_cols if c and c in df.columns]
            overlap = set(data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"target, treatment, entity, timestamp ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df[data_interface.feature_columns]
            
        # ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì…ë ¥ êµ¬ì„±
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        _check_missing_values_warning(X)
        
        y = df[target_col]
        additional_data = {}
        
    elif task_choice == "clustering":
        # âœ… feature_columns null ì²˜ë¦¬
        if data_interface.feature_columns is None:
            auto_exclude = exclude_cols
            X = df.drop(columns=[c for c in auto_exclude if c in df.columns])
            logger.info(f"Feature columns ìë™ ì„ íƒ (clustering): {list(X.columns)}")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = exclude_cols  # entity, timestamp ì»¬ëŸ¼ë§Œ
            forbidden_cols = [c for c in forbidden_cols if c and c in df.columns]
            overlap = set(data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"entity, timestamp ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df[data_interface.feature_columns]
            
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        _check_missing_values_warning(X)
        
        y = None
        additional_data = {}
        
    elif task_choice == "causal":
        target_col = data_interface.target_column
        treatment_col = data_interface.treatment_column
        
        # âœ… feature_columns null ì²˜ë¦¬
        if data_interface.feature_columns is None:
            auto_exclude = [target_col, treatment_col] + exclude_cols
            X = df.drop(columns=[c for c in auto_exclude if c in df.columns])
            logger.info(f"Feature columns ìë™ ì„ íƒ (causal): {list(X.columns)}")
        else:
            # ëª…ì‹œì  ì„ íƒ - ê¸ˆì§€ëœ ì»¬ëŸ¼ validation
            forbidden_cols = [target_col, treatment_col] + exclude_cols
            forbidden_cols = [c for c in forbidden_cols if c and c in df.columns]
            overlap = set(data_interface.feature_columns) & set(forbidden_cols)
            if overlap:
                raise ValueError(f"feature_columnsì— ê¸ˆì§€ëœ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {list(overlap)}. "
                               f"target, treatment, entity, timestamp ì»¬ëŸ¼ì€ featureë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            X = df[data_interface.feature_columns]
            
        X = X.select_dtypes(include=[np.number])
        
        # 5% ì´ìƒ ê²°ì¸¡ ì»¬ëŸ¼ ê²½ê³ 
        _check_missing_values_warning(X)
        
        y = df[target_col]
        additional_data = {
            'treatment': df[treatment_col],
            'treatment_value': getattr(data_interface, 'treatment_value', 1)
        }
    else:
        raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” task_choice: {task_choice}")
    
    return X, y, additional_data


def _check_missing_values_warning(X: pd.DataFrame, threshold: float = 0.05):
    """
    5% ì´ìƒ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ì„ ê°ì§€í•˜ê³  ê²½ê³ ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Args:
        X: íŠ¹ì„± ë°ì´í„°í”„ë ˆì„
        threshold: ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.05 = 5%)
    """
    if X.empty:
        return
        
    missing_info = []
    for col in X.columns:
        missing_count = X[col].isnull().sum()
        missing_ratio = missing_count / len(X)
        
        if missing_ratio >= threshold:
            missing_info.append({
                'column': col,
                'missing_count': missing_count,
                'missing_ratio': missing_ratio,
                'total_rows': len(X)
            })
    
    if missing_info:
        logger.warning("âš ï¸  ê²°ì¸¡ì¹˜ê°€ ë§ì€ ì»¬ëŸ¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for info in missing_info:
            logger.warning(
                f"   - {info['column']}: {info['missing_count']:,}ê°œ ({info['missing_ratio']:.1%}) "
                f"/ ì „ì²´ {info['total_rows']:,}ê°œ í–‰"
            )
        logger.warning("   ğŸ’¡ ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš” (Imputation, ì»¬ëŸ¼ ì œê±° ë“±)")
    else:
        logger.info(f"âœ… ëª¨ë“  íŠ¹ì„± ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ì´ {threshold:.0%} ë¯¸ë§Œì…ë‹ˆë‹¤.")
