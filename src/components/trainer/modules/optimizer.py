# src/components/_trainer/_optimizer.py
from datetime import datetime
from typing import Dict, Any, Callable
import pandas as pd
from src.settings import Settings
from src.utils.system.logger import logger
from src.utils.integrations.optuna_integration import logging_callback

class OptunaOptimizer:
    def __init__(self, settings: Settings, factory_provider: Callable[[], Any]):
        self.settings = settings
        self.factory_provider = factory_provider
        self.pruner = self._create_pruner()

    def _create_pruner(self):
        """ê¸°ë³¸ Pruner ìƒì„± (í•„ìš”ì‹œ settingsë¡œ í™•ì¥ ê°€ëŠ¥)"""
        try:
            import optuna
            return optuna.pruners.MedianPruner()
        except Exception:
            return None

    def optimize(self, train_df: pd.DataFrame, training_callback: Callable) -> Dict[str, Any]:
        """Optunaë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        logger.info("ğŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ ìµœì í™” ëª¨ë“œ ì‹œì‘")
        
        factory = self.factory_provider()
        optuna_integration = factory.create_optuna_integration()

        # optimization_metricì— ë”°ë¼ direction ìë™ ê²°ì •
        optimization_metric = self.settings.recipe.model.hyperparameters.optimization_metric or "accuracy"
        
        # metricë³„ ë°©í–¥ ë§¤í•‘
        metric_directions = {
            # Classification - ëª¨ë‘ maximize
            "accuracy": "maximize", "precision": "maximize", "recall": "maximize", "f1": "maximize", "roc_auc": "maximize",
            # Regression - MSE, RMSE, MAE, MAPEëŠ” minimize, R2ëŠ” maximize
            "mae": "minimize", "mse": "minimize", "rmse": "minimize", "r2": "maximize", "mape": "minimize",
            # Clustering - silhouette_score, calinski_harabaszëŠ” maximize, davies_bouldinì€ minimize
            "silhouette_score": "maximize", "davies_bouldin": "minimize", "calinski_harabasz": "maximize",
            # Causal - ê¸°ë³¸ì ìœ¼ë¡œ maximize
            "ate": "maximize", "att": "maximize", "confidence_intervals": "maximize"
        }
        
        direction = metric_directions.get(optimization_metric, "maximize")
        
        study = optuna_integration.create_study(
            direction=direction,
            study_name=f"study_{self.settings.recipe.name}",
            pruner=self.pruner
        )
        
        start_time = datetime.now()

        def objective(trial):
            # optuna_integrationì„ í†µí•´ íŒŒë¼ë¯¸í„° ì œì•ˆ
            params = optuna_integration.suggest_hyperparameters(
                trial, self.settings.recipe.model.hyperparameters.tunable or {}
            )
            result = training_callback(train_df=train_df, params=params, seed=trial.number)
            
            # ì„ íƒëœ optimization_metricì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ ë°˜í™˜
            if optimization_metric in result:
                return result[optimization_metric]
            else:
                # fallback to 'score' key for backward compatibility
                return result.get('score', 0.0)
        
        study.optimize(
            objective, 
            n_trials=self.settings.recipe.model.hyperparameters.n_trials or 10,
            timeout=self.settings.recipe.model.hyperparameters.timeout,
            callbacks=[logging_callback]
        )
        
        end_time = datetime.now()
        optimization_time = (end_time - start_time).total_seconds()
        
        logger.info(f"ğŸ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ! ìµœê³  {optimization_metric}: {study.best_value:.4f} ({optimization_time:.1f}ì´ˆ)")

        return {
            'enabled': True,
            'engine': 'optuna',
            'optimization_metric': optimization_metric,
            'optimization_direction': direction,
            'best_params': study.best_params,
            'best_score': study.best_value,
            'optimization_history': [trial.value for trial in study.trials if trial.value is not None],
            'total_trials': len(study.trials),
            'pruned_trials': len([t for t in study.trials if t.state.name == 'PRUNED']),
            'optimization_time': optimization_time,
            'search_space': self.settings.recipe.model.hyperparameters.tunable or {}
        }
