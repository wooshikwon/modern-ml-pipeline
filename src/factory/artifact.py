from __future__ import annotations
import pandas as pd
from typing import Dict, Any, Optional

import mlflow
from src.utils.system.logger import logger
from src.utils.system.console_manager import get_console

class PyfuncWrapper(mlflow.pyfunc.PythonModel):
    """
    í•™ìŠµëœ ì»´í¬ë„ŒíŠ¸ì™€ ëª¨ë“  ì„¤ì • ì •ë³´ë¥¼ ìº¡ìŠí™”í•˜ëŠ” MLflow PythonModel êµ¬í˜„ì²´.
    MLflow ì§ë ¬í™”ë¥¼ ìœ„í•´ ìµœì í™”ëœ ë²„ì „.
    """
    def __init__(
        self,
        settings: Any,  # Settings ê°ì²´ (ì‹¤ì œ íƒ€ì…ì€ ëŸ°íƒ€ì„ì— ê²°ì •)
        trained_model: Any,
        trained_datahandler: Optional[Any] = None,
        trained_preprocessor: Optional[Any] = None,
        trained_fetcher: Optional[Any] = None,
        training_results: Optional[Dict[str, Any]] = None,
        signature: Optional[Any] = None, # mlflow.models.ModelSignature
        data_schema: Optional[Any] = None, # mlflow.types.Schema
        data_interface_schema: Optional[Dict[str, Any]] = None,  # DataInterface ê¸°ë°˜ ê²€ì¦ìš©
    ):
        # Consoleì€ lazy loadingìœ¼ë¡œ ì²˜ë¦¬ (ì§ë ¬í™” ë¬¸ì œ í•´ê²°)
        self._console = None
        
        # ì§ë ¬í™” ê°€ëŠ¥í•œ ìµœì†Œí•œì˜ ì„¤ì • ì •ë³´ë§Œ ì¶”ì¶œ
        self._task_type, self.settings_dict = self._extract_serializable_settings(settings)
        
        self.trained_model = trained_model
        # ì§ë ¬í™” ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ë³µì¡í•œ ê°ì²´ë“¤ì€ Noneìœ¼ë¡œ ì„¤ì •
        # ì¶”ë¡  ì‹œì—ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ trained_modelë§Œ ì‚¬ìš©
        self.trained_datahandler = None  # trained_datahandler
        self.trained_preprocessor = None  # trained_preprocessor 
        self.trained_fetcher = None  # trained_fetcher
        self.training_results = training_results or {}
        self.signature = signature
        self.data_schema = data_schema
        self.data_interface_schema = data_interface_schema  # DataInterface ê¸°ë°˜ ê²€ì¦ìš©
        
        # Task typeë³„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ê²°ì •
        self._requires_datahandler = self._task_type in ["timeseries"]  # í–¥í›„ deeplearning ì¶”ê°€ ê°€ëŠ¥

    def _extract_serializable_settings(self, settings):
        """ì„¤ì •ì—ì„œ ì§ë ¬í™” ê°€ëŠ¥í•œ ìµœì†Œí•œì˜ ì •ë³´ë§Œ ì¶”ì¶œ"""
        try:
            if hasattr(settings, 'model_dump'):
                # Pydantic ëª¨ë¸ì¸ ê²½ìš° - ì•ˆì „í•˜ê²Œ ìµœì†Œ ì •ë³´ë§Œ ì¶”ì¶œ
                task_type = settings.recipe.task_choice
                settings_dict = {
                    'recipe': {
                        'task_choice': task_type,
                        'model': {
                            'class_path': getattr(settings.recipe.model, 'class_path', 'unknown')
                        },
                        'data': {
                            'data_interface': {
                                'target_column': getattr(settings.recipe.data.data_interface, 'target_column', None)
                            }
                        }
                    }
                }
                return task_type, settings_dict
            elif isinstance(settings, dict):
                # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                task_type = settings.get('recipe', {}).get('task_choice', 'unknown')
                return task_type, settings
            else:
                # ê¸°íƒ€ ê²½ìš° - ìµœì†Œí•œì˜ ì •ë³´ë§Œ
                task_type = getattr(settings.recipe, 'task_choice', 'unknown') if hasattr(settings, 'recipe') else 'unknown'
                settings_dict = {'recipe': {'task_choice': task_type}}
                return task_type, settings_dict
        except Exception:
            # ëª¨ë“  ê²ƒì´ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’
            return 'unknown', {'recipe': {'task_choice': 'unknown'}}
    
    @property  
    def console(self):
        """Consoleì„ lazy loadingìœ¼ë¡œ ì²˜ë¦¬"""
        if self._console is None:
            try:
                from src.utils.system.console_manager import get_console
                self._console = get_console()
            except:
                # ì™„ì „ ì‹¤íŒ¨ ì‹œ logger í´ë°±
                import logging
                self._console = logging.getLogger(__name__)
        return self._console
    
    def __getstate__(self):
        """ì§ë ¬í™” ì‹œ consoleê³¼ ë³µì¡í•œ ê°ì²´ ì œì™¸"""
        state = self.__dict__.copy()
        # console ì œì™¸ (lazy loadingìœ¼ë¡œ ì¬ìƒì„±ë¨)
        state['_console'] = None
        return state
    
    def __setstate__(self, state):
        """ì—­ì§ë ¬í™” ì‹œ ìƒíƒœ ë³µì›"""
        self.__dict__.update(state)
        # consoleì€ lazy loadingìœ¼ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ ë³„ë„ ì‘ì—… ë¶ˆí•„ìš”

    def _validate_input_schema(self, df: pd.DataFrame):
        """ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì˜ ìŠ¤í‚¤ë§ˆë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
        if self.data_schema:
            try:
                # Timestamp ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¤ëŠ” ë‹¨ìˆœ ë°°ì¹˜ ì…ë ¥ì„ ëŒ€ë¹„í•´ ì‚¬ì „ ë³€í™˜ ì‹œë„
                ts_col = self.data_schema.get('timestamp_column') if isinstance(self.data_schema, dict) else None
                if ts_col and ts_col in df.columns and not pd.api.types.is_datetime64_any_dtype(df[ts_col]):
                    df[ts_col] = pd.to_datetime(df[ts_col], errors='coerce')
                from src.utils.system.schema_utils import SchemaConsistencyValidator
                validator = SchemaConsistencyValidator(self.data_schema)
                validator.validate_inference_consistency(df)
                self.console.info("ì…ë ¥ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ", rich_message="âœ… Input schema validation passed")
            except ValueError as e:
                self.console.error(f"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ (Schema Drift ê°ì§€): {e}", rich_message=f"ğŸš¨ Schema validation failed: [red]{e}[/red]")
                raise

    @property
    def model_class_path(self) -> str:
        return self.settings_dict.get('recipe', {}).get('model', {}).get('class_path', 'unknown')

    @property
    def loader_sql_snapshot(self) -> str:
        return self.settings_dict.get('recipe', {}).get('data', {}).get('loader', {}).get('source_uri', '')

    @property
    def fetcher_config_snapshot(self) -> Dict[str, Any]:
        fetcher = self.settings_dict.get('recipe', {}).get('data', {}).get('fetcher', {})
        return fetcher if fetcher else {}

    @property
    def recipe_yaml_snapshot(self) -> str:
        # settings_dictì˜ recipe ë¶€ë¶„ì„ YAMLë¡œ ë³€í™˜
        import yaml
        recipe = self.settings_dict.get('recipe', {})
        return yaml.dump(recipe)

    @property
    def hyperparameter_optimization(self) -> Dict[str, Any]:
        return self.training_results.get('hyperparameter_optimization', {})

    @property
    def training_methodology(self) -> Dict[str, Any]:
        return self.training_results.get('training_methodology', {})

    def predict(self, context, model_input, params=None):
        """ë‹¨ìˆœí™”ëœ ì˜ˆì¸¡ ë©”ì„œë“œ - ì§ë ¬í™” ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ìµœì†Œí•œì˜ ë¡œì§ë§Œ ì‚¬ìš©"""
        run_mode = params.get("run_mode", "batch") if params else "batch"
        
        # ë””ë²„ê¹…: params ì „ë‹¬ ìƒíƒœ í™•ì¸
        self.console.info(f"Predict called with params: {params}", rich_message=f"ğŸ” Prediction request: [cyan]{len(params)} params[/cyan]" if params else "ğŸ” Prediction request received")

        if not isinstance(model_input, pd.DataFrame):
            model_input = pd.DataFrame(model_input)
            
        # ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ì„ íƒì )
        try:
            if self.data_interface_schema:
                self.console.info("Basic input validation passed", rich_message="âœ… Input validation passed")
        except:
            self.console.warning("Input validation skipped", rich_message="âš ï¸ Input validation skipped")

        # ë‹¨ìˆœí™”ëœ ì˜ˆì¸¡: íƒ€ê²Ÿ ì»¬ëŸ¼ì„ ì œì™¸í•œ í”¼ì²˜ë§Œ ì‚¬ìš©
        try:
            # data_interfaceì—ì„œ íƒ€ê²Ÿ ì»¬ëŸ¼ ì œì™¸
            target_col = self.data_interface_schema.get('data_interface_config', {}).get('target_column')
            feature_columns = [col for col in model_input.columns if col != target_col]
            
            # ëª¨ë“  í”¼ì²˜ ì‚¬ìš© (ë²”ì£¼í˜• ë³€ìˆ˜ë„ í¬í•¨)
            if feature_columns:
                X = model_input[feature_columns]
            else:
                # target_colì´ ì—†ê±°ë‚˜ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ëª¨ë“  ì»¬ëŸ¼ ì‚¬ìš©
                X = model_input
            
            # ëª¨ë¸ ì˜ˆì¸¡
            predictions = self.trained_model.predict(X)
            
            # í˜¸ì¶œ ì»¨í…ìŠ¤íŠ¸ì— ë”°ë¼ ë‹¤ë¥¸ í˜•íƒœë¡œ ë°˜í™˜
            # paramsì— 'return_dataframe'ì´ ìˆìœ¼ë©´ DataFrame ë°˜í™˜ (Inference Pipelineìš©)
            # ì—†ìœ¼ë©´ array/list ë°˜í™˜ (MLflow pyfunc í‘œì¤€)
            should_return_dataframe = params and params.get('return_dataframe', False)
            
            if should_return_dataframe:
                # Inference Pipelineìš©: DataFrame ë°˜í™˜ (ë©”íƒ€ë°ì´í„° ì¶”ê°€ ê°€ëŠ¥)
                if not isinstance(predictions, pd.DataFrame):
                    predictions_df = pd.DataFrame({'prediction': predictions}, index=model_input.index)
                    self.console.info(f"Prediction completed: {len(predictions_df)} samples (DataFrame)", rich_message=f"âœ… Prediction: [green]{len(predictions_df)}[/green] samples (DataFrame)")
                    return predictions_df
                else:
                    self.console.info(f"Prediction completed: {len(predictions)} samples (DataFrame)", rich_message=f"âœ… Prediction: [green]{len(predictions)}[/green] samples (DataFrame)")
                    return predictions
            else:
                # MLflow pyfunc í‘œì¤€: array/list ë°˜í™˜
                if isinstance(predictions, pd.DataFrame):
                    predictions = predictions.values.flatten()
                elif hasattr(predictions, 'tolist'):
                    predictions = predictions.tolist()
                    
                self.console.info(f"Prediction completed: {len(predictions)} samples (array/list)", rich_message=f"âœ… Prediction: [green]{len(predictions)}[/green] samples (array/list)")
                return predictions
            
        except Exception as e:
            self.console.error(f"Prediction failed: {e}", rich_message=f"âŒ Prediction failed: [red]{e}[/red]")
            # í´ë°±: ì²« ë²ˆì§¸ ì»¬ëŸ¼ë§Œ ì‚¬ìš©
            try:
                X = model_input.iloc[:, :1]
                predictions = self.trained_model.predict(X)
                return pd.DataFrame(predictions, columns=['prediction'])
            except:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ë”ë¯¸ ì˜ˆì¸¡
                dummy_predictions = [0.0] * len(model_input)
                return pd.DataFrame(dummy_predictions, columns=['prediction'])
    
    # ë³µì¡í•œ ê²€ì¦ ë©”ì„œë“œë“¤ì€ ì§ë ¬í™” ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì œê±°
    # ì¶”ë¡  ì‹œì—ëŠ” ê¸°ë³¸ì ì¸ ëª¨ë¸ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰
