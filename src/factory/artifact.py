from __future__ import annotations
import pandas as pd
from typing import Dict, Any, Optional

import mlflow
from src.utils.system.logger import logger

class PyfuncWrapper(mlflow.pyfunc.PythonModel):
    """
    í•™ìŠµëœ ì»´í¬ë„ŒíŠ¸ì™€ ëª¨ë“  ì„¤ì • ì •ë³´ë¥¼ ìº¡ìŠí™”í•˜ëŠ” MLflow PythonModel êµ¬í˜„ì²´.
    """
    def __init__(
        self,
        settings: Any,  # Settings ê°ì²´ (ì‹¤ì œ íƒ€ì…ì€ ëŸ°íƒ€ì„ì— ê²°ì •)
        trained_model: Any,
        trained_datahandler: Optional[Any] = None,
        trained_preprocessor: Optional[Any] = None,
        trained_fetcher: Optional[Any] = None,
        training_results: Optional[Dict[str, Any]] = None,
        signature: Optional[Any] = None, # mlflow.models.ModelSignature
        data_schema: Optional[Any] = None, # mlflow.types.Schema
        data_interface_schema: Optional[Dict[str, Any]] = None,  # DataInterface ê¸°ë°˜ ê²€ì¦ìš©
    ):
        # ë³µì¡í•œ Settings ê°ì²´ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        if hasattr(settings, 'model_dump'):
            # Pydantic ëª¨ë¸ì¸ ê²½ìš°
            self.settings_dict = settings.model_dump()
            self._task_type = settings.recipe.task_choice
        else:
            # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
            self.settings_dict = settings
            self._task_type = settings.get('recipe', {}).get('task_choice', 'unknown')
        
        self.trained_model = trained_model
        self.trained_datahandler = trained_datahandler
        self.trained_preprocessor = trained_preprocessor
        self.trained_fetcher = trained_fetcher
        self.training_results = training_results or {}
        self.signature = signature
        self.data_schema = data_schema
        self.data_interface_schema = data_interface_schema  # DataInterface ê¸°ë°˜ ê²€ì¦ìš©
        
        # Task typeë³„ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ê²°ì •
        self._requires_datahandler = self._task_type in ["timeseries"]  # í–¥í›„ deeplearning ì¶”ê°€ ê°€ëŠ¥

    def _validate_input_schema(self, df: pd.DataFrame):
        """ì…ë ¥ ë°ì´í„°í”„ë ˆì„ì˜ ìŠ¤í‚¤ë§ˆë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
        if self.data_schema:
            try:
                # Timestamp ì»¬ëŸ¼ì´ ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¤ëŠ” ë‹¨ìˆœ ë°°ì¹˜ ì…ë ¥ì„ ëŒ€ë¹„í•´ ì‚¬ì „ ë³€í™˜ ì‹œë„
                ts_col = self.data_schema.get('timestamp_column') if isinstance(self.data_schema, dict) else None
                if ts_col and ts_col in df.columns and not pd.api.types.is_datetime64_any_dtype(df[ts_col]):
                    df[ts_col] = pd.to_datetime(df[ts_col], errors='coerce')
                from src.utils.system.schema_utils import SchemaConsistencyValidator
                validator = SchemaConsistencyValidator(self.data_schema)
                validator.validate_inference_consistency(df)
                logger.info("âœ… PyfuncWrapper: ì…ë ¥ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì™„ë£Œ.")
            except ValueError as e:
                logger.error(f"ğŸš¨ PyfuncWrapper: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨ (Schema Drift ê°ì§€): {e}")
                raise

    @property
    def model_class_path(self) -> str:
        return self.settings_dict.get('recipe', {}).get('model', {}).get('class_path', 'unknown')

    @property
    def loader_sql_snapshot(self) -> str:
        return self.settings_dict.get('recipe', {}).get('data', {}).get('loader', {}).get('source_uri', '')

    @property
    def fetcher_config_snapshot(self) -> Dict[str, Any]:
        fetcher = self.settings_dict.get('recipe', {}).get('data', {}).get('fetcher', {})
        return fetcher if fetcher else {}

    @property
    def recipe_yaml_snapshot(self) -> str:
        # settings_dictì˜ recipe ë¶€ë¶„ì„ YAMLë¡œ ë³€í™˜
        import yaml
        recipe = self.settings_dict.get('recipe', {})
        return yaml.dump(recipe)

    @property
    def hyperparameter_optimization(self) -> Dict[str, Any]:
        return self.training_results.get('hyperparameter_optimization', {})

    @property
    def training_methodology(self) -> Dict[str, Any]:
        return self.training_results.get('training_methodology', {})

    def predict(self, context, model_input, params=None):
        run_mode = params.get("run_mode", "batch") if params else "batch"

        if not isinstance(model_input, pd.DataFrame):
            model_input = pd.DataFrame(model_input)
            
        # 1. DataInterface ê¸°ë°˜ ì»¬ëŸ¼ ê²€ì¦
        if self.data_interface_schema:
            self._validate_data_interface_columns(model_input)
        else:
            # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€: data_schema ê¸°ë°˜ ê²€ì¦
            self._validate_input_schema(model_input)

        # 2. ì˜¬ë°”ë¥¸ íŒŒì´í”„ë¼ì¸ ìˆœì„œ: Fetcher â†’ DataHandler â†’ Preprocessor â†’ Model
        if self._requires_datahandler and self.trained_datahandler:
            return self._predict_with_datahandler(model_input, run_mode)
        else:
            return self._predict_traditional(model_input, run_mode)
    
    def _predict_with_datahandler(self, model_input: pd.DataFrame, run_mode: str) -> pd.DataFrame:
        """DataHandlerê°€ í•„ìš”í•œ task (timeseries ë“±)ì˜ ì¶”ë¡  íŒŒì´í”„ë¼ì¸"""
        logger.info(f"ğŸ”„ DataHandler íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (task_type: {self._task_type})")
        
        # 1. Fetcher: í”¼ì²˜ ì¦ê°•
        fetched_df = self.trained_fetcher.fetch(model_input, run_mode=run_mode)
        
        # 2. DataHandler: íŠ¹ì„± ìƒì„±/ë³€í™˜ (ì¬í˜„ì„± ë³´ì¥)
        X, _, additional_data = self.trained_datahandler.prepare_data(fetched_df)
        
        # 3. Preprocessor: ìŠ¤ì¼€ì¼ë§/ì¸ì½”ë”©
        if self.trained_preprocessor:
            X = self.trained_preprocessor.transform(X)
        
        # 4. Model: ì˜ˆì¸¡
        predictions = self.trained_model.predict(X)
        
        # 5. ê²°ê³¼ êµ¬ì„± (timeseriesì˜ ê²½ìš° timestamp ì •ë³´ ì¶”ê°€)
        result_df = pd.DataFrame(predictions, columns=['prediction'], index=model_input.index)
        
        if self._task_type == "timeseries" and additional_data.get('timestamp') is not None:
            result_df['timestamp'] = additional_data['timestamp']
        
        logger.info(f"âœ… DataHandler íŒŒì´í”„ë¼ì¸ ì™„ë£Œ. ì˜ˆì¸¡ ê²°ê³¼: {len(result_df)}ê°œ")
        return result_df
    
    def _predict_traditional(self, model_input: pd.DataFrame, run_mode: str) -> pd.DataFrame:
        """ê¸°ì¡´ ë°©ì‹ (tabular ë“±)ì˜ ì¶”ë¡  íŒŒì´í”„ë¼ì¸"""
        logger.info(f"ğŸ”„ ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (task_type: {self._task_type})")
        
        # ê¸°ì¡´ ë¡œì§: Fetcher â†’ Preprocessor â†’ Model
        fetched_df = self.trained_fetcher.fetch(model_input, run_mode=run_mode)
        preprocessed_df = self.trained_preprocessor.transform(fetched_df) if self.trained_preprocessor else fetched_df
        predictions = self.trained_model.predict(preprocessed_df)
        
        result_df = pd.DataFrame(predictions, columns=['prediction'], index=model_input.index)
        return result_df

    def _validate_data_interface_columns(self, df: pd.DataFrame):
        """
        DataInterface í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        
        DataInterface ê¸°ë°˜ ê²€ì¦ ë¡œì§ì„ ì‚¬ìš©í•˜ì—¬
        ì¶”ë¡  ì‹œì ì— í•„ìˆ˜ ì»¬ëŸ¼ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        **í•µì‹¬ ê¸°ëŠ¥:**
        - í•™ìŠµì‹œ ì €ì¥ëœ required_columnsì™€ ì¶”ë¡  ë°ì´í„° ë¹„êµ
        - feature_columns=nullì´ì—ˆë˜ ê²½ìš° ì‹¤ì œ í•™ìŠµì‹œ ì‚¬ìš©ëœ ëª¨ë“  ì»¬ëŸ¼ ê²€ì¦
        
        Args:
            df: ê²€ì¦í•  ì…ë ¥ ë°ì´í„°í”„ë ˆì„
            
        Raises:
            ValueError: í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ëœ ê²½ìš°
        """
        try:
            from src.utils.system.data_validation import validate_data_interface_columns
            from src.settings.recipe import DataInterface
            
            # DataInterface ê°ì²´ ë³µì›
            data_interface = DataInterface(**self.data_interface_schema['data_interface'])
            
            # í•µì‹¬: í•™ìŠµì‹œ ì €ì¥ëœ í•„ìˆ˜ ì»¬ëŸ¼ ëª©ë¡ ì‚¬ìš©
            stored_required_columns = self.data_interface_schema.get('required_columns', [])
            
            # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ ì‹¤í–‰ (ì €ì¥ëœ ì»¬ëŸ¼ ëª©ë¡ ê¸°ì¤€)
            validate_data_interface_columns(df, data_interface, stored_required_columns)
            
            logger.info(
                f"âœ… DataInterface ì»¬ëŸ¼ ê²€ì¦ ì™„ë£Œ - "
                f"Task: {data_interface.task_type}, "
                f"ì €ì¥ëœ í•„ìˆ˜ ì»¬ëŸ¼: {len(stored_required_columns)}ê°œ, "
                f"ì…ë ¥ ì»¬ëŸ¼: {len(df.columns)}ê°œ"
            )
            
        except ImportError as e:
            logger.error(f"DataInterface ê²€ì¦ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
            raise RuntimeError("DataInterface ê²€ì¦ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"DataInterface ì»¬ëŸ¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            raise
