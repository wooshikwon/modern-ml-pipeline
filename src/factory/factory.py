from __future__ import annotations
import importlib
from typing import Optional, Dict, Any, TYPE_CHECKING, ClassVar

import pandas as pd

from src.components.fetcher import FetcherRegistry
from src.components.preprocessor import Preprocessor, BasePreprocessor
from src.components.adapter import AdapterRegistry
from src.components.evaluator import EvaluatorRegistry
from src.interface import BaseAdapter
from src.settings import Settings
from src.utils.system.logger import logger

if TYPE_CHECKING:
    from src.factory.artifact import PyfuncWrapper
    from src.interface import BaseFetcher


class Factory:
    """
    í˜„ëŒ€í™”ëœ Recipe ì„¤ì •(settings.recipe)ì— ê¸°ë°˜í•˜ì—¬ ëª¨ë“  í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì•™ íŒ©í† ë¦¬ í´ë˜ìŠ¤.
    ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ê³¼ ìºì‹±ì„ í†µí•´ íš¨ìœ¨ì ì¸ ì»´í¬ë„ŒíŠ¸ ìƒì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    # í´ë˜ìŠ¤ ë³€ìˆ˜: ì»´í¬ë„ŒíŠ¸ ë“±ë¡ ìƒíƒœ ì¶”ì 
    _components_registered: ClassVar[bool] = False
    
    def __init__(self, settings: Settings):
        # ì»´í¬ë„ŒíŠ¸ ìë™ ë“±ë¡ (ìµœì´ˆ 1íšŒë§Œ)
        self._ensure_components_registered()
        
        self.settings = settings
        
        # í˜„ëŒ€í™”ëœ Recipe êµ¬ì¡° ê²€ì¦
        if not self.settings.recipe:
            raise ValueError("í˜„ëŒ€í™”ëœ Recipe êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤. settings.recipeê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìì£¼ ì‚¬ìš©í•˜ëŠ” ê²½ë¡œ ìºì‹± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´)
        self._recipe = settings.recipe
        self._config = settings.config
        self._data = self._recipe.data
        self._model = self._recipe.model
        
        # ìƒì„±ëœ ì»´í¬ë„ŒíŠ¸ ìºì‹±
        self._component_cache: Dict[str, Any] = {}
        
        logger.info(f"Factory initialized with Recipe: {self._recipe.name}")
    
    @classmethod
    def _ensure_components_registered(cls) -> None:
        """
        ì»´í¬ë„ŒíŠ¸ë“¤ì´ Registryì— ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”ì‹œ ë“±ë¡í•©ë‹ˆë‹¤.
        ì´ ë©”ì„œë“œëŠ” Factory ì¸ìŠ¤í„´ìŠ¤ê°€ ì²˜ìŒ ìƒì„±ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        if not cls._components_registered:
            logger.debug("Initializing component registries...")
            
            # ì»´í¬ë„ŒíŠ¸ ëª¨ë“ˆë“¤ì„ importí•˜ì—¬ self-registration íŠ¸ë¦¬ê±°
            try:
                import src.components.adapter
                import src.components.evaluator
                import src.components.fetcher
                import src.components.trainer
                import src.components.preprocessor
                import src.components.datahandler
            except ImportError as e:
                logger.warning(f"Some components could not be imported: {e}")
            
            cls._components_registered = True
            logger.debug("Component registries initialized successfully")
    
    def _create_from_class_path(self, class_path: str, hyperparameters: Dict[str, Any]) -> Any:
        """
        í´ë˜ìŠ¤ ê²½ë¡œë¡œë¶€í„° ë™ì ìœ¼ë¡œ ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ.
        
        Args:
            class_path: ì „ì²´ í´ë˜ìŠ¤ ê²½ë¡œ (ì˜ˆ: 'sklearn.ensemble.RandomForestClassifier')
            hyperparameters: í´ë˜ìŠ¤ ì´ˆê¸°í™” íŒŒë¼ë¯¸í„°
            
        Returns:
            ìƒì„±ëœ ê°ì²´ ì¸ìŠ¤í„´ìŠ¤
        """
        try:
            module_path, class_name = class_path.rsplit('.', 1)
            module = importlib.import_module(module_path)
            model_class = getattr(module, class_name)
            
            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²˜ë¦¬ (callable íŒŒë¼ë¯¸í„° ì²˜ë¦¬)
            processed_params = self._process_hyperparameters(hyperparameters)
            
            instance = model_class(**processed_params)
            logger.info(f"âœ… Created instance from class path: {class_path}")
            return instance
            
        except Exception as e:
            logger.error(f"Failed to create instance from {class_path}: {e}")
            raise ValueError(f"Could not load class: {class_path}") from e
    
    def _process_hyperparameters(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²˜ë¦¬ (ë¬¸ìì—´ì„ ê°ì²´ë¡œ ë³€í™˜ ë“±)."""
        processed = params.copy()
        
        for key, value in processed.items():
            if isinstance(value, str) and "." in value and ("_fn" in key or "_class" in key):
                try:
                    module_path, func_name = value.rsplit('.', 1)
                    module = importlib.import_module(module_path)
                    processed[key] = getattr(module, func_name)
                    logger.debug(f"Converted hyperparameter '{key}' to callable: {value}")
                except (ImportError, AttributeError):
                    logger.debug(f"Keeping hyperparameter '{key}' as string: {value}")
        
        return processed

    def _detect_adapter_type_from_uri(self, source_uri: str) -> str:
        """
        source_uri íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ì–´ëŒ‘í„° íƒ€ì…ì„ ìë™ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.
        
        íŒ¨í„´:
        - .sql íŒŒì¼ ë˜ëŠ” SQL ì¿¼ë¦¬ â†’ 'sql'
        - .csv, .parquet, .json â†’ 'storage'
        - s3://, gs://, az:// â†’ 'storage'
        - bigquery:// â†’ 'bigquery'
        """
        uri_lower = source_uri.lower()
        
        # SQL íŒ¨í„´
        if uri_lower.endswith('.sql') or 'select' in uri_lower or 'from' in uri_lower:
            return 'sql'
        
        # BigQuery íŒ¨í„´
        if uri_lower.startswith('bigquery://'):
            return 'bigquery'
        
        # Cloud Storage íŒ¨í„´
        if any(uri_lower.startswith(prefix) for prefix in ['s3://', 'gs://', 'az://']):
            return 'storage'
        
        # File íŒ¨í„´
        if any(uri_lower.endswith(ext) for ext in ['.csv', '.parquet', '.json', '.tsv']):
            return 'storage'
        
        # ê¸°ë³¸ê°’
        logger.warning(f"source_uri íŒ¨í„´ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_uri}. 'storage' ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return 'storage'
    
    def create_data_adapter(self, adapter_type: Optional[str] = None) -> "BaseAdapter":
        """
        ë°ì´í„° ì–´ëŒ‘í„° ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).
        
        Args:
            adapter_type: ëª…ì‹œì  ì–´ëŒ‘í„° íƒ€ì… (ì„ íƒì‚¬í•­)
            
        Returns:
            BaseAdapter ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = f"adapter_{adapter_type}" if adapter_type else "adapter_auto"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached adapter: {cache_key}")
            return self._component_cache[cache_key]
        
        # ì–´ëŒ‘í„° íƒ€ì… ê²°ì • (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´)
        if adapter_type:
            target_type = adapter_type
        else:
            # ìºì‹±ëœ ê²½ë¡œ ì‚¬ìš©
            source_uri = self._data.loader.source_uri
            target_type = self._detect_adapter_type_from_uri(source_uri)
            logger.info(f"Auto-detected adapter type '{target_type}' from URI: {source_uri}")
        
        # Registryë¥¼ í†µí•œ ìƒì„± (ì¼ê´€ëœ íŒ¨í„´)
        try:
            adapter = AdapterRegistry.create(target_type, self.settings)
            self._component_cache[cache_key] = adapter  # ìºì‹±
            logger.info(f"âœ… Created data adapter: {target_type}")
            return adapter
        except Exception as e:
            available = list(AdapterRegistry.list_adapters().keys())
            raise ValueError(
                f"Failed to create adapter '{target_type}'. Available: {available}"
            ) from e
    
    def create_fetcher(self, run_mode: Optional[str] = None) -> "BaseFetcher":
        """
        Fetcher ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        
        Args:
            run_mode: ì‹¤í–‰ ëª¨ë“œ (batch/serving)
            
        Returns:
            BaseFetcher ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í‚¤ ìƒì„±
        mode = (run_mode or "batch").lower()
        cache_key = f"fetcher_{mode}"
        
        # ìºì‹± í™•ì¸
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached fetcher: {cache_key}")
            return self._component_cache[cache_key]
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ìœ¼ë¡œ ì„¤ì • ì ‘ê·¼
        env = self._config.environment.env_name if hasattr(self._config, "environment") else "local"
        provider = self.settings.feature_store.provider if self.settings.feature_store else "none"
        fetch_conf = self._recipe.data.fetcher if hasattr(self._recipe.data, "fetcher") else None
        fetch_type = fetch_conf.type if fetch_conf else None

        # serving ëª¨ë“œ ê²€ì¦
        if mode == "serving":
            if fetch_type in (None, "pass_through") or provider in (None, "none"):
                raise TypeError(
                    "Serving ëª¨ë“œì—ì„œëŠ” Feature Store ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤. "
                    "pass_through ë˜ëŠ” feature_store ë¯¸êµ¬ì„±ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )

        # Fetcher ìƒì„± (ì¼ê´€ëœ Registry íŒ¨í„´)
        try:
            # PassThrough ì¼€ì´ìŠ¤
            if env == "local" or provider == "none" or fetch_type == "pass_through" or not fetch_conf:
                fetcher = FetcherRegistry.create("pass_through")
                
            # Feature Store ì¼€ì´ìŠ¤
            elif fetch_type == "feature_store" and provider in {"feast", "mock", "dynamic"}:
                fetcher = FetcherRegistry.create(
                    fetch_type, 
                    settings=self.settings, 
                    factory=self
                )
            else:
                raise ValueError(
                    f"ì ì ˆí•œ fetcherë¥¼ ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                    f"env={env}, provider={provider}, fetch_type={fetch_type}, mode={mode}"
                )
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = fetcher
            logger.info(f"âœ… Created fetcher: {fetch_type or 'pass_through'} (mode={mode})")
            return fetcher
            
        except Exception as e:
            logger.error(f"Failed to create fetcher: {e}")
            raise

    def create_preprocessor(self) -> Optional[BasePreprocessor]:
        """
        Preprocessor ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        
        Returns:
            BasePreprocessor ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
        """
        # ìºì‹± í™•ì¸
        cache_key = "preprocessor"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached preprocessor")
            return self._component_cache[cache_key]
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´
        preprocessor_config = getattr(self._recipe, "preprocessor", None)
        
        if not preprocessor_config:
            logger.info("No preprocessor configured")
            return None
        
        try:
            # Preprocessor ìƒì„±
            preprocessor = Preprocessor(settings=self.settings)
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = preprocessor
            logger.info("âœ… Created preprocessor")
            return preprocessor
            
        except Exception as e:
            logger.error(f"Failed to create preprocessor: {e}")
            raise

    def create_model(self) -> Any:
        """
        Model ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + í—¬í¼ ë©”ì„œë“œ í™œìš©).
        
        Returns:
            ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = "model"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached model")
            return self._component_cache[cache_key]
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´
        class_path = self._model.class_path
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ì¼ê´€ëœ íŒ¨í„´)
        if hasattr(self._model.hyperparameters, 'get_fixed_params'):
            hyperparameters = self._model.hyperparameters.get_fixed_params()
        else:
            hyperparameters = dict(self._model.hyperparameters) if hasattr(self._model.hyperparameters, '__dict__') else {}
        
        try:
            # í—¬í¼ ë©”ì„œë“œ í™œìš©
            model = self._create_from_class_path(class_path, hyperparameters)
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = model
            logger.info(f"âœ… Created model: {class_path}")
            return model
            
        except Exception as e:
            logger.error(f"Failed to create model from {class_path}: {e}")
            raise

    def create_evaluator(self) -> Any:
        """
        Evaluator ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        
        Returns:
            Evaluator ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = "evaluator"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached evaluator")
            return self._component_cache[cache_key]
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´
        data_interface = self._recipe.data.data_interface
        task_type = data_interface.task_type
        
        try:
            # Registry íŒ¨í„´ìœ¼ë¡œ ìƒì„±
            evaluator = EvaluatorRegistry.create(task_type, data_interface)
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = evaluator
            logger.info(f"âœ… Created evaluator for task: {task_type}")
            return evaluator
            
        except Exception as e:
            available = list(EvaluatorRegistry.list_evaluators().keys())
            logger.error(f"Failed to create evaluator for '{task_type}'. Available: {available}")
            raise

    def create_trainer(self, trainer_type: Optional[str] = None) -> Any:
        """
        Trainer ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        
        Args:
            trainer_type: íŠ¸ë ˆì´ë„ˆ íƒ€ì… (Noneì´ë©´ 'default' ì‚¬ìš©)
            
        Returns:
            Trainer ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = f"trainer_{trainer_type or 'default'}"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached trainer")
            return self._component_cache[cache_key]
        
        # TrainerRegistry import
        from src.components.trainer import TrainerRegistry
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´
        trainer_type = trainer_type or 'default'
        
        try:
            # settingsì™€ factory_providerë¥¼ ì „ë‹¬í•˜ì—¬ trainer ìƒì„±
            trainer = TrainerRegistry.create(
                trainer_type, 
                settings=self._settings,
                factory_provider=lambda: self
            )
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = trainer
            logger.info(f"âœ… Created trainer: {trainer_type}")
            return trainer
            
        except Exception as e:
            available = list(TrainerRegistry.trainers.keys())
            logger.error(f"Failed to create trainer for '{trainer_type}'. Available: {available}")
            raise

    def create_datahandler(self) -> Any:
        """
        DataHandler ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        task_typeì— ë”°ë¼ ì ì ˆí•œ DataHandlerë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
        
        Returns:
            BaseDataHandler ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = "datahandler"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached datahandler")
            return self._component_cache[cache_key]
        
        # DataHandlerRegistry import
        from src.components.datahandler import DataHandlerRegistry
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´
        data_interface = self._recipe.data.data_interface
        task_type = data_interface.task_type
        
        try:
            # Registry íŒ¨í„´ìœ¼ë¡œ task_typeì— ë”°ë¼ ìë™ ìƒì„±
            datahandler = DataHandlerRegistry.get_handler_for_task(task_type, self.settings)
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = datahandler
            logger.info(f"âœ… Created datahandler for task: {task_type}")
            return datahandler
            
        except Exception as e:
            available = list(DataHandlerRegistry.get_available_handlers().keys())
            logger.error(f"Failed to create datahandler for '{task_type}'. Available: {available}")
            raise

    def create_feature_store_adapter(self) -> "BaseAdapter":
        """
        Feature Store ì–´ëŒ‘í„° ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        
        Returns:
            Feature Store ì–´ëŒ‘í„° ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = "feature_store_adapter"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached feature store adapter")
            return self._component_cache[cache_key]
        
        # ê²€ì¦
        if not self.settings.feature_store:
            raise ValueError("Feature Store settings are not configured.")
        
        try:
            # Registry íŒ¨í„´ìœ¼ë¡œ ìƒì„±
            adapter = AdapterRegistry.create('feature_store', self.settings)
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = adapter
            logger.info("âœ… Created Feature Store adapter")
            return adapter
            
        except Exception as e:
            logger.error(f"Failed to create Feature Store adapter: {e}")
            raise
    
    def create_optuna_integration(self) -> Any:
        """
        Optuna Integration ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ + ìºì‹±).
        
        Returns:
            OptunaIntegration ì¸ìŠ¤í„´ìŠ¤
        """
        # ìºì‹± í™•ì¸
        cache_key = "optuna_integration"
        if cache_key in self._component_cache:
            logger.debug(f"Returning cached Optuna integration")
            return self._component_cache[cache_key]
        
        # ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ (Recipe hyperparameters êµ¬ì¡° ì‚¬ìš©)
        tuning_config = getattr(self._model, "hyperparameters", None)
        
        if not tuning_config:
            raise ValueError("Hyperparameter tuning settings are not configured.")
        
        try:
            from src.utils.integrations.optuna_integration import OptunaIntegration
            
            # Integration ìƒì„±
            integration = OptunaIntegration(tuning_config)
            
            # ìºì‹± ì €ì¥
            self._component_cache[cache_key] = integration
            logger.info("âœ… Created Optuna integration")
            return integration
            
        except ImportError as e:
            logger.error("Optuna is not installed. Please install with 'pip install optuna'")
            raise
        except Exception as e:
            logger.error(f"Failed to create Optuna integration: {e}")
            raise

    def create_pyfunc_wrapper(
        self, 
        trained_model: Any, 
        trained_datahandler: Any,
        trained_preprocessor: Optional[BasePreprocessor],
        trained_fetcher: Optional['BaseFetcher'],
        training_df: Optional[pd.DataFrame] = None,
        training_results: Optional[Dict[str, Any]] = None
    ) -> PyfuncWrapper:
        """ğŸ”„ Phase 5: ì™„ì „í•œ ìŠ¤í‚¤ë§ˆ ì •ë³´ê°€ ìº¡ìŠí™”ëœ Enhanced Artifact ìƒì„±"""
        from src.factory.artifact import PyfuncWrapper
        logger.info("Creating PyfuncWrapper artifact...")
        
        signature, data_schema = None, None
        if training_df is not None:
            logger.info("Generating model signature and data schema from training_df...")
            from src.utils.integrations.mlflow_integration import create_enhanced_model_signature_with_schema
            
            # âœ… ìƒˆë¡œìš´ êµ¬ì¡°ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            fetcher_conf = self._recipe.data.fetcher
            data_interface = self._recipe.data.data_interface
            
            # Timestamp ì»¬ëŸ¼ ì²˜ë¦¬
            ts_col = fetcher_conf.timestamp_column if fetcher_conf else None
            if ts_col and ts_col in training_df.columns:
                import pandas as pd
                if not pd.api.types.is_datetime64_any_dtype(training_df[ts_col]):
                    training_df = training_df.copy()
                    training_df[ts_col] = pd.to_datetime(training_df[ts_col], errors='coerce')

            # âœ… ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ data_interface_config êµ¬ì„±
            data_interface_config = {
                'entity_columns': data_interface.entity_columns,
                'timestamp_column': ts_col,
                'task_type': data_interface.task_type,
                'target_column': data_interface.target_column,
                'treatment_column': getattr(data_interface, 'treatment_column', None),
            }
            
            signature, data_schema = create_enhanced_model_signature_with_schema(
                training_df, 
                data_interface_config
            )
            logger.info("âœ… Signature and data schema created successfully.")
        
        return PyfuncWrapper(
            settings=self.settings,
            trained_model=trained_model,
            trained_datahandler=trained_datahandler,
            trained_preprocessor=trained_preprocessor,
            trained_fetcher=trained_fetcher,
            training_results=training_results,
            signature=signature,
            data_schema=data_schema,
        )
