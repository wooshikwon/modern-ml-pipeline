from __future__ import annotations

import functools
import importlib
from typing import TYPE_CHECKING, Any, Callable, ClassVar, Dict, Optional

import pandas as pd

from src.components.adapter import AdapterRegistry
from src.components.adapter.base import BaseAdapter
from src.components.calibration.calibration_evaluator import CalibrationEvaluator
from src.components.evaluator import EvaluatorRegistry
from src.components.fetcher import FetcherRegistry
from src.components.preprocessor import BasePreprocessor, Preprocessor
from src.settings import Settings
from src.utils.core.logger import log_fact, logger

if TYPE_CHECKING:
    from src.components.fetcher.base import BaseFetcher
    from src.utils.integrations.pyfunc_wrapper import PyfuncWrapper


def cached(cache_key_fn: Callable[..., str]):
    """
    Factory ë©”ì„œë“œì˜ ê²°ê³¼ë¥¼ ìºì‹±í•˜ëŠ” ë°ì½”ë ˆì´í„°.
    None ë°˜í™˜ê°’ì€ ìºì‹±í•˜ì§€ ì•ŠìŒ (ì„¤ì • ë¯¸ì™„ë£Œ ìƒíƒœë¥¼ ìºì‹±í•˜ì§€ ì•Šê¸° ìœ„í•¨).

    Args:
        cache_key_fn: ìºì‹œ í‚¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜. ë©”ì„œë“œ ì¸ìë¥¼ ë°›ì•„ ë¬¸ìì—´ ë°˜í™˜.

    ì‚¬ìš© ì˜ˆì‹œ:
        @cached(lambda adapter_type=None: f"adapter_{adapter_type or 'auto'}")
        def create_data_adapter(self, adapter_type: Optional[str] = None):
            ...
    """

    def decorator(method: Callable) -> Callable:
        @functools.wraps(method)
        def wrapper(self, *args, **kwargs) -> Any:
            key = cache_key_fn(*args, **kwargs)
            if key in self._component_cache:
                logger.debug(f"ìºì‹œëœ ì»´í¬ë„ŒíŠ¸ ë°˜í™˜: {key}")
                return self._component_cache[key]

            result = method(self, *args, **kwargs)
            # Noneì€ ìºì‹±í•˜ì§€ ì•ŠìŒ (ì„¤ì • ë¯¸ì™„ë£Œ ìƒíƒœ ì²˜ë¦¬)
            if result is not None:
                self._component_cache[key] = result
            return result

        return wrapper

    return decorator


class Factory:
    """
    3-Tier Component Architectureë¥¼ í†µí•œ MLOps ì»´í¬ë„ŒíŠ¸ ì¤‘ì•™ íŒ©í† ë¦¬ í´ë˜ìŠ¤.
    Recipe ì„¤ì •(settings.recipe)ì— ê¸°ë°˜í•˜ì—¬ ê³„ì¸µë³„ íŒ¨í„´ì— ë”°ë¼ ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Architecture Overview:
    =====================

    ğŸ”¹ Tier 1: Atomic Components (ì›ìì  ì»´í¬ë„ŒíŠ¸)
       - Registry Pattern: XXXRegistry.create()
       - ë‹¨ì¼ ì±…ì„, ë…ë¦½ì  ê¸°ëŠ¥
       - ì˜ˆ: Evaluator, Fetcher, DataAdapter, Calibrator

    ğŸ”¹ Tier 2: Composite Components (ì¡°í•©í˜• ì»´í¬ë„ŒíŠ¸)
       - Factory-aware Registry Pattern: XXXRegistry.create(..., factory_provider=self)
       - ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ë“¤ì— ëŒ€í•œ ì˜ì¡´ì„± í•„ìš”
       - ì˜ˆ: Trainer, DataHandler

    ğŸ”¹ Tier 3: Orchestrator Components (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì»´í¬ë„ŒíŠ¸)
       - Direct Instantiation Pattern: Class(settings=self.settings)
       - ë³µìˆ˜ì˜ í•˜ìœ„ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ë™ì  ì¡°í•©/ê´€ë¦¬
       - ì˜ˆ: Preprocessor (ë‹¤ìˆ˜ ì „ì²˜ë¦¬ ìŠ¤í… ì¡°í•©)

    ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´ê³¼ ìºì‹±ì„ í†µí•´ íš¨ìœ¨ì ì¸ ì»´í¬ë„ŒíŠ¸ ìƒì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """

    # í´ë˜ìŠ¤ ë³€ìˆ˜: ì»´í¬ë„ŒíŠ¸ ë“±ë¡ ìƒíƒœ ì¶”ì 
    _components_registered: ClassVar[bool] = False

    def __init__(self, settings: Settings):
        # ì»´í¬ë„ŒíŠ¸ ìë™ ë“±ë¡ (ìµœì´ˆ 1íšŒë§Œ)
        self._ensure_components_registered()

        self.settings = settings

        # Recipe êµ¬ì¡° ê²€ì¦
        if not self.settings.recipe:
            raise ValueError("Recipe êµ¬ì¡°ê°€ í•„ìš”í•©ë‹ˆë‹¤. settings.recipeê°€ ì—†ìŠµë‹ˆë‹¤.")

        # ìì£¼ ì‚¬ìš©í•˜ëŠ” ê²½ë¡œ ìºì‹± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´)
        self._recipe = settings.recipe
        self._config = settings.config
        self._data = self._recipe.data
        self._model = self._recipe.model

        # ìƒì„±ëœ ì»´í¬ë„ŒíŠ¸ ìºì‹±
        self._component_cache: Dict[str, Any] = {}

        # Factory ì´ˆê¸°í™” ì •ë³´ ë¡œê¹…
        log_fact(f"ì´ˆê¸°í™” ì™„ë£Œ - Recipe: {self._recipe.name}, Task: {self._recipe.task_choice}")

        # í™˜ê²½ ì„¤ì • ìš”ì•½ ì¶”ê°€
        env_name = (
            self._config.environment.name if hasattr(self._config, "environment") else "local"
        )
        data_source_type = (
            getattr(self._config.data_source, "adapter_type", "unknown")
            if hasattr(self._config, "data_source")
            else "unknown"
        )
        feature_store_provider = (
            self._config.feature_store.provider
            if hasattr(self._config, "feature_store") and self._config.feature_store
            else "none"
        )

        logger.debug(
            f"[FACT] í™˜ê²½ ì„¤ì • - Environment: {env_name}, DataSource: {data_source_type}, FeatureStore: {feature_store_provider}"
        )

    @classmethod
    def _ensure_components_registered(cls) -> None:
        """
        ì»´í¬ë„ŒíŠ¸ë“¤ì´ Registryì— ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , í•„ìš”ì‹œ ë“±ë¡í•©ë‹ˆë‹¤.
        ì´ ë©”ì„œë“œëŠ” Factory ì¸ìŠ¤í„´ìŠ¤ê°€ ì²˜ìŒ ìƒì„±ë  ë•Œ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        """
        # Check if calibration components are already registered
        from src.components.calibration.registry import CalibrationRegistry

        is_calibration_registered = bool(CalibrationRegistry.list_keys())

        if not cls._components_registered or not is_calibration_registered:
            # ì»´í¬ë„ŒíŠ¸ ëª¨ë“ˆë“¤ì„ importí•˜ì—¬ self-registration íŠ¸ë¦¬ê±°
            try:
                import src.components.adapter
                import src.components.calibration
                import src.components.datahandler
                import src.components.evaluator
                import src.components.fetcher
                import src.components.optimizer
                import src.components.preprocessor
                import src.components.trainer
            except ImportError as e:
                logger.warning(f"[FACT] ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

            cls._components_registered = True

    def _create_from_class_path(self, class_path: str, hyperparameters: Dict[str, Any]) -> Any:
        """
        í´ë˜ìŠ¤ ê²½ë¡œë¡œë¶€í„° ë™ì ìœ¼ë¡œ ê°ì²´ë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ.

        Args:
            class_path: ì „ì²´ í´ë˜ìŠ¤ ê²½ë¡œ (ì˜ˆ: 'sklearn.ensemble.RandomForestClassifier')
            hyperparameters: í´ë˜ìŠ¤ ì´ˆê¸°í™” íŒŒë¼ë¯¸í„°

        Returns:
            ìƒì„±ëœ ê°ì²´ ì¸ìŠ¤í„´ìŠ¤
        """
        try:
            module_path, class_name = class_path.rsplit(".", 1)
            module = importlib.import_module(module_path)
            model_class = getattr(module, class_name)

            # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²˜ë¦¬ (callable íŒŒë¼ë¯¸í„° ì²˜ë¦¬)
            processed_params = self._process_hyperparameters(hyperparameters)

            instance = model_class(**processed_params)
            logger.debug(f"[FACT] í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì™„ë£Œ - {class_path}")
            return instance

        except Exception as e:
            logger.error(f"[FACT] í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹¤íŒ¨ - {class_path}: {e}")
            raise ValueError(f"Could not load class: {class_path}") from e

    def _process_hyperparameters(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ì „ì²˜ë¦¬ (ë¬¸ìì—´ì„ ê°ì²´ë¡œ ë³€í™˜ ë“±)."""
        processed = params.copy()

        for key, value in processed.items():
            if isinstance(value, str) and "." in value and ("_fn" in key or "_class" in key):
                try:
                    module_path, func_name = value.rsplit(".", 1)
                    module = importlib.import_module(module_path)
                    processed[key] = getattr(module, func_name)
                    logger.debug(f"Hyperparameter '{key}'ë¥¼ callableë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤: {value}")
                except (ImportError, AttributeError):
                    logger.debug(f"Hyperparameter '{key}'ë¥¼ ë¬¸ìì—´ë¡œ ìœ ì§€í•©ë‹ˆë‹¤: {value}")

        return processed

    def _detect_adapter_type_from_uri(self, source_uri: str) -> str:
        """
        source_uri íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ì–´ëŒ‘í„° íƒ€ì…ì„ ìë™ìœ¼ë¡œ ê²°ì •í•©ë‹ˆë‹¤.

        íŒ¨í„´:
        - .sql íŒŒì¼ ë˜ëŠ” SQL ì¿¼ë¦¬ â†’ 'sql'
        - .csv, .parquet, .json â†’ 'storage'
        - s3://, gs://, az:// â†’ 'storage'
        - bigquery:// â†’ 'sql'
        """
        uri_lower = source_uri.lower()

        # SQL íŒ¨í„´
        if uri_lower.endswith(".sql") or "select" in uri_lower or "from" in uri_lower:
            return "sql"

        # BigQuery íŒ¨í„´ â†’ SQL adapterë¡œ í†µí•©
        if uri_lower.startswith("bigquery://"):
            return "sql"  # 'bigquery' ëŒ€ì‹  'sql' ë°˜í™˜

        # Cloud Storage íŒ¨í„´
        if any(uri_lower.startswith(prefix) for prefix in ["s3://", "gs://", "az://"]):
            return "storage"

        # File íŒ¨í„´
        if any(uri_lower.endswith(ext) for ext in [".csv", ".parquet", ".json", ".tsv"]):
            return "storage"

        # ê¸°ë³¸ê°’
        logger.warning(f"[FACT] URI íŒ¨í„´ ì¸ì‹ ì‹¤íŒ¨: {source_uri} -> storage ì–´ëŒ‘í„° ì‚¬ìš©")
        return "storage"

    # ===============================
    # Tier 1: Atomic Components
    # Registry Pattern - ë‹¨ì¼ ì±…ì„ ì»´í¬ë„ŒíŠ¸
    # ===============================

    @cached(lambda adapter_type=None: f"adapter_{adapter_type or 'auto'}")
    def create_data_adapter(self, adapter_type: Optional[str] = None) -> "BaseAdapter":
        """
        ë°ì´í„° ì–´ëŒ‘í„° ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Args:
            adapter_type: ëª…ì‹œì  ì–´ëŒ‘í„° íƒ€ì… (ì„ íƒì‚¬í•­)

        Returns:
            BaseAdapter ì¸ìŠ¤í„´ìŠ¤
        """
        # ì–´ëŒ‘í„° íƒ€ì… ê²°ì •
        if adapter_type:
            target_type = adapter_type
        else:
            # 1ìˆœìœ„: configì—ì„œ ëª…ì‹œëœ adapter_type ì‚¬ìš©
            config_adapter_type = getattr(self.settings.config.data_source, "adapter_type", None)
            if config_adapter_type:
                target_type = config_adapter_type
                logger.debug(f"[FACT] ì„¤ì •ëœ adapter ìœ í˜• ì‚¬ìš©: {target_type}")
            else:
                # 2ìˆœìœ„: source_uriì—ì„œ ìë™ ê°ì§€
                source_uri = self._data.loader.source_uri
                target_type = self._detect_adapter_type_from_uri(source_uri)
                logger.debug(f"[FACT] URIì—ì„œ adapter ìœ í˜• ìë™ ê°ì§€: {target_type}")

        # Registryë¥¼ í†µí•œ ìƒì„±
        try:
            adapter = AdapterRegistry.create(target_type, self.settings)
            return adapter
        except Exception as e:
            available = AdapterRegistry.list_keys()
            logger.error(f"'{target_type}' adapter ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Available: {available}")
            raise ValueError(
                f"Failed to create adapter '{target_type}'. Available: {available}"
            ) from e

    @cached(lambda run_mode=None: f"fetcher_{(run_mode or 'batch').lower()}")
    def create_fetcher(self, run_mode: Optional[str] = None) -> "BaseFetcher":
        """
        Fetcher ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Args:
            run_mode: ì‹¤í–‰ ëª¨ë“œ (batch/serving)

        Returns:
            BaseFetcher ì¸ìŠ¤í„´ìŠ¤
        """
        mode = (run_mode or "batch").lower()

        # ì„¤ì • ì ‘ê·¼
        provider = (
            self.settings.config.feature_store.provider
            if self.settings.config.feature_store
            else "none"
        )
        fetch_conf = self._recipe.data.fetcher if hasattr(self._recipe.data, "fetcher") else None
        fetch_type = fetch_conf.type if fetch_conf else None

        # serving ëª¨ë“œ ê²€ì¦
        if mode == "serving":
            if fetch_type in (None, "pass_through") or provider in (None, "none"):
                raise TypeError(
                    "Serving ëª¨ë“œì—ì„œëŠ” Feature Store ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤. "
                    "pass_through ë˜ëŠ” feature_store ë¯¸êµ¬ì„±ì€ í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )

        # Fetcher ìƒì„±: í™˜ê²½ì´ ì•„ë‹Œ ëª…ì‹œì  ì„¤ì •(provider, fetch_type)ìœ¼ë¡œ ê²°ì •
        try:
            if provider == "none" or fetch_type == "pass_through" or not fetch_conf:
                fetcher = FetcherRegistry.create("pass_through")
            elif fetch_type == "feature_store" and provider in {"feast", "mock", "dynamic"}:
                fetcher = FetcherRegistry.create(fetch_type, settings=self.settings, factory=self)
            else:
                raise ValueError(
                    f"ì ì ˆí•œ fetcherë¥¼ ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                    f"provider={provider}, fetch_type={fetch_type}, mode={mode}"
                )

            return fetcher

        except Exception as e:
            logger.error(f"Fetcher ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e} (mode={mode}, provider={provider})")
            raise

    @cached(lambda: "evaluator")
    def create_evaluator(self) -> Any:
        """
        Evaluator ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Returns:
            Evaluator ì¸ìŠ¤í„´ìŠ¤
        """
        task_choice = self._recipe.task_choice

        try:
            evaluator = EvaluatorRegistry.create(task_choice, self.settings)
            return evaluator

        except Exception:
            available = EvaluatorRegistry.list_keys()
            logger.error(
                f"'{task_choice}'ì— ëŒ€í•œ Evaluator ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Available: {available}"
            )
            raise

    @cached(lambda method=None: f"calibrator_{method or 'default'}")
    def create_calibrator(self, method: Optional[str] = None) -> Optional[Any]:
        """
        Calibrator ìƒì„± (ì¡°ê±´ì— ë”°ë¥¸ ìƒì„± ë¶„ê¸° ì²˜ë¦¬).

        Args:
            method: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°©ë²• ('beta', 'isotonic' ë“±)

        Returns:
            BaseCalibrator ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
        """
        # Taskì™€ calibration ì„¤ì • í™•ì¸
        task_type = self._recipe.task_choice
        calibration_config = getattr(self._recipe.model, "calibration", None)

        if not calibration_config or not getattr(calibration_config, "enabled", False):
            logger.debug("[FACT] Calibration ë¹„í™œì„±í™” - ìŠ¤í‚µ")
            return None

        if task_type != "classification":
            logger.debug(f"[FACT] {task_type} taskì—ì„œëŠ” Calibration ë¯¸ì§€ì› - ìŠ¤í‚µ")
            return None

        # Method ê²°ì •
        calibration_method = method or getattr(calibration_config, "method", None)
        if not calibration_method:
            raise ValueError(
                "Calibration methodê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                "Recipeì—ì„œ model.calibration.methodë¥¼ ì„¤ì •í•˜ì„¸ìš”. "
                "ì‚¬ìš© ê°€ëŠ¥: 'beta', 'isotonic', 'temperature'"
            )

        try:
            from src.components.calibration.registry import CalibrationRegistry

            calibrator = CalibrationRegistry.create(calibration_method)
            return calibrator

        except Exception:
            from src.components.calibration.registry import CalibrationRegistry

            available = CalibrationRegistry.list_keys()
            logger.error(
                f"'{calibration_method}' Calibrator ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Available: {available}"
            )
            raise

    @cached(lambda: "feature_store_adapter")
    def create_feature_store_adapter(self) -> "BaseAdapter":
        """
        Feature Store ì–´ëŒ‘í„° ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Returns:
            Feature Store ì–´ëŒ‘í„° ì¸ìŠ¤í„´ìŠ¤
        """
        # ê²€ì¦
        if not self.settings.config.feature_store:
            raise ValueError("Feature Store settings are not configured.")

        try:
            adapter = AdapterRegistry.create("feature_store", self.settings)
            return adapter

        except Exception as e:
            logger.error(f"Feature Store adapter ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            raise

    # ===============================
    # Tier 2: Composite Components
    # Factory-aware Registry Pattern - ì˜ì¡´ì„± ì£¼ì…ì´ í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸
    # ===============================

    @cached(lambda trainer_type=None: f"trainer_{trainer_type or 'default'}")
    def create_trainer(self, trainer_type: Optional[str] = None) -> Any:
        """
        Trainer ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Args:
            trainer_type: íŠ¸ë ˆì´ë„ˆ íƒ€ì… (Noneì´ë©´ 'default' ì‚¬ìš©)

        Returns:
            Trainer ì¸ìŠ¤í„´ìŠ¤
        """
        from src.components.trainer import TrainerRegistry

        trainer_type = trainer_type or "default"

        try:
            trainer = TrainerRegistry.create(
                trainer_type, settings=self.settings, factory_provider=lambda: self
            )
            return trainer

        except Exception:
            available = TrainerRegistry.list_keys()
            logger.error(f"'{trainer_type}' Trainer ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Available: {available}")
            raise

    @cached(lambda: "datahandler")
    def create_datahandler(self) -> Any:
        """
        DataHandler ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).
        task_typeì— ë”°ë¼ ì ì ˆí•œ DataHandlerë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.

        Returns:
            BaseDataHandler ì¸ìŠ¤í„´ìŠ¤
        """
        from src.components.datahandler import DataHandlerRegistry

        task_choice = self._recipe.task_choice

        try:
            model_class_path = getattr(self._recipe.model, "class_path", None)
            datahandler = DataHandlerRegistry.get_handler_for_task(
                task_choice, self.settings, model_class_path=model_class_path
            )
            return datahandler

        except Exception:
            available = DataHandlerRegistry.list_keys()
            logger.error(
                f"'{task_choice}'ì— ëŒ€í•œ DataHandler ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Available: {available}"
            )
            raise

    # ===============================
    # Tier 3: Orchestrator Components
    # Direct Instantiation Pattern - ë³µì¡í•œ ì¡°í•© ë¡œì§ì„ ë‚´ì¥í•œ ì»´í¬ë„ŒíŠ¸
    # ===============================

    @cached(lambda: "preprocessor")
    def create_preprocessor(self) -> Optional[BasePreprocessor]:
        """
        Preprocessor ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Returns:
            BasePreprocessor ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” None
        """
        preprocessor_config = getattr(self._recipe, "preprocessor", None)

        if not preprocessor_config:
            return None

        try:
            preprocessor = Preprocessor(settings=self.settings)
            return preprocessor

        except Exception as e:
            logger.error(f"Preprocessor ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            raise

    # ===============================
    # Specialized Creation Methods
    # Recipe êµ¬ì¡° ê¸°ë°˜ ë™ì  ìƒì„± - ì„¤ì •ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ìƒì„±
    # ===============================

    @cached(lambda: "model")
    def create_model(self) -> Any:
        """
        Model ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Returns:
            ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        """
        class_path = self._model.class_path

        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ (tuning ë©”íƒ€ë°ì´í„° ì œì™¸)
        hyperparameters = {}
        if hasattr(self._model.hyperparameters, "tuning_enabled"):
            if self._model.hyperparameters.tuning_enabled:
                # íŠœë‹ í™œì„±í™”ì‹œ: fixed íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©
                if (
                    hasattr(self._model.hyperparameters, "fixed")
                    and self._model.hyperparameters.fixed
                ):
                    hyperparameters = self._model.hyperparameters.fixed.copy()
            else:
                # íŠœë‹ ë¹„í™œì„±í™”ì‹œ: values íŒŒë¼ë¯¸í„° ì‚¬ìš©
                if (
                    hasattr(self._model.hyperparameters, "values")
                    and self._model.hyperparameters.values
                ):
                    hyperparameters = self._model.hyperparameters.values.copy()
        else:
            # ë ˆê±°ì‹œ êµ¬ì¡°: ì „ì²´ dictì—ì„œ tuning ë©”íƒ€ë°ì´í„° ì œì™¸
            hyperparameters = (
                dict(self._model.hyperparameters)
                if hasattr(self._model.hyperparameters, "__dict__")
                else {}
            )
            tuning_keys = [
                "tuning_enabled",
                "optimization_metric",
                "direction",
                "n_trials",
                "timeout",
                "fixed",
                "tunable",
                "values",
            ]
            for key in tuning_keys:
                hyperparameters.pop(key, None)

        try:
            model = self._create_from_class_path(class_path, hyperparameters)
            return model

        except Exception as e:
            logger.error(f"{class_path}ì—ì„œ Model ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            raise

    # ===============================
    # Specialized Creation Methods
    # Recipe êµ¬ì¡° ê¸°ë°˜ ë™ì  ìƒì„± - ì„¤ì •ì— ë”°ë¥¸ ì¡°ê±´ë¶€ ìƒì„±
    # ===============================

    @cached(lambda: "optuna_integration")
    def create_optuna_integration(self) -> Any:
        """
        Optuna Integration ìƒì„± (ì¼ê´€ëœ ì ‘ê·¼ íŒ¨í„´).

        Returns:
            OptunaIntegration ì¸ìŠ¤í„´ìŠ¤
        """
        tuning_config = getattr(self._model, "hyperparameters", None)

        if not tuning_config:
            raise ValueError("Hyperparameter tuning settings are not configured.")

        try:
            from src.utils.integrations.optuna_integration import OptunaIntegration

            integration = OptunaIntegration(tuning_config)
            return integration

        except ImportError:
            logger.error("Optunaê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install optunaë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”")
            raise
        except Exception as e:
            logger.error(f"Optuna integration ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            raise

    def create_calibration_evaluator(self, trained_model, trained_calibrator) -> Optional[Any]:
        """
        Calibration Evaluator ìƒì„± ë° ì‹¤í–‰ (ëª¨ë“  ë³µì¡í•œ ë¡œì§ ì²˜ë¦¬)

        Args:
            trained_model: í•™ìŠµëœ ëª¨ë¸
            trained_calibrator: í•™ìŠµëœ calibrator

        Returns:
            Calibration metrics ë˜ëŠ” None
        """
        # Taskì™€ calibrator í™•ì¸
        task_type = self._recipe.task_choice
        if task_type != "classification" or not trained_calibrator:
            return None

        # ëª¨ë¸ì´ predict_probaë¥¼ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸
        if not hasattr(trained_model, "predict_proba"):
            logger.warning("Modelì´ predict_probaë¥¼ ì§€ì›í•˜ì§€ ì•Šì•„ calibration í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
            return None

        return CalibrationEvaluator(trained_model, trained_calibrator)

    def create_pyfunc_wrapper(
        self,
        trained_model: Any,
        trained_datahandler: Any,
        trained_preprocessor: Optional[BasePreprocessor],
        trained_fetcher: Optional["BaseFetcher"],
        trained_calibrator: Optional[Any] = None,
        training_df: Optional[pd.DataFrame] = None,
        training_results: Optional[Dict[str, Any]] = None,
    ) -> PyfuncWrapper:
        """PyfuncWrapper ìƒì„± (PyfuncFactory ìœ„ì„)"""
        from src.factory.pyfunc_factory import PyfuncFactory

        pyfunc_factory = PyfuncFactory(self.settings, self._recipe)
        return pyfunc_factory.create(
            trained_model=trained_model,
            trained_datahandler=trained_datahandler,
            trained_preprocessor=trained_preprocessor,
            trained_fetcher=trained_fetcher,
            trained_calibrator=trained_calibrator,
            training_df=training_df,
            training_results=training_results,
        )
