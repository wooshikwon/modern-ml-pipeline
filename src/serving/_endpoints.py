# src/serving/_endpoints.py

import logging
from typing import Any, Dict

import numpy as np
import pandas as pd
from fastapi import HTTPException

from src.serving._context import app_context
from src.serving.schemas import (
    BatchPredictionResponse,
    HealthCheckResponse,
    HyperparameterOptimizationInfo,
    ModelMetadataResponse,
    OptimizationHistoryResponse,
    ReadyCheckResponse,
    TrainingMethodologyInfo,
)
from src.utils.data.data_io import format_predictions

logger = logging.getLogger(__name__)


def _convert_to_signature_types(df: pd.DataFrame, model: Any) -> pd.DataFrame:
    """
    MLflow Signatureì— ì •ì˜ëœ íƒ€ì…ì— ë§ê²Œ DataFrame ì»¬ëŸ¼ íƒ€ì…ì„ ë³€í™˜.
    int64 â†’ float64, float â†’ int64 ë“± í•„ìš”í•œ ë³€í™˜ ìˆ˜í–‰.
    """
    if model is None:
        return df

    try:
        metadata = getattr(model, "metadata", None)
        if metadata is None:
            return df

        sig = getattr(metadata, "signature", None)
        if sig is None:
            return df

        schema_inputs = getattr(sig, "inputs", None)
        if schema_inputs is None:
            return df

        col_specs = getattr(schema_inputs, "inputs", None)
        if col_specs is None:
            return df

        for col_spec in col_specs:
            col_name = getattr(col_spec, "name", None)
            col_type_raw = getattr(col_spec, "type", None)

            if col_name is None or col_type_raw is None:
                continue

            if col_name not in df.columns:
                continue

            # íƒ€ì… ë¬¸ìì—´ ì •ê·œí™” (DataType.double â†’ double)
            col_type = str(col_type_raw).lower()
            if "." in col_type:
                col_type = col_type.split(".")[-1]

            current_dtype = str(df[col_name].dtype)

            # float/double íƒ€ì… ë³€í™˜ (int â†’ float)
            if col_type in ("double", "float", "float64", "float32"):
                if "int" in current_dtype or "object" in current_dtype:
                    df[col_name] = pd.to_numeric(df[col_name], errors="coerce").astype("float64")
                    logger.debug(f"[TYPE] '{col_name}': {current_dtype} â†’ float64")

            # int/long íƒ€ì… ë³€í™˜ (float â†’ int)
            elif col_type in ("integer", "long", "int64", "int32"):
                if "float" in current_dtype:
                    df[col_name] = df[col_name].astype("int64")
                    logger.debug(f"[TYPE] '{col_name}': {current_dtype} â†’ int64")
                elif "object" in current_dtype:
                    df[col_name] = pd.to_numeric(df[col_name], errors="coerce").astype("int64")
                    logger.debug(f"[TYPE] '{col_name}': {current_dtype} â†’ int64")

    except Exception as e:
        logger.warning(f"[TYPE] Signature ê¸°ë°˜ íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")

    return df


def health() -> HealthCheckResponse:
    """
    Liveness ì²´í¬ (K8s livenessProbeìš©).
    í”„ë¡œì„¸ìŠ¤ ìƒì¡´ ì—¬ë¶€ë§Œ í™•ì¸í•˜ëŠ” ê²½ëŸ‰ ì—”ë“œí¬ì¸íŠ¸.
    ëª¨ë¸ ë¡œë“œ ìƒíƒœì™€ ë¬´ê´€í•˜ê²Œ í•­ìƒ 200 ë°˜í™˜.
    """
    return HealthCheckResponse(status="ok")


def ready() -> ReadyCheckResponse:
    """
    Readiness ì²´í¬ (K8s readinessProbeìš©).
    ëª¨ë¸ì´ ë¡œë“œë˜ì–´ íŠ¸ë˜í”½ì„ ë°›ì„ ì¤€ë¹„ê°€ ë˜ì—ˆëŠ”ì§€ í™•ì¸.
    """
    if not app_context.model or not app_context.settings:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    model_info = "unknown"
    try:
        wrapped_model = app_context.model.unwrap_python_model()
        model_info = getattr(wrapped_model, "model_class_path", "unknown")
    except Exception:
        pass

    return ReadyCheckResponse(
        status="ready",
        model_uri=app_context.model_uri,
        model_name=model_info,
    )


def predict_batch(request: Dict[str, Any]) -> BatchPredictionResponse:
    validated_request = app_context.BatchPredictionRequest(**request)

    input_df = pd.DataFrame([sample.model_dump() for sample in validated_request.samples])
    if input_df.empty:
        raise HTTPException(status_code=400, detail="ì…ë ¥ ìƒ˜í”Œì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    # ì…ë ¥ ê°’ ìŠ¤ì¹¼ë¼ ê²€ì¦ (list/dict ë“± ë¹„ìŠ¤ì¹¼ë¼ ê±°ë¶€)
    for col in input_df.columns:
        if input_df[col].apply(lambda v: isinstance(v, (list, dict))).any():
            raise HTTPException(
                status_code=422, detail=f"ì»¬ëŸ¼ '{col}'ì— ë¹„ìŠ¤ì¹¼ë¼ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            )

    # ìˆ«ìí˜• ì»¬ëŸ¼ íƒ€ì… ê²€ì¦: í•™ìŠµ ì‹œê·¸ë‹ˆì²˜/ë°ì´í„°ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ float/int ê¸°ëŒ€ ì»¬ëŸ¼ì€ ë¬¸ìì—´ ë“± ë¹„ìˆ˜ì¹˜ ê±°ë¶€
    try:
        wrapped = app_context.model.unwrap_python_model()
        di = getattr(wrapped, "data_interface_schema", {}) or {}
        # data_interface_schemaëŠ” top-levelì— feature_columns í¬í•¨
        feature_cols = set(di.get("feature_columns") or [])

        # MLflow Signatureì—ì„œ ë³´ì™„
        sig = getattr(getattr(app_context.model, "metadata", None), "signature", None)
        schema_inputs = getattr(sig, "inputs", None)
        if schema_inputs is not None and hasattr(schema_inputs, "inputs"):
            cols = getattr(schema_inputs, "inputs", []) or []
            for c in cols:
                name = getattr(c, "name", None)
                if name:
                    feature_cols.add(name)

        expected_numeric_cols = set()
        if schema_inputs is not None and hasattr(schema_inputs, "inputs"):
            for c in getattr(schema_inputs, "inputs", []) or []:
                name = getattr(c, "name", None)
                t = getattr(c, "type", None)
                if name and t and str(t).lower() in ("double", "float", "integer", "long"):
                    expected_numeric_cols.add(name)

        # feature ì»¬ëŸ¼ ë‚´ ìˆ«ìí˜• ê¸°ëŒ€ ì»¬ëŸ¼ ê²€ì¦
        for col in feature_cols or input_df.columns:
            if col in input_df.columns and (
                not expected_numeric_cols or col in expected_numeric_cols
            ):
                val_is_numeric = (
                    input_df[col]
                    .apply(lambda v: isinstance(v, (int, float)) and np.isfinite(v))
                    .all()
                )
                if not val_is_numeric:
                    raise HTTPException(
                        status_code=422, detail=f"ì»¬ëŸ¼ '{col}'ì€ ìˆ«ìí˜•ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                    )
    except Exception:
        # ì‹œê·¸ë‹ˆì²˜ë¥¼ ì½ì§€ ëª»í•˜ë”ë¼ë„ ë™ì‘ì€ ê³„ì† (MLflow ë‚´ë¶€ ê²€ì¦ì´ 2ì°¨ ë°©ì–´)
        pass

    # MLflow ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„±ì„ ìœ„í•œ ë°ì´í„° íƒ€ì… ë³€í™˜
    input_df = _convert_to_signature_types(input_df, app_context.model)

    # í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ê²€ì¦
    # Feature Store fetcher ì‚¬ìš© ì‹œ: entity_columnsë§Œ í•„ìˆ˜ (ë‚˜ë¨¸ì§€ëŠ” Online Storeì—ì„œ ì¦ê°•)
    # pass_through fetcher ì‚¬ìš© ì‹œ: ëª¨ë“  feature_columns í•„ìˆ˜
    try:
        required_cols = set()
        wrapped = app_context.model.unwrap_python_model()
        di = getattr(wrapped, "data_interface_schema", {}) or {}
        trained_fetcher = getattr(wrapped, "trained_fetcher", None)

        # Fetcher ìœ ë¬´ì— ë”°ë¼ í•„ìˆ˜ ì»¬ëŸ¼ ê²°ì •
        has_feature_store_fetcher = trained_fetcher is not None and hasattr(
            trained_fetcher, "_fetcher_config"
        )

        if has_feature_store_fetcher:
            # Feature Store fetcher: entity_columnsë§Œ í•„ìˆ˜ (featureëŠ” Online Storeì—ì„œ ì¡°íšŒ)
            entity_cols = di.get("entity_columns", [])
            required_cols.update(entity_cols)
        else:
            # pass_through ë˜ëŠ” fetcher ì—†ìŒ: entity + feature_columns í•„ìˆ˜
            required_cols.update(di.get("required_columns", []) or [])

        missing = [c for c in sorted(required_cols) if c not in input_df.columns]
        if missing:
            raise HTTPException(status_code=422, detail=f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    except HTTPException:
        raise
    except Exception:
        pass

    predict_params = {"run_mode": "serving", "return_intermediate": False, "return_dataframe": True}
    raw_predictions_df = app_context.model.predict(input_df, params=predict_params)

    # Inference íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•˜ê²Œ data_interface ê¸°ë°˜ í¬ë§· ì ìš©
    wrapped_model = app_context.model.unwrap_python_model()
    data_interface_schema = getattr(wrapped_model, "data_interface_schema", {}) or {}
    # format_predictionsì— ì „ì²´ schema ì „ë‹¬ (top-levelì— ëª¨ë“  í•„ë“œ í¬í•¨)
    predictions_df = format_predictions(raw_predictions_df, input_df, data_interface_schema)

    # JSON ì§ë ¬í™” í˜¸í™˜ì„ ìœ„í•´ numpy ìŠ¤ì¹¼ë¼ë¥¼ íŒŒì´ì¬ ê¸°ë³¸í˜•ìœ¼ë¡œ ë³€í™˜
    def _to_py(x):
        return x.item() if isinstance(x, np.generic) else x

    predictions_df = predictions_df.map(_to_py)

    # ì¶œë ¥ ê°’ ìœ í•œì„± ê²€ì¦: NaN/Inf í¬í•¨ ì‹œ 422 ë°˜í™˜
    def _is_non_finite(val: Any) -> bool:
        try:
            return isinstance(val, (float, int)) and (not np.isfinite(val))
        except Exception:
            return False

    # ì£¼ìš” ì˜ˆì¸¡ ì»¬ëŸ¼ë“¤ ì ê²€
    if predictions_df.map(_is_non_finite).any().any():
        raise HTTPException(
            status_code=422, detail="ì˜ˆì¸¡ ê²°ê³¼ì— ë¹„ìœ í•œ ê°’(NaN/Inf)ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
        )

    return BatchPredictionResponse(
        predictions=predictions_df.to_dict(orient="records"),
        model_uri=app_context.model_uri,
        sample_count=len(predictions_df),
    )


def get_model_metadata() -> ModelMetadataResponse:
    if app_context.model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    hpo_info = getattr(app_context.model, "hyperparameter_optimization", {}) or {}
    hyperparameter_optimization = HyperparameterOptimizationInfo(
        enabled=hpo_info.get("enabled", False),
        engine=hpo_info.get("engine", ""),
        best_params=hpo_info.get("best_params", {}),
        best_score=hpo_info.get("best_score", 0.0),
        total_trials=hpo_info.get("total_trials", 0),
        pruned_trials=hpo_info.get("pruned_trials", 0),
        optimization_time=str(hpo_info.get("optimization_time", "")),
    )

    tm_info = getattr(app_context.model, "training_methodology", {}) or {}
    training_methodology = TrainingMethodologyInfo(
        train_test_split_method=tm_info.get("train_test_split_method", ""),
        train_ratio=tm_info.get("train_ratio", 0.8),
        validation_strategy=tm_info.get("validation_strategy", ""),
        preprocessing_fit_scope=tm_info.get("preprocessing_fit_scope", ""),
        random_state=tm_info.get("random_state", 42),
    )

    # ğŸ†• Phase 5.5: DataInterface ê¸°ë°˜ API ìŠ¤í‚¤ë§ˆ ì •ë³´ í–¥ìƒ
    wrapped_model = app_context.model.unwrap_python_model()
    data_interface_schema = getattr(wrapped_model, "data_interface_schema", None)

    api_schema = {
        "input_fields": list(app_context.PredictionRequest.model_fields.keys()),
    }

    if data_interface_schema:
        api_schema.update(
            {
                "schema_generation_method": "datainterface_based",
                "entity_columns": data_interface_schema.get("entity_columns", []),
                "required_columns": data_interface_schema.get("required_columns", []),
                "task_type": data_interface_schema.get("task_type", ""),
            }
        )
    else:
        api_schema["schema_generation_method"] = "legacy_sql_parsing"

    return ModelMetadataResponse(
        model_uri=app_context.model_uri,
        model_class_path=getattr(app_context.model, "model_class_path", ""),
        hyperparameter_optimization=hyperparameter_optimization,
        training_methodology=training_methodology,
        api_schema=api_schema,
    )


def get_optimization_history() -> OptimizationHistoryResponse:
    if app_context.model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    hpo_info = getattr(app_context.model, "hyperparameter_optimization", {}) or {}

    if not hpo_info.get("enabled", False):
        return OptimizationHistoryResponse(
            enabled=False,
            optimization_history=[],
            search_space={},
            convergence_info={"message": "í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤."},
        )

    return OptimizationHistoryResponse(
        enabled=True,
        optimization_history=hpo_info.get("optimization_history", []),
        search_space=hpo_info.get("search_space", {}),
        convergence_info={
            "best_score": hpo_info.get("best_score", 0.0),
            "total_trials": hpo_info.get("total_trials", 0),
            "pruned_trials": hpo_info.get("pruned_trials", 0),
            "optimization_time": str(hpo_info.get("optimization_time", "")),
        },
    )


def get_api_schema() -> Dict[str, Any]:
    if app_context.model is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # ğŸ†• Phase 5.5: DataInterface ìŠ¤í‚¤ë§ˆ ì •ë³´ í¬í•¨
    wrapped_model = app_context.model.unwrap_python_model()
    data_interface_schema = getattr(wrapped_model, "data_interface_schema", None)

    schema_info = {
        "prediction_request_schema": app_context.PredictionRequest.model_json_schema(),
        "batch_prediction_request_schema": app_context.BatchPredictionRequest.model_json_schema(),
        "loader_sql_snapshot": getattr(wrapped_model, "loader_sql_snapshot", ""),
    }

    # DataInterface ìŠ¤í‚¤ë§ˆê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì •ë³´ ì œê³µ
    if data_interface_schema:
        schema_info.update(
            {
                "data_interface_schema": data_interface_schema,
                "schema_generation_method": "datainterface_based",
                "required_columns": data_interface_schema.get("required_columns", []),
                "entity_columns": data_interface_schema.get("entity_columns", []),
                "task_type": data_interface_schema.get("task_type", ""),
            }
        )
    else:
        schema_info["schema_generation_method"] = "legacy_sql_parsing"

    return schema_info


def predict(request: Dict[str, Any]) -> Dict[str, Any]:
    request_df = pd.DataFrame([request])

    # DataInterface ê¸°ë°˜ PredictionRequest ìŠ¤í‚¤ë§ˆë¡œ í•„ìˆ˜ ì»¬ëŸ¼ ì„ ì œ ê²€ì¦
    try:
        pr_fields = getattr(app_context.PredictionRequest, "model_fields", {})
        if pr_fields:
            required_cols = set(pr_fields.keys())
            missing = [c for c in sorted(required_cols) if c not in request_df.columns]
            if missing:
                raise HTTPException(status_code=422, detail=f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    except HTTPException:
        raise
    except Exception:
        pass

    # MLflow ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„±ì„ ìœ„í•œ ë°ì´í„° íƒ€ì… ë³€í™˜
    request_df = _convert_to_signature_types(request_df, app_context.model)

    # ì…ë ¥ ê°’ ìŠ¤ì¹¼ë¼ ê²€ì¦ (list/dict ë“± ë¹„ìŠ¤ì¹¼ë¼ ê±°ë¶€)
    for col in request_df.columns:
        val = request_df.iloc[0][col]
        if isinstance(val, (list, dict)):
            raise HTTPException(
                status_code=422, detail=f"ì»¬ëŸ¼ '{col}'ì— ë¹„ìŠ¤ì¹¼ë¼ ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            )
    # ìˆ«ìí˜• ì»¬ëŸ¼ íƒ€ì… ê²€ì¦: í•™ìŠµ ì‹œê·¸ë‹ˆì²˜ ê¸°ë°˜ìœ¼ë¡œ float/int ê¸°ëŒ€ ì»¬ëŸ¼ì€ ë¬¸ìì—´ ë“± ë¹„ìˆ˜ì¹˜ ê±°ë¶€
    try:
        signature_input = getattr(
            getattr(app_context.model, "metadata", None), "get_input_schema", None
        )
        expected_numeric_cols = set()
        if callable(signature_input):
            schema = signature_input()
            for col in getattr(schema, "inputs", []) or []:
                t = getattr(col, "type", None)
                name = getattr(col, "name", None)
                if name and t and str(t).lower() in ("double", "float", "integer", "long"):
                    expected_numeric_cols.add(name)
        for col in request_df.columns:
            if col in expected_numeric_cols:
                val = request_df.iloc[0][col]
                if not (isinstance(val, (int, float)) and np.isfinite(val)):
                    raise HTTPException(
                        status_code=422, detail=f"ì»¬ëŸ¼ '{col}'ì€ ìˆ«ìí˜•ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
                    )
    except Exception:
        pass

    # í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ê²€ì¦: MLflow signature ê¸°ë°˜
    try:
        required_cols = set()
        sig = getattr(getattr(app_context.model, "metadata", None), "signature", None)
        schema_inputs = getattr(sig, "inputs", None)
        if schema_inputs is not None:
            # Try input_names() if available
            try:
                if hasattr(schema_inputs, "input_names") and callable(
                    getattr(schema_inputs, "input_names", None)
                ):
                    for n in schema_inputs.input_names():
                        required_cols.add(n)
            except Exception:
                pass
            # Fallback to inputs list
            if not required_cols and hasattr(schema_inputs, "inputs"):
                for c in getattr(schema_inputs, "inputs", []) or []:
                    name = getattr(c, "name", None)
                    if name:
                        required_cols.add(name)
        missing = [c for c in sorted(required_cols) if c not in request_df.columns]
        if missing:
            raise HTTPException(status_code=422, detail=f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
    except HTTPException:
        raise
    except Exception:
        pass

    # ì„œë¹™ ê²½ë¡œ ê°•ì œ + DataFrame ë°˜í™˜ ë³´ì¥
    raw_predictions_df = app_context.model.predict(
        request_df,
        params={"run_mode": "serving", "return_intermediate": False, "return_dataframe": True},
    )

    # Inference íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ í¬ë§· ì ìš©
    wrapped_model = app_context.model.unwrap_python_model()
    data_interface_schema = getattr(wrapped_model, "data_interface_schema", {}) or {}
    # format_predictionsì— ì „ì²´ schema ì „ë‹¬ (top-levelì— ëª¨ë“  í•„ë“œ í¬í•¨)
    predictions_df = format_predictions(raw_predictions_df, request_df, data_interface_schema)

    # ìµœì†Œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜ (numpy ìŠ¤ì¹¼ë¼ â†’ íŒŒì´ì¬ ê¸°ë³¸í˜•)
    if hasattr(predictions_df, "iloc") and "prediction" in predictions_df.columns:
        value = predictions_df.iloc[0]["prediction"]
    elif hasattr(predictions_df, "iloc") and predictions_df.shape[1] >= 1:
        value = predictions_df.iloc[0, 0]
    else:
        value = None

    if isinstance(value, np.generic):
        value = value.item()

    # ì¶œë ¥ ìœ í•œì„± ê²€ì¦: NaN/Infì´ë©´ 422
    try:
        if isinstance(value, (int, float)) and not np.isfinite(value):
            raise HTTPException(status_code=422, detail="ì˜ˆì¸¡ ê²°ê³¼ê°€ ë¹„ìœ í•œ ê°’(NaN/Inf)ì…ë‹ˆë‹¤.")
    except Exception:
        pass

    return {"prediction": value, "model_uri": app_context.model_uri}
