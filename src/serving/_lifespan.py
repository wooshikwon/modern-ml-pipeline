# src/serving/lifespan.py

from contextlib import asynccontextmanager

import mlflow
from fastapi import FastAPI

from src.factory import bootstrap
from src.serving._context import app_context
from src.serving.schemas import (
    create_batch_prediction_request,
    create_datainterface_based_prediction_request_v2,
    create_dynamic_prediction_request,
)
from src.settings import Settings
from src.utils.core.logger import logger
from src.utils.database.sql_utils import parse_select_columns


def setup_api_context(run_id: str, settings: Settings):
    """ì„œë²„ ì‹œì‘ ì‹œ API ì»¨í…ìŠ¤íŠ¸ë¥¼ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # ë¶€íŠ¸ìŠ¤íŠ¸ë©: ë ˆì§€ìŠ¤íŠ¸ë¦¬/ì˜ì¡´ì„± ê²€ì¦ ë³´ì¥
        bootstrap(settings)
        model_uri = f"runs:/{run_id}/model"
        app_context.model = mlflow.pyfunc.load_model(model_uri)
        app_context.model_uri = model_uri
        app_context.settings = settings

        wrapped_model = app_context.model.unwrap_python_model()

        # ğŸ†• Phase 5.5: DataInterface ê¸°ë°˜ API ìŠ¤í‚¤ë§ˆ ìƒì„± (ìš°ì„ ìˆœìœ„)
        data_interface_schema = getattr(wrapped_model, "data_interface_schema", None)
        if data_interface_schema:
            # DataInterface ìŠ¤í‚¤ë§ˆë¥¼ ì‚¬ìš©í•˜ì—¬ API ìŠ¤í‚¤ë§ˆ ìƒì„± (ê°€ì¥ ì •í™•í•¨)
            # V2 ë²„ì „ ì‚¬ìš©: target_column ìë™ ì œì™¸
            logger.info("DataInterface ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ API ìŠ¤í‚¤ë§ˆ ìƒì„± (target_column ìë™ ì œì™¸)")
            app_context.PredictionRequest = create_datainterface_based_prediction_request_v2(
                model_name="DataInterfacePredictionRequest",
                data_interface_schema=data_interface_schema,
                exclude_target=True,  # target_column ìë™ ì œì™¸
            )
        else:
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ (data_schema ë˜ëŠ” SQL íŒŒì‹±)
            logger.warning("âš ï¸ DataInterface ìŠ¤í‚¤ë§ˆ ì—†ìŒ - ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±")
            data_schema = getattr(wrapped_model, "data_schema", None)
            if isinstance(data_schema, dict) and data_schema.get("entity_columns"):
                pk_fields = list(data_schema.get("entity_columns") or [])
            else:
                loader_sql = getattr(
                    wrapped_model, "loader_sql_snapshot", "SELECT user_id FROM DUAL"
                )
                pk_fields = parse_select_columns(loader_sql)

            app_context.PredictionRequest = create_dynamic_prediction_request(
                model_name="DynamicPredictionRequest", pk_fields=pk_fields
            )
        app_context.BatchPredictionRequest = create_batch_prediction_request(
            app_context.PredictionRequest
        )
        logger.info(f"API ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì™„ë£Œ: {model_uri}")
    except Exception as e:
        logger.error(f"API ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}", exc_info=True)
        raise


@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI ì•±ì˜ ìƒëª…ì£¼ê¸°(ì‹œì‘/ì¢…ë£Œ)ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    logger.info("Modern ML Pipeline API ì„œë²„ ì‹œì‘...")
    # ì—¬ê¸°ì— ì„œë²„ ì‹œì‘ ì‹œ í•„ìš”í•œ ë¡œì§ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì˜ˆë¥¼ ë“¤ì–´, run_idì™€ settingsë¥¼ í™˜ê²½ ë³€ìˆ˜ë‚˜ ì„¤ì • íŒŒì¼ì—ì„œ ì½ì–´ì™€
    # setup_api_contextë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    yield
    logger.info("Modern ML Pipeline API ì„œë²„ ì¢…ë£Œ.")
