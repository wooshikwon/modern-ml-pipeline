import uvicorn
from fastapi import FastAPI, HTTPException
from typing import Dict, Any

from src.settings import Settings
from src.utils.system.logger import logger
from src.serving._context import app_context
from src.serving._lifespan import lifespan, setup_api_context
from src.serving import _endpoints as handlers
from src.components._fetcher import PassThroughAugmenter
from src.serving.schemas import (
    HealthCheckResponse,
    ModelMetadataResponse,
    OptimizationHistoryResponse,
    MinimalPredictionResponse,
)

# í…ŒìŠ¤íŠ¸ì™€ ì‹¤ì œ ì„œë¹™ ëª¨ë‘ì—ì„œ ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” ìµœìƒìœ„ app ê°ì²´
app = FastAPI(
    title="Modern ML Pipeline API",
    description="Blueprint v17.0 ê¸°ë°˜ ëª¨ë¸ ì„œë¹™ API",
    version="17.0.0",
    lifespan=lifespan,
)

def _register_dynamic_routes_if_needed():
    """Setup í›„ ë™ì  ë¼ìš°íŠ¸ë¥¼ ë³´ì¥í•œë‹¤(/predict)."""
    # ì´ë¯¸ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if any(getattr(r, "path", None) == "/predict" for r in app.router.routes):
        return
    PredictionRequest = app_context.PredictionRequest
    if PredictionRequest is None:
        return

    def predict(request: PredictionRequest) -> MinimalPredictionResponse:
        try:
            prediction_result = handlers.predict(request.model_dump())
            return MinimalPredictionResponse(**prediction_result)
        except Exception as e:
            logger.error(f"ë‹¨ì¼ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=str(e))

    app.add_api_route(
        "/predict",
        predict,
        response_model=MinimalPredictionResponse,
        methods=["POST"],
        tags=["Prediction"],
    )

@app.get("/", tags=["General"])
def root() -> Dict[str, str]:
    return {
        "message": "Modern ML Pipeline API",
        "status": "ready" if app_context.model else "error",
        "model_uri": app_context.model_uri,
    }

@app.get("/health", response_model=HealthCheckResponse, tags=["General"])
def health_check() -> HealthCheckResponse:
    try:
        return handlers.health()
    except Exception as e:
        logger.error(f"Health check ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/predict", response_model=MinimalPredictionResponse, tags=["Prediction"])
def predict_generic(request: Dict[str, Any]) -> MinimalPredictionResponse:
    if not app_context.model or not app_context.settings:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    try:
        # ì„œë¹™ ì •ì±…: pass_through/í´ë°± ì°¨ë‹¨
        try:
            wrapped_model = app_context.model.unwrap_python_model()
            if isinstance(wrapped_model.trained_augmenter, PassThroughAugmenter):
                raise HTTPException(status_code=503, detail="Serving with 'pass_through' augmenter is not allowed.")
        except HTTPException:
            raise
        except Exception:
            pass
        prediction_result = handlers.predict(request)
        return MinimalPredictionResponse(**prediction_result)
    except HTTPException as he:
        # ì •ì±… ìœ„ë°˜ ë“±ì€ ì›ë˜ ìƒíƒœì½”ë“œë¡œ ì „ë‹¬
        raise he
    except Exception as e:
        logger.error(f"ë‹¨ì¼ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

# ğŸ†• Blueprint v17.0: ëª¨ë¸ ë©”íƒ€ë°ì´í„° ìê¸° ê¸°ìˆ  ì—”ë“œí¬ì¸íŠ¸ë“¤
    
@app.get("/model/metadata", response_model=ModelMetadataResponse, tags=["Model Metadata"])
def get_model_metadata() -> ModelMetadataResponse:
    """
    ëª¨ë¸ì˜ ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ë°˜í™˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”, Data Leakage ë°©ì§€ ì •ë³´ í¬í•¨)
    """
    try:
        return handlers.get_model_metadata()
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/model/optimization", response_model=OptimizationHistoryResponse, tags=["Model Metadata"])
def get_optimization_history() -> OptimizationHistoryResponse:
    """
    í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê³¼ì •ì˜ ìƒì„¸ íˆìŠ¤í† ë¦¬ ë°˜í™˜
    """
    try:
        return handlers.get_optimization_history()
    except Exception as e:
        logger.error(f"ìµœì í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/model/schema", tags=["Model Metadata"])
def get_api_schema() -> Dict[str, Any]:
    """
    ë™ì ìœ¼ë¡œ ìƒì„±ëœ API ìŠ¤í‚¤ë§ˆ ì •ë³´ ë°˜í™˜
    """
    try:
        return handlers.get_api_schema()
    except Exception as e:
        logger.error(f"API ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

def run_api_server(settings: Settings, run_id: str, host: str = "0.0.0.0", port: int = 8000):
    """
    FastAPI ì„œë²„ë¥¼ ì‹¤í–‰í•˜ê³ , Lifespan ì´ë²¤íŠ¸ë¥¼ í†µí•´ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    # Blueprint ì›ì¹™ 9: í™˜ê²½ë³„ ê¸°ëŠ¥ ë¶„ë¦¬ - API ì„œë¹™ ì‹œìŠ¤í…œì  ì°¨ë‹¨
    if hasattr(settings, 'serving') and settings.serving and not getattr(settings.serving, 'enabled', True):
        logger.error(f"'{settings.environment.env_name}' í™˜ê²½ì—ì„œëŠ” API ì„œë¹™ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        return

    # ì„œë²„ ì‹œì‘ ì‹œ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
    setup_api_context(run_id=run_id, settings=settings)

    # [ì‹ ê·œ] Augmenter íƒ€ì… ëª…ì‹œì  ê²€ì¦
    wrapped_model = app_context.model.unwrap_python_model()
    if isinstance(wrapped_model.trained_augmenter, PassThroughAugmenter):
        raise TypeError(
            "API serving is not supported when the augmenter is 'pass_through'. "
            "A feature store connection is required."
        )
    # ì •ì  predict ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©

    uvicorn.run(app, host=host, port=port)
