"""
Inference Pipeline - Batch and Realtime Inference
"""
import pandas as pd
import mlflow
from datetime import datetime
from typing import Dict, Any, Optional

from src.factory import Factory
from src.utils.integrations.mlflow_integration import start_run
from src.utils.system.logger import logger
from src.utils.system.console_manager import UnifiedConsole, RichConsoleManager
from src.settings import Settings
from src.utils.system.reproducibility import set_global_seeds


def _is_jinja_template(sql_text: str) -> bool:
    """SQL í…ìŠ¤íŠ¸ê°€ Jinja í…œí”Œë¦¿ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    import re
    jinja_patterns = [
        r'\{\{.*?\}\}',  # {{ variable }}
        r'\{%.*?%\}',    # {% for ... %}
    ]
    return any(re.search(pattern, sql_text) for pattern in jinja_patterns)


def run_inference_pipeline(settings: Settings, run_id: str, data_path: str = None, context_params: dict = None):
    """
    ì§€ì •ëœ Run IDì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ ì¶”ë¡ ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    --data-pathë¡œ ì§ì ‘ ë°ì´í„° ê²½ë¡œë¥¼ ì§€ì •í•˜ëŠ” ë°©ì‹
    """
    context_params = context_params or {}
    console = UnifiedConsole(settings)

    # ì¬í˜„ì„±ì„ ìœ„í•œ ì „ì—­ ì‹œë“œ ì„¤ì • (ë ˆì‹œí”¼ ì‹œë“œê°€ ì—†ìœ¼ë©´ 42)
    seed = getattr(settings.recipe.model, 'computed', {}).get('seed', 42)
    set_global_seeds(seed)
    
    # Pipeline context start  
    rich_console = RichConsoleManager()
    with rich_console.pipeline_context("Batch Inference Pipeline", f"Model: {run_id}"):
        
        # 1. MLflow ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
        with start_run(settings, run_name=f"batch_inference_{run_id}") as run:
            # 2. ëª¨ë¸ ë¡œë“œ
            rich_console.log_phase("Model Loading", "ğŸ¤–")
            model_uri = f"runs:/{run_id}/model"
            console.info(f"MLflow ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_uri}", 
                        rich_message=f"Loading model from [cyan]{model_uri}[/cyan]")
            model = mlflow.pyfunc.load_model(model_uri)
            console.info("ëª¨ë¸ ë¡œë”© ì™„ë£Œ", rich_message="âœ… Model loaded successfully")
            
            # 3. ë°ì´í„° ë¡œë”© (CLI data_path ìš°ì„ , Jinja ë Œë”ë§ ì§€ì›)
            rich_console.log_phase("Data Loading", "ğŸ“Š")
            factory = Factory(settings)
            data_adapter = factory.create_data_adapter()
            
            if data_path:
                # CLIì—ì„œ ì§€ì •í•œ data_path ì‚¬ìš©
                console.info(f"CLI data_path ì‚¬ìš©: {data_path}",
                           rich_message=f"Using CLI data path: [cyan]{data_path}[/cyan]")
                final_data_source = data_path
                
                # Jinja í…œí”Œë¦¿ ë Œë”ë§ ì²˜ë¦¬ (.sql.j2 ë˜ëŠ” paramsê°€ ìˆëŠ” .sql)
                if data_path.endswith('.sql.j2') or (data_path.endswith('.sql') and context_params):
                    from src.utils.system.templating_utils import render_template_from_string
                    from pathlib import Path
                    
                    rich_console.log_processing_step("Template rendering", f"Processing {Path(data_path).name}")
                    template_path = Path(data_path)
                    if template_path.exists():
                        template_content = template_path.read_text()
                        if context_params:
                            try:
                                final_data_source = render_template_from_string(template_content, context_params)
                                console.info(f"CLI data_path Jinja ë Œë”ë§ ì„±ê³µ: {data_path}",
                                           rich_message="âœ… Template rendering successful")
                            except ValueError as e:
                                console.error(f"CLI data_path Jinja ë Œë”ë§ ì‹¤íŒ¨: {e}",
                                           rich_message=f"âŒ Template rendering failed: {e}")
                                raise ValueError(f"í…œí”Œë¦¿ ë Œë”ë§ ì‹¤íŒ¨: {e}")
                        else:
                            # íŒŒë¼ë¯¸í„° ì—†ì´ .sql.j2 íŒŒì¼ â†’ ì—ëŸ¬
                            error_msg = f"Jinja í…œí”Œë¦¿ íŒŒì¼({data_path})ì—ëŠ” --paramsê°€ í•„ìš”í•©ë‹ˆë‹¤"
                            console.error(error_msg, suggestion="Use --params flag to provide template parameters")
                            raise ValueError(error_msg)
                    else:
                        error_msg = f"í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}"
                        console.error(error_msg, context={"file_path": data_path})
                        raise FileNotFoundError(error_msg)
                
                df = data_adapter.read(final_data_source)
                console.data_operation("Data loaded from CLI path", df.shape)
                
            else:
                # Fallback: ê¸°ì¡´ ë°©ì‹ (ì €ì¥ëœ loader_sql_snapshot ì‚¬ìš©)
                console.info("CLI data_path ì—†ìŒ, ì €ì¥ëœ SQL ì‚¬ìš©", 
                           rich_message="Using stored SQL from model")
                wrapped_model = model.unwrap_python_model()
                loader_sql_template = wrapped_model.loader_sql_snapshot
                
                # ê¸°ì¡´ Jinja ë Œë”ë§ ë¡œì§ (ë³´ì•ˆ ê°•í™”)
                if _is_jinja_template(loader_sql_template) and context_params:
                    # Jinja template + context_params â†’ ë³´ì•ˆ ê°•í™” ë™ì  ë Œë”ë§
                    from src.utils.system.templating_utils import render_template_from_string
                    rich_console.log_processing_step("Dynamic SQL rendering", "Security-validated template processing")
                    try:
                        rendered_sql = render_template_from_string(loader_sql_template, context_params)
                        console.info("ë™ì  SQL ë Œë”ë§ ì„±ê³µ (ë³´ì•ˆ ê²€ì¦ ì™„ë£Œ)",
                                   rich_message="âœ… Dynamic SQL rendering successful (security validated)")
                        final_data_source = rendered_sql
                    except ValueError as e:
                        # ë³´ì•ˆ ìœ„ë°˜ ë˜ëŠ” ì˜ëª»ëœ íŒŒë¼ë¯¸í„° â†’ ëª…í™•í•œ ì—ëŸ¬
                        console.error(f"ë™ì  SQL ë Œë”ë§ ì‹¤íŒ¨: {e}",
                                    suggestion="Check template parameters and security constraints")
                        raise ValueError(f"ë™ì  SQL ë Œë”ë§ ì‹¤íŒ¨: {e}")
                        
                elif context_params:
                    # ì •ì  SQL + context_params â†’ ë³´ì•ˆ ì—ëŸ¬ (ëª…í™•í•œ ì•ˆë‚´)
                    error_msg = ("ë³´ì•ˆ ìœ„ë°˜: ì´ ëª¨ë¸ì€ ì •ì  SQLë¡œ í•™ìŠµë˜ì–´ ë™ì  ì‹œì  ë³€ê²½ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                               "ë™ì  Batch Inferenceë¥¼ ì›í•œë‹¤ë©´ Jinja template (.sql.j2)ë¡œ í•™ìŠµí•˜ì„¸ìš”.")
                    console.error(error_msg, 
                                context={"sql_preview": loader_sql_template[:100] + "..."},
                                suggestion="Train model with Jinja template (.sql.j2) for dynamic inference")
                    raise ValueError(f"ğŸš¨ {error_msg}")
                else:
                    # ì •ì  SQL + context_params ì—†ìŒ â†’ ì •ìƒ ì²˜ë¦¬
                    final_data_source = loader_sql_template
                
                df = data_adapter.read(final_data_source)
                console.data_operation("Data loaded from stored SQL", df.shape)
            
            # 4. ì˜ˆì¸¡ ì‹¤í–‰ (PyfuncWrapperê°€ ë‚´ë¶€ì ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ê²€ì¦ì„ ìˆ˜í–‰)
            rich_console.log_phase("Model Inference", "ğŸ”®")
            with rich_console.progress_tracker("inference", 100, "Running model prediction") as update:
                # MLflow predict í˜¸ì¶œ í›„ DataFrameìœ¼ë¡œ ë³€í™˜
                predictions_result = model.predict(df)
                
                # ê²°ê³¼ê°€ list/arrayì¸ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜
                if isinstance(predictions_result, (list, tuple)) or hasattr(predictions_result, 'tolist'):
                    predictions_df = pd.DataFrame({'prediction': predictions_result}, index=df.index)
                elif isinstance(predictions_result, pd.DataFrame):
                    predictions_df = predictions_result
                else:
                    # numpy array ë“±ì˜ ê²½ìš°
                    predictions_df = pd.DataFrame({'prediction': predictions_result.flatten()}, index=df.index)
                    
                update(100)
        
        # 5. í•µì‹¬ ë©”íƒ€ë°ì´í„° ì¶”ê°€ (ì¶”ì ì„± ë³´ì¥)
        predictions_df['model_run_id'] = run_id  # ì‚¬ìš©ëœ ëª¨ë¸ì˜ MLflow Run ID
        predictions_df['inference_run_id'] = run.info.run_id  # í˜„ì¬ ë°°ì¹˜ ì¶”ë¡  ì‹¤í–‰ ID
        predictions_df['inference_timestamp'] = datetime.now()  # ì˜ˆì¸¡ ìˆ˜í–‰ ì‹œê°
        
        # 6. ê²°ê³¼ ì €ì¥ (Output ì„¤ì • ê¸°ë°˜)
        rich_console.log_phase("Output Saving", "ğŸ’¾")
        output_cfg = getattr(settings.config, 'output', None)
        if output_cfg and getattr(output_cfg.inference, 'enabled', True):
            try:
                target = output_cfg.inference
                if target.adapter_type == "storage":
                    console.info("Storage ì–´ëŒ‘í„° ì‚¬ìš©í•˜ì—¬ ê²°ê³¼ ì €ì¥",
                               rich_message="ğŸ“ Saving predictions to storage")
                    storage_adapter = factory.create_data_adapter("storage")
                    base_path = target.config.get('base_path', './artifacts/predictions')
                    target_path = f"{base_path}/preds_{run.info.run_id}.parquet"
                    storage_adapter.write(predictions_df, target_path)
                    # ë¡œì»¬ ê²½ë¡œë§Œ MLflow artifactë¡œ ë¡œê¹…
                    if not target_path.startswith("s3://") and not target_path.startswith("gs://"):
                        mlflow.log_artifact(target_path.replace("file://", ""))
                    console.info(f"ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {target_path}",
                               rich_message=f"âœ… Predictions saved to [cyan]{target_path}[/cyan]")
                elif target.adapter_type == "sql":
                    sql_adapter = factory.create_data_adapter("sql")
                    table = target.config.get('table')
                    if not table:
                        raise ValueError("output.inference.config.tableì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    console.info(f"SQL ë°ì´í„°ë² ì´ìŠ¤ì— ê²°ê³¼ ì €ì¥: {table}",
                               rich_message=f"ğŸ—„ï¸  Saving to database table [cyan]{table}[/cyan]")
                    sql_adapter.write(predictions_df, table, if_exists='append', index=False)
                    console.info("SQL ì €ì¥ ì™„ë£Œ", rich_message="âœ… SQL save completed")
                elif target.adapter_type == "bigquery":
                    bq_adapter = factory.create_data_adapter("bigquery")
                    project_id = target.config.get('project_id')
                    dataset = target.config.get('dataset_id')
                    table = target.config.get('table')
                    location = target.config.get('location')
                    if not (project_id and dataset and table):
                        raise ValueError("BigQuery ì¶œë ¥ì—ëŠ” project_id, dataset_id, tableì´ í•„ìš”í•©ë‹ˆë‹¤.")
                    console.info(f"BigQueryì— ê²°ê³¼ ì €ì¥: {dataset}.{table}",
                               rich_message=f"â˜ï¸  Saving to BigQuery [cyan]{dataset}.{table}[/cyan]")
                    bq_adapter.write(
                        predictions_df,
                        f"{dataset}.{table}",
                        options={"project_id": project_id, "location": location, "if_exists": "append"}
                    )
                    console.info("BigQuery ì €ì¥ ì™„ë£Œ", rich_message="âœ… BigQuery save completed")
                else:
                    console.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” output ì–´ëŒ‘í„° íƒ€ì…: {target.adapter_type}. ì €ì¥ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.",
                                  rich_message=f"âš ï¸  Unknown adapter type: [yellow]{target.adapter_type}[/yellow], skipping save",
                                  context={"adapter_type": target.adapter_type})
            except Exception as e:
                console.error(f"ì¶œë ¥ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}",
                            rich_message=f"âŒ Output save failed: {e}",
                            context={"error_type": type(e).__name__, "run_id": run.info.run_id},
                            suggestion="Check output configuration and adapter connectivity")
        else:
            console.info("Output ì„¤ì •ì´ ë¹„í™œì„±í™”ë˜ì–´ ì €ì¥ì„ ìŠ¤í‚µí•©ë‹ˆë‹¤.",
                       rich_message="â„¹ï¸  Output disabled, skipping save")
        
        mlflow.log_metric("inference_row_count", len(predictions_df))


def _is_jinja_template(sql: str) -> bool:
    """
    SQL ë¬¸ìì—´ì´ Jinja2 í…œí”Œë¦¿ì¸ì§€ ê°ì§€
    
    Args:
        sql: ê²€ì‚¬í•  SQL ë¬¸ìì—´
        
    Returns:
        Jinja2 í…œí”Œë¦¿ íŒ¨í„´ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ True, ì•„ë‹ˆë©´ False
    """
    jinja_patterns = ['{{', '}}', '{%', '%}']
    return any(pattern in sql for pattern in jinja_patterns)