import json
from pathlib import Path
from typing import Optional, Dict, Any

import mlflow

from src.settings import Settings
from src.core.factory import Factory
from src.core.trainer import Trainer
from src.utils.system.logger import logger
from src.utils.system import mlflow_utils


def run_training(settings: Settings, context_params: Optional[Dict[str, Any]] = None):
    """
    ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Factoryë¥¼ í†µí•´ ë°ì´í„° ì–´ëŒ‘í„°ì™€ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ
    ìˆœìˆ˜ ë¡œì§ PyfuncWrapperë¥¼ ìƒì„±í•˜ì—¬ MLflowì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    logger.info(f"'{settings.model.computed['run_name']}' ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    context_params = context_params or {}

    factory = Factory(settings)

    with mlflow_utils.start_run(settings) as run:
        run_id = run.info.run_id
        
        # ìë™ ìƒì„±ëœ Run Name ì„¤ì •
        run_name = settings.model.computed["run_name"]
        mlflow.set_tag("mlflow.runName", run_name)
        
        # ì²´ê³„ì ì¸ ì‹¤í—˜ ì¡°ì§ì„ ìœ„í•œ ì¶”ê°€ íƒœê·¸ ì„¤ì •
        mlflow.set_tag("model_class", settings.model.computed["model_class_name"])
        mlflow.set_tag("recipe_file", settings.model.computed["recipe_file"])
        mlflow.set_tag("experiment_type", "training")
        mlflow.set_tag("class_path", settings.model.class_path)
        mlflow.set_tag("timestamp", settings.model.computed["timestamp"])

        # ëª¨ë¸ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params(settings.model.hyperparameters.root)
        mlflow.log_param("class_path", settings.model.class_path)

        # 1. ë°ì´í„° ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë”©
        # âœ… Blueprint ì›ì¹™ 3: URI ê¸°ë°˜ ë™ì‘ ë° ë™ì  íŒ©í† ë¦¬ ì™„ì „ êµ¬í˜„
        # Factoryê°€ í™˜ê²½ë³„ ë¶„ê¸°ì™€ ì–´ëŒ‘í„° ì„ íƒì„ ì „ë‹´
        data_adapter = factory.create_data_adapter("loader")
        
        # ìˆœìˆ˜ ë…¼ë¦¬ ê²½ë¡œë§Œ ì‚¬ìš© - Factoryê°€ í™˜ê²½ë³„ URI í•´ì„ ì²˜ë¦¬
        df = data_adapter.read(settings.model.loader.source_uri, params=context_params)
        mlflow.log_metric("row_count", len(df))
        mlflow.log_metric("column_count", len(df.columns))

        # 2. í•™ìŠµì— ì‚¬ìš©í•  ì»´í¬ë„ŒíŠ¸ ìƒì„±
        augmenter = factory.create_augmenter()
        preprocessor = factory.create_preprocessor()
        model = factory.create_model()

        # 3. ëª¨ë¸ í•™ìŠµ
        trainer = Trainer(settings=settings)
        trained_preprocessor, trained_model, training_results = trainer.train(  # â† training_results í™œìš©
            df=df,
            model=model,
            augmenter=augmenter,
            preprocessor=preprocessor,
            context_params=context_params,
        )
        
        # 4. ê²°ê³¼ ë¡œê¹… (í™•ì¥)
        if 'metrics' in training_results:
            mlflow.log_metrics(training_results['metrics'])
        
        # ğŸ†• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ë¡œê¹…
        if 'hyperparameter_optimization' in training_results:
            hpo_result = training_results['hyperparameter_optimization']
            if hpo_result['enabled']:
                mlflow.log_params(hpo_result['best_params'])
                mlflow.log_metric('best_score', hpo_result['best_score'])
                mlflow.log_metric('total_trials', hpo_result['total_trials'])

        # 5. í™•ì¥ëœ PyfuncWrapper ìƒì„± ë° ì €ì¥
        pyfunc_wrapper = factory.create_pyfunc_wrapper(
            trained_model=trained_model,
            trained_preprocessor=trained_preprocessor,
            training_results=training_results,  # ğŸ†• ê²°ê³¼ ì „ë‹¬
        )
        
        # ğŸ†• Dynamic Signature ìƒì„± (Day 3)
        # í•™ìŠµ ë°ì´í„°ë¡œ ìƒ˜í”Œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì—¬ signature ìƒì„±
        logger.info("ModelSignature ìƒì„±ì„ ìœ„í•œ ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        
        # ì‘ì€ ìƒ˜í”Œ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ (ì²˜ìŒ 5ê°œ í–‰ ì‚¬ìš©)
        sample_input = df.head(5)
        sample_output = pyfunc_wrapper.predict(
            context=None,
            model_input=sample_input,
            params={"run_mode": "batch", "return_intermediate": False}
        )
        
        # DataFrameì´ ì•„ë‹Œ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜
        if not hasattr(sample_output, 'columns'):
            import pandas as pd
            sample_output = pd.DataFrame(sample_output)
        
        # ModelSignature ìƒì„±
        signature = mlflow_utils.create_model_signature(
            input_df=sample_input,
            output_df=sample_output
        )
        
        # model.nameì´ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° run_nameì„ ì‚¬ìš©
        model_name = getattr(settings.model, 'name', None) or settings.model.computed['run_name']
        
        mlflow.pyfunc.log_model(
            artifact_path="model",
            python_model=pyfunc_wrapper,
            signature=signature,  # ğŸ†• signature ì¶”ê°€
        )
        logger.info(f"ìˆœìˆ˜ ë¡œì§ ëª¨ë¸ '{model_name}'ì„ MLflowì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        # 6. (ì„ íƒì ) ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {"run_id": run_id, "model_name": model_name}
        local_dir = Path("./local/artifacts")
        local_dir.mkdir(parents=True, exist_ok=True)
        metadata_path = local_dir / f"metadata-{run_id}.json"
        with metadata_path.open('w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=4, default=str)
        mlflow.log_artifact(str(metadata_path), "metadata")