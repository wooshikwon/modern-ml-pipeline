import json
from pathlib import Path
from typing import Optional, Dict, Any

import mlflow
import pandas as pd
from contextlib import contextmanager

from src.settings import Settings
from src.engine import Factory
from src.components._trainer import Trainer
from src.utils.system.logger import logger
from src.utils.integrations import mlflow_integration as mlflow_utils


def run_training(settings: Settings, context_params: Optional[Dict[str, Any]] = None):
    """
    ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Factoryë¥¼ í†µí•´ ë°ì´í„° ì–´ëŒ‘í„°ì™€ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ
    ìˆœìˆ˜ ë¡œì§ PyfuncWrapperë¥¼ ìƒì„±í•˜ì—¬ MLflowì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    logger.info(f"['{settings.recipe.model.computed['run_name']}'] ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    logger.info(f"MLflow Tracking URI (from settings): {settings.mlflow.tracking_uri}") # ê²½ë¡œ ê²€ì¦ ë¡œê·¸ ì¶”ê°€
    context_params = context_params or {}

    # MLflow ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
    with mlflow_utils.start_run(settings, run_name=settings.recipe.model.computed["run_name"]) as run:
        run_id = run.info.run_id
        
        # Factory ìƒì„±
        factory = Factory(settings)

        # 1. ë°ì´í„° ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë”©
        data_adapter = factory.create_data_adapter(settings.data_adapters.default_loader)
        df = data_adapter.read(settings.recipe.model.loader.source_uri)

        mlflow.log_metric("row_count", len(df))
        mlflow.log_metric("column_count", len(df.columns))

        # 2. í•™ìŠµì— ì‚¬ìš©í•  ì»´í¬ë„ŒíŠ¸ ìƒì„±
        augmenter = factory.create_augmenter()
        preprocessor = factory.create_preprocessor()
        model = factory.create_model()

        # 3. ëª¨ë¸ í•™ìŠµ
        trainer = Trainer(settings=settings)
        trained_model, trained_preprocessor, metrics, training_results = trainer.train(  # ğŸ”„ ìˆ˜ì •: ë°˜í™˜ê°’ ìˆœì„œ ì˜¬ë°”ë¥´ê²Œ ë³€ê²½
            df=df,
            model=model,
            augmenter=augmenter,
            preprocessor=preprocessor,
            context_params=context_params,
        )
        
        # 4. ê²°ê³¼ ë¡œê¹… (í™•ì¥)
        if metrics:  # ğŸ”„ ìˆ˜ì •: 'metrics' keyê°€ ì•„ë‹Œ ì§ì ‘ metrics ê°ì²´ ì‚¬ìš©
            mlflow.log_metrics(metrics)
        
        # ğŸ†• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ë¡œê¹…
        if 'hyperparameter_optimization' in training_results:
            hpo_result = training_results['hyperparameter_optimization']
            if hpo_result['enabled']:
                mlflow.log_params(hpo_result['best_params'])
                mlflow.log_metric('best_score', hpo_result['best_score'])
                mlflow.log_metric('total_trials', hpo_result['total_trials'])

        # 5. ğŸ”„ Phase 5: Enhanced PyfuncWrapper ìƒì„± (training_df ì¶”ê°€)
        pyfunc_wrapper = factory.create_pyfunc_wrapper(
            trained_model=trained_model,
            trained_preprocessor=trained_preprocessor,
            trained_augmenter=augmenter, # í•™ìŠµì— ì‚¬ìš©ëœ augmenterë¥¼ ì§ì ‘ ì „ë‹¬
            training_df=df,
            training_results=training_results,
        )
        
        # 6. ğŸ†• Phase 5: Enhanced Model + ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ì €ì¥
        logger.info("ğŸ†• Phase 5: Enhanced Artifact ì €ì¥ ì¤‘...")
        
        if pyfunc_wrapper.signature and pyfunc_wrapper.data_schema:
            # Phase 5 Enhanced ì €ì¥ ë¡œì§ ì‚¬ìš©
            from src.utils.integrations.mlflow_integration import log_enhanced_model_with_schema
            
            log_enhanced_model_with_schema(
                python_model=pyfunc_wrapper,
                signature=pyfunc_wrapper.signature,
                data_schema=pyfunc_wrapper.data_schema,
                input_example=df.head(5)  # ì…ë ¥ ì˜ˆì œ
            )
            
            model_name = getattr(settings.recipe.model, 'name', None) or settings.recipe.model.computed['run_name']
            logger.info(f"âœ… Enhanced Artifact '{model_name}' MLflow ì €ì¥ ì™„ë£Œ (Phase 1-5 í†µí•©)")
        else:
            # Fallback: ê¸°ì¡´ ë°©ì‹ (training_dfê°€ ì—†ì—ˆë˜ ê²½ìš°)
            logger.warning("âš ï¸ Enhanced ì •ë³´ê°€ ì—†ì–´ ê¸°ë³¸ ì €ì¥ ë°©ì‹ ì‚¬ìš©")
            
            # ê¸°ë³¸ ìƒ˜í”Œ ì˜ˆì¸¡ ë° signature ìƒì„±
            sample_input = df.head(5)
            sample_output = pyfunc_wrapper.predict(
                context=None,
                model_input=sample_input,
                params={"run_mode": "batch", "return_intermediate": False}
            )
            
            if not isinstance(sample_output, pd.DataFrame):
                sample_output = pd.DataFrame(sample_output)
            
            signature = mlflow_utils.create_model_signature(
                input_df=sample_input,
                output_df=sample_output
            )
            
            # ê¸°ì¡´ MLflow ì €ì¥
            mlflow.pyfunc.log_model(
                artifact_path="model",
                python_model=pyfunc_wrapper,
                signature=signature,
                input_example=sample_input,
            )
            
            model_name = getattr(settings.recipe.model, 'name', None) or settings.recipe.model.computed['run_name']
            logger.info(f"ê¸°ë³¸ ëª¨ë¸ '{model_name}'ì„ MLflowì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        # 7. (ì„ íƒì ) ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {"run_id": run_id, "model_name": model_name}
        local_dir = Path("./local/artifacts")
        local_dir.mkdir(parents=True, exist_ok=True)
        metadata_path = local_dir / f"metadata-{run_id}.json"
        with metadata_path.open('w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=4, default=str)
        mlflow.log_artifact(str(metadata_path), "metadata")