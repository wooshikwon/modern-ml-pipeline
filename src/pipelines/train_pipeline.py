import json
from typing import Optional, Dict, Any
from types import SimpleNamespace

import mlflow
import pandas as pd

from src.settings import Settings
from src.factory import Factory
from src.utils.system.logger import logger
from src.utils.system.console_manager import RichConsoleManager
from src.utils.integrations import mlflow_integration as mlflow_utils
from src.utils.system.environment_check import get_pip_requirements
from src.utils.system.reproducibility import set_global_seeds
from src.utils.integrations.mlflow_integration import log_training_results
from src.utils.integrations.mlflow_integration import log_enhanced_model_with_schema

def run_train_pipeline(
    settings: Settings,
    context_params: Optional[Dict[str, Any]] = None,
    record_requirements: bool = False,
):
    """
    ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Factoryë¥¼ í†µí•´ ë°ì´í„° ì–´ëŒ‘í„°ì™€ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ê³ ,
    PyfuncWrapperë¥¼ ìƒì„±í•˜ì—¬ MLflowì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    console = RichConsoleManager()
    
    # ì¬í˜„ì„±ì„ ìœ„í•œ ì „ì—­ ì‹œë“œ ì„¤ì •
    seed = getattr(settings.recipe.model, 'computed', {}).get('seed', 42)
    set_global_seeds(seed)

    # Pipeline context start
    task_type = settings.recipe.task_choice
    model_name = getattr(settings.recipe.model, 'class_path', 'Unknown')
    pipeline_description = f"Environment: {settings.config.environment.name} | Task: {task_type} | Model: {model_name.split('.')[-1]}"
    
    with console.pipeline_context("Training Pipeline", pipeline_description):
        context_params = context_params or {}

        # MLflow ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
        with mlflow_utils.start_run(settings, run_name=settings.recipe.model.computed["run_name"]) as run:
            run_id = run.info.run_id
            
            # Factory ìƒì„±
            factory = Factory(settings)

            # 1. ë°ì´í„° ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë”©
            console.log_phase("Data Loading", "ğŸ“Š")
            with console.progress_tracker("data_loading", 100, "Loading and preparing data") as update:
                data_adapter = factory.create_data_adapter()
                df = data_adapter.read(settings.recipe.data.loader.source_uri)
                update(100)
            
            console.log_milestone(f"Data loaded successfully: {len(df)} rows, {len(df.columns)} columns", "success")

            mlflow.log_metric("row_count", len(df))
            mlflow.log_metric("column_count", len(df.columns))

            # 2. ì»´í¬ë„ŒíŠ¸ ìƒì„±
            console.log_phase("Component Initialization", "ğŸ”§")
            fetcher = factory.create_fetcher()
            datahandler = factory.create_datahandler()  # ì¼ê´€ëœ Factory íŒ¨í„´
            preprocessor = factory.create_preprocessor()
            model = factory.create_model()
            evaluator = factory.create_evaluator()
            trainer = factory.create_trainer()  # ì¼ê´€ëœ Factory íŒ¨í„´

            # 3. í”¼ì²˜ ì¦ê°•
            console.log_phase("Feature Augmentation", "âœ¨")
            augmented_df = fetcher.fetch(df, run_mode="train") if fetcher else df

            # 4. ë°ì´í„° ì¤€ë¹„
            console.log_phase("Model Training", "ğŸ¤–")
            X_train, y_train, add_train, X_test, y_test, add_test = datahandler.split_and_prepare(augmented_df)
            
            # 5. ì „ì²˜ë¦¬
            if preprocessor:
                preprocessor.fit(X_train)
                X_train = preprocessor.transform(X_train)
                X_test = preprocessor.transform(X_test)
            
            # 6. í•™ìŠµ
            trained_model, trainer_info = trainer.train(
                X_train=X_train,
                y_train=y_train,
                X_val=X_test,
                y_val=y_test,
                model=model,
                additional_data={'train': add_train, 'val': add_test},
            )

            # 7. í‰ê°€ ë° í‰ê°€ê²°ê³¼ ì €ì¥
            metrics = evaluator.evaluate(trained_model, X_test, y_test, add_test)
            training_results = {
                'evaluation_metrics': metrics,
                'trainer': trainer_info,
            }
            console.log_phase("Evaluation & Logging", "ğŸ“Š")
            log_training_results(settings, metrics, training_results)

            # 8. PyfuncWrapper ìƒì„± ë° ì €ì¥
            console.log_phase("Model Packaging", "ğŸ“¦")
            pyfunc_wrapper = factory.create_pyfunc_wrapper(
                trained_model=trained_model,
                trained_datahandler=datahandler,  # ì¶”ë¡  ì‹œ ì¬í˜„ì„±ì„ ìœ„í•œ DataHandler
                trained_preprocessor=preprocessor,
                trained_fetcher=fetcher, # í•™ìŠµì— ì‚¬ìš©ëœ fetcherë¥¼ ì§ì ‘ ì „ë‹¬
                training_df=augmented_df,
                training_results=training_results,
            )
            
            pip_reqs = get_pip_requirements() if record_requirements else []
            
            if not (pyfunc_wrapper.signature and pyfunc_wrapper.data_schema):
                raise ValueError("Failed to generate signature and data_schema. This should not happen.")
        
            log_enhanced_model_with_schema(
                python_model=pyfunc_wrapper,
                signature=pyfunc_wrapper.signature,
                data_schema=pyfunc_wrapper.data_schema,
                input_example=df.head(5),  # ì…ë ¥ ì˜ˆì œ
                pip_requirements=pip_reqs
            )
            
            return SimpleNamespace(run_id=run_id, model_uri=f"runs:/{run_id}/model")