import json
from pathlib import Path
from typing import Optional, Dict, Any
from types import SimpleNamespace

import mlflow
import pandas as pd

from src.settings import Settings
from src.factory import Factory
from src.utils.system.logger import logger
from src.utils.integrations import mlflow_integration as mlflow_utils
from src.utils.system.environment_check import get_pip_requirements
from src.utils.system.reproducibility import set_global_seeds


def run_train_pipeline(settings: Settings, context_params: Optional[Dict[str, Any]] = None):
    """
    ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Factoryë¥¼ í†µí•´ ë°ì´í„° ì–´ëŒ‘í„°ì™€ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ
    ìˆœìˆ˜ ë¡œì§ PyfuncWrapperë¥¼ ìƒì„±í•˜ì—¬ MLflowì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    # ì¬í˜„ì„±ì„ ìœ„í•œ ì „ì—­ ì‹œë“œ ì„¤ì •
    seed = getattr(settings.recipe.model, 'computed', {}).get('seed', 42)
    set_global_seeds(seed)

    logger.info(f"['{settings.recipe.model.computed['run_name']}'] ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    logger.info(f"MLflow Tracking URI (from settings): {settings.config.mlflow.tracking_uri}") # ê²½ë¡œ ê²€ì¦ ë¡œê·¸ ì¶”ê°€
    context_params = context_params or {}

    # MLflow ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
    with mlflow_utils.start_run(settings, run_name=settings.recipe.model.computed["run_name"]) as run:
        run_id = run.info.run_id
        
        # Factory ìƒì„±
        factory = Factory(settings)

        # 1. ë°ì´í„° ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë”©
        # adapter íƒ€ì…ì€ source_uri íŒ¨í„´ì—ì„œ ìë™ ê°ì§€ë¨
        data_adapter = factory.create_data_adapter()
        df = data_adapter.read(settings.recipe.data.loader.source_uri)

        mlflow.log_metric("row_count", len(df))
        mlflow.log_metric("column_count", len(df.columns))

        # 2. í•™ìŠµì— ì‚¬ìš©í•  ì»´í¬ë„ŒíŠ¸ ìƒì„±
        fetcher = factory.create_fetcher()
        datahandler = factory.create_datahandler()  # ì¼ê´€ëœ Factory íŒ¨í„´
        preprocessor = factory.create_preprocessor()
        model = factory.create_model()
        evaluator = factory.create_evaluator()
        trainer = factory.create_trainer()  # ì¼ê´€ëœ Factory íŒ¨í„´

        # 3. ëª¨ë¸ í•™ìŠµ
        trained_model, trained_preprocessor, metrics, training_results = trainer.train(
            df=df,
            model=model,
            fetcher=fetcher,
            datahandler=datahandler,  # ì¼ê´€ëœ Factory íŒ¨í„´
            preprocessor=preprocessor,
            evaluator=evaluator,
            context_params=context_params,
        )
        
        # 4. ê²°ê³¼ ë¡œê¹… (í™•ì¥)
        if metrics:  # ğŸ”„ ìˆ˜ì •: 'metrics' keyê°€ ì•„ë‹Œ ì§ì ‘ metrics ê°ì²´ ì‚¬ìš©
            mlflow.log_metrics(metrics)
        
        # ğŸ†• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ë¡œê¹…
        if 'hyperparameter_optimization' in training_results:
            hpo_result = training_results['hyperparameter_optimization']
            if hpo_result['enabled']:
                mlflow.log_params(hpo_result['best_params'])
                mlflow.log_metric('best_score', hpo_result['best_score'])
                mlflow.log_metric('total_trials', hpo_result['total_trials'])

        # 5. ğŸ”„ Phase 5: Enhanced PyfuncWrapper ìƒì„± (training_df + datahandler ì¶”ê°€)
        pyfunc_wrapper = factory.create_pyfunc_wrapper(
            trained_model=trained_model,
            trained_datahandler=datahandler,  # ì¶”ë¡  ì‹œ ì¬í˜„ì„±ì„ ìœ„í•œ DataHandler
            trained_preprocessor=trained_preprocessor,
            trained_fetcher=fetcher, # í•™ìŠµì— ì‚¬ìš©ëœ fetcherë¥¼ ì§ì ‘ ì „ë‹¬
            training_df=df,
            training_results=training_results,
        )
        
        # 6. ğŸ†• Phase 5: Enhanced Model + ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ì €ì¥
        logger.info("ğŸ†• Phase 5: Enhanced Artifact ì €ì¥ ì¤‘...")
        
        # ëª¨ë¸ ì €ì¥ ì‹œì ì˜ íŒ¨í‚¤ì§€ ì˜ì¡´ì„± ìº¡ì²˜
        pip_reqs = get_pip_requirements()
        
        # Signatureì™€ data_schema ê²€ì¦
        if not (pyfunc_wrapper.signature and pyfunc_wrapper.data_schema):
            raise ValueError("Failed to generate signature and data_schema. This should not happen.")
        
        # Phase 5 Enhanced ì €ì¥ ë¡œì§ ì‚¬ìš©
        from src.utils.integrations.mlflow_integration import log_enhanced_model_with_schema
        
        log_enhanced_model_with_schema(
            python_model=pyfunc_wrapper,
            signature=pyfunc_wrapper.signature,
            data_schema=pyfunc_wrapper.data_schema,
            input_example=df.head(5),  # ì…ë ¥ ì˜ˆì œ
            pip_requirements=pip_reqs
        )
        
        model_name = getattr(settings.recipe.model, 'name', None) or settings.recipe.model.computed['run_name']
        logger.info(f"âœ… Enhanced Artifact '{model_name}' MLflow ì €ì¥ ì™„ë£Œ (Phase 1-5 í†µí•©)")

        # 7. (ì„ íƒì ) ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {"run_id": run_id, "model_name": model_name}
        local_dir = Path("./local/artifacts")
        local_dir.mkdir(parents=True, exist_ok=True)
        metadata_path = local_dir / f"metadata-{run_id}.json"
        with metadata_path.open('w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=4, default=str)
        mlflow.log_artifact(str(metadata_path), "metadata")

        # 8. ê²°ê³¼ ê°ì²´ ë°˜í™˜(run_id ë° model_uri í¬í•¨)
        return SimpleNamespace(run_id=run_id, model_uri=f"runs:/{run_id}/model")