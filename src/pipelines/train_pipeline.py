import json
from pathlib import Path
from typing import Optional, Dict, Any

import mlflow
import pandas as pd

from src.settings import Settings
from src.engine.factory import Factory
from src.components.trainer import Trainer
from src.utils.system.logger import logger
from src.utils.integrations import mlflow_integration as mlflow_utils


def run_training(settings: Settings, context_params: Optional[Dict[str, Any]] = None):
    """
    ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    Factoryë¥¼ í†µí•´ ë°ì´í„° ì–´ëŒ‘í„°ì™€ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œ
    ìˆœìˆ˜ ë¡œì§ PyfuncWrapperë¥¼ ìƒì„±í•˜ì—¬ MLflowì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    logger.info(f"'{settings.model.computed['run_name']}' ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    context_params = context_params or {}

    # MLflow ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ì‹œì‘
    with mlflow_utils.start_run(settings, run_name=settings.model.computed["run_name"]) as run:
        run_id = run.info.run_id
        
        # Factory ìƒì„±
        factory = Factory(settings)

        # 1. ë°ì´í„° ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë¡œë”©
        # E2E í…ŒìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì‹¤ì œ ì–´ëŒ‘í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        data_adapter = factory.create_data_adapter(settings.data_adapters.default_loader)
        
        # --- E2E í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„ì‹œ Mocking ë¡œì§ ---
        is_e2e_test_run = "LIMIT 100" in settings.model.loader.source_uri
        if is_e2e_test_run:
            logger.warning("E2E í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì‹¤ì œ ë°ì´í„° ë¡œë”© ëŒ€ì‹  Mock DataFrameì„ ìƒì„±í•©ë‹ˆë‹¤.")
            df = pd.DataFrame({
                'user_id': [f'user_{i}' for i in range(100)],
                'item_id': [f'item_{i % 10}' for i in range(100)],
                'timestamp': pd.to_datetime('2024-01-01'),
                'target_date': context_params.get('target_date', '2024-01-01'),
                'target': [i % 2 for i in range(100)]
            })
        else:
            df = data_adapter.read(settings.model.loader.source_uri)

        mlflow.log_metric("row_count", len(df))
        mlflow.log_metric("column_count", len(df.columns))

        # 2. í•™ìŠµì— ì‚¬ìš©í•  ì»´í¬ë„ŒíŠ¸ ìƒì„±
        augmenter = factory.create_augmenter()
        preprocessor = factory.create_preprocessor()
        model = factory.create_model()

        # 3. ëª¨ë¸ í•™ìŠµ
        trainer = Trainer(settings=settings)
        trained_preprocessor, trained_model, training_results = trainer.train(  # â† training_results í™œìš©
            df=df,
            model=model,
            augmenter=augmenter,
            preprocessor=preprocessor,
            context_params=context_params,
        )
        
        # 4. ê²°ê³¼ ë¡œê¹… (í™•ì¥)
        if 'metrics' in training_results:
            mlflow.log_metrics(training_results['metrics'])
        
        # ğŸ†• í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ë¡œê¹…
        if 'hyperparameter_optimization' in training_results:
            hpo_result = training_results['hyperparameter_optimization']
            if hpo_result['enabled']:
                mlflow.log_params(hpo_result['best_params'])
                mlflow.log_metric('best_score', hpo_result['best_score'])
                mlflow.log_metric('total_trials', hpo_result['total_trials'])

        # 5. í™•ì¥ëœ PyfuncWrapper ìƒì„± ë° ì €ì¥
        pyfunc_wrapper = factory.create_pyfunc_wrapper(
            trained_model=trained_model,
            trained_preprocessor=trained_preprocessor,
            training_results=training_results,  # ğŸ†• ê²°ê³¼ ì „ë‹¬
        )
        
        # ğŸ†• Dynamic Signature ìƒì„± (Day 3)
        # í•™ìŠµ ë°ì´í„°ë¡œ ìƒ˜í”Œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ì—¬ signature ìƒì„±
        logger.info("ModelSignature ìƒì„±ì„ ìœ„í•œ ìƒ˜í”Œ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        
        # ì‘ì€ ìƒ˜í”Œ ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ (ì²˜ìŒ 5ê°œ í–‰ ì‚¬ìš©)
        sample_input = df.head(5)
        sample_output = pyfunc_wrapper.predict(
            context=None,
            model_input=sample_input,
            params={"run_mode": "batch", "return_intermediate": False}
        )
        
        # DataFrameì´ ì•„ë‹Œ ê²½ìš° DataFrameìœ¼ë¡œ ë³€í™˜
        if not hasattr(sample_output, 'columns'):
            import pandas as pd
            sample_output = pd.DataFrame(sample_output)
        
        # ModelSignature ìƒì„±
        signature = mlflow_utils.create_model_signature(
            input_df=sample_input,
            output_df=sample_output
        )
        
        # model.nameì´ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° run_nameì„ ì‚¬ìš©
        model_name = getattr(settings.model, 'name', None) or settings.model.computed['run_name']
        
        mlflow.pyfunc.log_model(
            artifact_path="model",
            python_model=pyfunc_wrapper,
            signature=signature,  # ğŸ†• signature ì¶”ê°€
        )
        logger.info(f"ìˆœìˆ˜ ë¡œì§ ëª¨ë¸ '{model_name}'ì„ MLflowì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        # 6. (ì„ íƒì ) ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {"run_id": run_id, "model_name": model_name}
        local_dir = Path("./local/artifacts")
        local_dir.mkdir(parents=True, exist_ok=True)
        metadata_path = local_dir / f"metadata-{run_id}.json"
        with metadata_path.open('w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=4, default=str)
        mlflow.log_artifact(str(metadata_path), "metadata")