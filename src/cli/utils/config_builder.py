"""
Config Builder for Modern ML Pipeline CLI
Phase 3: Interactive configuration file generation

CLAUDE.md ÏõêÏπô Ï§ÄÏàò:
- ÌÉÄÏûÖ ÌûåÌä∏ ÌïÑÏàò
- Google Style Docstring
- ÎåÄÌôîÌòï Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
"""

from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

from src.cli.utils.interactive_ui import InteractiveUI
from src.cli.utils.template_engine import TemplateEngine


class InteractiveConfigBuilder:
    """ÎåÄÌôîÌòï ÌôòÍ≤Ω ÏÑ§Ï†ï ÎπåÎçî.
    
    ÏÇ¨Ïö©ÏûêÏôÄÏùò ÎåÄÌôîÌòï Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î•º ÌÜµÌï¥ ÌôòÍ≤ΩÎ≥Ñ ÏÑ§Ï†ï ÌååÏùºÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
    """
    
    def __init__(self):
        """InteractiveConfigBuilder Ï¥àÍ∏∞Ìôî."""
        self.ui = InteractiveUI()
        templates_dir = Path(__file__).parent.parent / "templates"
        self.template_engine = TemplateEngine(templates_dir)
    
    def run_interactive_flow(self, env_name: Optional[str] = None) -> Dict[str, Any]:
        """
        ÎåÄÌôîÌòï ÏÑ§Ï†ï ÌîåÎ°úÏö∞ Ïã§Ìñâ.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            
        Returns:
            ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠ÏùÑ Îã¥ÏùÄ ÎîïÏÖîÎÑàÎ¶¨
        """
        selections = {}
        
        # 1. ÌôòÍ≤Ω Ïù¥Î¶Ñ ÏûÖÎ†•
        if not env_name:
            env_name = self.ui.text_input(
                "ÌôòÍ≤Ω Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî (Ïòà: local, dev, prod)",
                default="local",
                validator=lambda x: len(x) > 0 and x.replace("-", "").replace("_", "").isalnum()
            )
        selections["env_name"] = env_name
        
        self.ui.print_divider()
        
        # 2. MLflow ÏÇ¨Ïö© Ïó¨Î∂Ä
        self.ui.show_info("MLflow ÏÑ§Ï†ï")
        use_mlflow = self.ui.confirm("MLflowÎ•º ÏÇ¨Ïö©ÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True)
        selections["use_mlflow"] = use_mlflow
        
        if use_mlflow:
            # MLflow Ï∂îÍ∞Ä ÏÑ§Ï†ï
            mlflow_tracking = self.ui.text_input(
                "MLflow Tracking URI",
                default="./mlruns" if env_name == "local" else "http://mlflow-server:5000"
            )
            selections["mlflow_tracking_uri"] = mlflow_tracking
        
        self.ui.print_divider()
        
        # 3. Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ†ÌÉù
        self.ui.show_info("Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ§Ï†ï")
        data_sources = [
            "PostgreSQL",
            "BigQuery", 
            "Local Files",
            "S3",
            "GCS"
        ]
        
        data_source = self.ui.select_from_list(
            "Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌï† ÏÜåÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            data_sources
        )
        selections["data_source"] = data_source
        
        # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î≥Ñ Ï∂îÍ∞Ä ÏÑ§Ï†ï
        if data_source == "PostgreSQL":
            selections["db_host"] = self.ui.text_input("Database Host", default="localhost")
            selections["db_port"] = self.ui.number_input("Database Port", default=5432)
            selections["db_name"] = self.ui.text_input("Database Name", default="mlpipeline")
        elif data_source == "BigQuery":
            selections["gcp_project"] = self.ui.text_input("GCP Project ID")
            selections["bq_dataset"] = self.ui.text_input("BigQuery Dataset", default="ml_dataset")
        elif data_source == "S3":
            selections["s3_bucket"] = self.ui.text_input("S3 Bucket Name")
            selections["aws_region"] = self.ui.text_input("AWS Region", default="us-east-1")
        elif data_source == "GCS":
            selections["gcp_project"] = self.ui.text_input("GCP Project ID")
            selections["gcs_bucket"] = self.ui.text_input("GCS Bucket Name")
        
        self.ui.print_divider()
        
        # 4. Feature Store ÏÑ†ÌÉù
        self.ui.show_info("Feature Store ÏÑ§Ï†ï")
        feature_stores = [
            "ÏóÜÏùå",
            "Feast"
        ]
        
        feature_store = self.ui.select_from_list(
            "Feature StoreÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            feature_stores
        )
        selections["feature_store"] = feature_store
        
        # Feature StoreÎ≥Ñ Ï∂îÍ∞Ä ÏÑ§Ï†ï
        if feature_store == "Feast":
            selections["feast_project"] = self.ui.text_input(
                "Feast Project Name",
                default=f"feast_{env_name}"
            )
            selections["feast_registry"] = self.ui.text_input(
                "Feast Registry Path",
                default="./feast_repo/registry.db"
            )
        
        self.ui.print_divider()
        
        # 5. Artifact Storage ÏÑ†ÌÉù
        self.ui.show_info("Artifact Storage ÏÑ§Ï†ï")
        
        if use_mlflow:
            storages = [
                "Local",
                "S3",
                "GCS"
            ]
            
            artifact_storage = self.ui.select_from_list(
                "MLflow ArtifactsÎ•º Ï†ÄÏû•Ìï† Ïä§ÌÜ†Î¶¨ÏßÄÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                storages
            )
            selections["artifact_storage"] = artifact_storage
            
            # StorageÎ≥Ñ Ï∂îÍ∞Ä ÏÑ§Ï†ï
            if artifact_storage == "S3":
                if "s3_bucket" not in selections:
                    selections["artifact_s3_bucket"] = self.ui.text_input(
                        "Artifact S3 Bucket",
                        default="mlflow-artifacts"
                    )
                    selections["artifact_aws_region"] = self.ui.text_input(
                        "AWS Region",
                        default="us-east-1"
                    )
            elif artifact_storage == "GCS":
                if "gcs_bucket" not in selections:
                    selections["artifact_gcs_bucket"] = self.ui.text_input(
                        "Artifact GCS Bucket",
                        default="mlflow-artifacts"
                    )
        
        self.ui.print_divider()
        
        # 6. Ï∂îÍ∞Ä ÏÑ§Ï†ï
        self.ui.show_info("Ï∂îÍ∞Ä ÏÑ§Ï†ï")
        
        # Serving ÏÑ§Ï†ï
        enable_serving = self.ui.confirm("API ServingÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=False)
        selections["enable_serving"] = enable_serving
        
        if enable_serving:
            selections["serving_port"] = self.ui.number_input(
                "API Serving Port",
                default=8000,
                min_value=1024,
                max_value=65535
            )
        
        # Hyperparameter Tuning ÏÑ§Ï†ï
        enable_tuning = self.ui.confirm(
            "Hyperparameter Tuning (Optuna)ÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
            default=False
        )
        selections["enable_hyperparameter_tuning"] = enable_tuning
        
        if enable_tuning:
            selections["tuning_timeout"] = self.ui.number_input(
                "Tuning Timeout (seconds)",
                default=300,
                min_value=60,
                max_value=3600
            )
        
        # Monitoring ÏÑ§Ï†ï
        enable_monitoring = self.ui.confirm("MonitoringÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=False)
        selections["enable_monitoring"] = enable_monitoring
        
        self.ui.print_divider()
        
        # ÏÑ†ÌÉù ÏÇ¨Ìï≠ ÌôïÏù∏
        self._show_selections_summary(selections)
        
        if not self.ui.confirm("\nÏù¥ ÏÑ§Ï†ïÏúºÎ°ú ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True):
            self.ui.show_warning("ÏÑ§Ï†ïÏù¥ Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§. Îã§Ïãú ÏãúÏûëÌï¥Ï£ºÏÑ∏Ïöî.")
            return self.run_interactive_flow(env_name)
        
        return selections
    
    def _show_selections_summary(self, selections: Dict[str, Any]) -> None:
        """
        ÏÑ†ÌÉù ÏÇ¨Ìï≠ ÏöîÏïΩ ÌëúÏãú.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
        """
        summary = f"""
ÌôòÍ≤Ω Ïù¥Î¶Ñ: {selections['env_name']}
MLflow ÏÇ¨Ïö©: {'Ïòà' if selections.get('use_mlflow') else 'ÏïÑÎãàÏò§'}
Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§: {selections.get('data_source', 'N/A')}
Feature Store: {selections.get('feature_store', 'ÏóÜÏùå')}
Artifact Storage: {selections.get('artifact_storage', 'Local')}
API Serving: {'ÌôúÏÑ±Ìôî' if selections.get('enable_serving') else 'ÎπÑÌôúÏÑ±Ìôî'}
Hyperparameter Tuning: {'ÌôúÏÑ±Ìôî' if selections.get('enable_hyperparameter_tuning') else 'ÎπÑÌôúÏÑ±Ìôî'}
Monitoring: {'ÌôúÏÑ±Ìôî' if selections.get('enable_monitoring') else 'ÎπÑÌôúÏÑ±Ìôî'}
"""
        self.ui.show_panel(summary, title="üìã ÏÑ§Ï†ï ÏöîÏïΩ", style="cyan")
    
    def generate_config_file(self, env_name: str, selections: Dict[str, Any]) -> Path:
        """
        ÏÑ§Ï†ï ÌååÏùº ÏÉùÏÑ±.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÏÉùÏÑ±Îêú ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        """
        # ÌÖúÌîåÎ¶ø Ïª®ÌÖçÏä§Ìä∏ Ï§ÄÎπÑ
        context = self._prepare_template_context(selections)
        
        # ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        config_dir = Path("configs")
        config_dir.mkdir(exist_ok=True)
        config_path = config_dir / f"{env_name}.yaml"
        
        # ÌÖúÌîåÎ¶ø Î†åÎçîÎßÅ Î∞è ÌååÏùº ÏÉùÏÑ±
        self.template_engine.write_rendered_file(
            "configs/config.yaml.j2",
            config_path,
            context
        )
        
        return config_path
    
    def generate_env_template(self, env_name: str, selections: Dict[str, Any]) -> Path:
        """
        ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÌååÏùº ÏÉùÏÑ±.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÏÉùÏÑ±Îêú ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÌååÏùº Í≤ΩÎ°ú
        """
        env_template_path = Path(f".env.{env_name}.template")
        
        # ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÎÇ¥Ïö© ÏÉùÏÑ±
        env_content = self._generate_env_template_content(selections)
        
        # ÌååÏùº Ïì∞Í∏∞
        env_template_path.write_text(env_content, encoding='utf-8')
        
        return env_template_path
    
    def _prepare_template_context(self, selections: Dict[str, Any]) -> Dict[str, Any]:
        """
        ÌÖúÌîåÎ¶ø Î†åÎçîÎßÅÏùÑ ÏúÑÌïú Ïª®ÌÖçÏä§Ìä∏ Ï§ÄÎπÑ.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÌÖúÌîåÎ¶ø Ïª®ÌÖçÏä§Ìä∏
        """
        context = selections.copy()
        context["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î≥Ñ ÌîåÎûòÍ∑∏ ÏÑ§Ï†ï
        data_source = selections.get("data_source", "")
        context["use_sql"] = data_source == "PostgreSQL"
        context["use_bq"] = data_source == "BigQuery"
        context["use_s3"] = data_source == "S3"
        context["use_gcs"] = data_source == "GCS"
        context["use_storage"] = data_source == "Local Files"
        context["use_azure"] = "Azure" in data_source
        
        # Feature Store ÌîåÎûòÍ∑∏
        feature_store = selections.get("feature_store", "ÏóÜÏùå")
        context["use_feast"] = feature_store == "Feast"
        
        # Storage ÌîåÎûòÍ∑∏
        artifact_storage = selections.get("artifact_storage", "Local")
        context["use_local_storage"] = artifact_storage == "Local"
        context["use_s3"] = artifact_storage == "S3"
        context["use_gcs"] = artifact_storage == "GCS"
        
        # Í∏∞ÌÉÄ ÌîåÎûòÍ∑∏
        context["use_redis"] = context.get("use_feast", False)  # Feast uses Redis for online store
        context["enable_auth"] = False  # Í∏∞Î≥∏Í∞í
        context["enable_grafana"] = context.get("enable_monitoring", False)
        
        # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï
        context.setdefault("serving_workers", 1)
        context.setdefault("model_stage", "None")
        context.setdefault("tuning_direction", "maximize")
        context.setdefault("tuning_jobs", 2)
        context.setdefault("prometheus_port", 9090)
        
        return context
    
    def _generate_env_template_content(self, selections: Dict[str, Any]) -> str:
        """
        ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÎÇ¥Ïö© ÏÉùÏÑ±.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÎÇ¥Ïö©
        """
        lines = [
            f"# Environment variables for {selections['env_name']}",
            f"# Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
        ]
        
        # MLflow ÏÑ§Ï†ï
        if selections.get("use_mlflow"):
            lines.extend([
                "# MLflow Configuration",
                f"MLFLOW_TRACKING_URI={selections.get('mlflow_tracking_uri', './mlruns')}",
                f"MLFLOW_EXPERIMENT_NAME=mmp-{selections['env_name']}",
                "",
            ])
        
        # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ§Ï†ï
        data_source = selections.get("data_source", "")
        
        if data_source == "PostgreSQL":
            lines.extend([
                "# PostgreSQL Configuration",
                f"DB_HOST={selections.get('db_host', 'localhost')}",
                f"DB_PORT={selections.get('db_port', 5432)}",
                f"DB_NAME={selections.get('db_name', 'mlpipeline')}",
                "DB_USER=your_username",
                "DB_PASSWORD=your_password",
                "",
            ])
        elif data_source == "BigQuery":
            lines.extend([
                "# BigQuery Configuration",
                f"GCP_PROJECT_ID={selections.get('gcp_project', '')}",
                f"BQ_DATASET_ID={selections.get('bq_dataset', 'ml_dataset')}",
                "BQ_LOCATION=US",
                "",
            ])
        elif data_source == "S3":
            lines.extend([
                "# S3 Configuration",
                f"S3_BUCKET={selections.get('s3_bucket', '')}",
                f"AWS_REGION={selections.get('aws_region', 'us-east-1')}",
                "AWS_ACCESS_KEY_ID=your_access_key",
                "AWS_SECRET_ACCESS_KEY=your_secret_key",
                "",
            ])
        elif data_source == "GCS":
            lines.extend([
                "# GCS Configuration",
                f"GCP_PROJECT_ID={selections.get('gcp_project', '')}",
                f"GCS_BUCKET={selections.get('gcs_bucket', '')}",
                "GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json",
                "",
            ])
        
        # Feature Store ÏÑ§Ï†ï
        feature_store = selections.get("feature_store", "ÏóÜÏùå")
        
        if feature_store == "Feast":
            feast_project = selections.get('feast_project', f"feast_{selections['env_name']}")
            lines.extend([
                "# Feast Configuration",
                f"FEAST_PROJECT={feast_project}",
                f"FEAST_REGISTRY_PATH={selections.get('feast_registry', './feast_repo/registry.db')}",
                "REDIS_HOST=localhost",
                "REDIS_PORT=6379",
                "",
            ])
        
        # Artifact Storage ÏÑ§Ï†ï
        artifact_storage = selections.get("artifact_storage", "Local")
        
        if artifact_storage == "S3" and "artifact_s3_bucket" in selections:
            lines.extend([
                "# Artifact Storage (S3)",
                f"ARTIFACT_S3_BUCKET={selections.get('artifact_s3_bucket', 'mlflow-artifacts')}",
                f"ARTIFACT_AWS_REGION={selections.get('artifact_aws_region', 'us-east-1')}",
                "",
            ])
        elif artifact_storage == "GCS" and "artifact_gcs_bucket" in selections:
            lines.extend([
                "# Artifact Storage (GCS)",
                f"ARTIFACT_GCS_BUCKET={selections.get('artifact_gcs_bucket', 'mlflow-artifacts')}",
                "",
            ])

        # API Serving ÏÑ§Ï†ï
        if selections.get("enable_serving"):
            lines.extend([
                "# API Serving Configuration",
                "API_HOST=0.0.0.0",
                f"API_PORT={selections.get('serving_port', 8000)}",
                "API_WORKERS=1",
                "",
            ])
        
        # Hyperparameter Tuning ÏÑ§Ï†ï
        if selections.get("enable_hyperparameter_tuning"):
            lines.extend([
                "# Hyperparameter Tuning Configuration (Optuna)",
                f"HYPERPARAM_TIMEOUT={selections.get('tuning_timeout', 300)}",
                "HYPERPARAM_JOBS=2",
                f"OPTUNA_STUDY_NAME=mmp_{selections['env_name']}_study",
                "OPTUNA_STORAGE=sqlite:///optuna.db",
            ])
            
            lines.append("")
        
        # Monitoring ÏÑ§Ï†ï
        if selections.get("enable_monitoring"):
            lines.extend([
                "# Monitoring Configuration",
                f"METRICS_PORT={selections.get('prometheus_port', 9090)}",
                "GRAFANA_HOST=localhost",
                "GRAFANA_PORT=3000",
                "COLLECT_SYSTEM_METRICS=true",
                "COLLECT_MODEL_METRICS=true",
                "COLLECT_DATA_METRICS=true",
                "",
            ])
        
        return "\n".join(lines)