"""
Config Builder for Modern ML Pipeline CLI
Phase 3: Interactive configuration file generation

CLAUDE.md ÏõêÏπô Ï§ÄÏàò:
- ÌÉÄÏûÖ ÌûåÌä∏ ÌïÑÏàò
- Google Style Docstring
- ÎåÄÌôîÌòï Ïù∏ÌÑ∞ÌéòÏù¥Ïä§
"""

from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

from src.cli.utils.interactive_ui import InteractiveUI
from src.cli.utils.template_engine import TemplateEngine


class InteractiveConfigBuilder:
    """ÎåÄÌôîÌòï ÌôòÍ≤Ω ÏÑ§Ï†ï ÎπåÎçî.
    
    ÏÇ¨Ïö©ÏûêÏôÄÏùò ÎåÄÌôîÌòï Ïù∏ÌÑ∞ÌéòÏù¥Ïä§Î•º ÌÜµÌï¥ ÌôòÍ≤ΩÎ≥Ñ ÏÑ§Ï†ï ÌååÏùºÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
    """
    
    def __init__(self):
        """InteractiveConfigBuilder Ï¥àÍ∏∞Ìôî."""
        self.ui = InteractiveUI()
        templates_dir = Path(__file__).parent.parent / "templates"
        self.template_engine = TemplateEngine(templates_dir)
    
    def run_interactive_flow(self, env_name: Optional[str] = None) -> Dict[str, Any]:
        """
        ÎåÄÌôîÌòï ÏÑ§Ï†ï ÌîåÎ°úÏö∞ Ïã§Ìñâ.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ (ÏÑ†ÌÉùÏÇ¨Ìï≠)
            
        Returns:
            ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠ÏùÑ Îã¥ÏùÄ ÎîïÏÖîÎÑàÎ¶¨
        """
        selections = {}
        
        # 1. ÌôòÍ≤Ω Ïù¥Î¶Ñ ÏûÖÎ†•
        if not env_name:
            env_name = self.ui.text_input(
                "ÌôòÍ≤Ω Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî (Ïòà: local, dev, prod)",
                default="local",
                validator=lambda x: len(x) > 0 and x.replace("-", "").replace("_", "").isalnum()
            )
        selections["env_name"] = env_name
        
        self.ui.print_divider()
        
        # 2. MLflow ÏÇ¨Ïö© Ïó¨Î∂Ä
        self.ui.show_info("MLflow ÏÑ§Ï†ï")
        use_mlflow = self.ui.confirm("MLflowÎ•º ÏÇ¨Ïö©ÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True)
        selections["use_mlflow"] = use_mlflow
        
        if use_mlflow:
            # MLflow Ï∂îÍ∞Ä ÏÑ§Ï†ï
            mlflow_tracking = self.ui.text_input(
                "MLflow Tracking URI",
                default="./mlruns" if env_name == "local" else "http://mlflow-server:5000"
            )
            selections["mlflow_tracking_uri"] = mlflow_tracking
        
        self.ui.print_divider()
        
        # 3. Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ†ÌÉù
        self.ui.show_info("Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ§Ï†ï")
        data_sources = [
            "PostgreSQL",
            "BigQuery", 
            "Local Files",
            "S3",
            "GCS"
        ]
        
        data_source = self.ui.select_from_list(
            "Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌï† ÏÜåÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            data_sources
        )
        selections["data_source"] = data_source
        
        # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÌÉÄÏûÖÎßå Ï†ÄÏû• (Íµ¨Ï≤¥Ï†Å ÏÑ§Ï†ïÏùÄ .env ÌååÏùºÏóêÏÑú)
        
        self.ui.print_divider()
        
        # 4. Feature Store ÏÑ†ÌÉù
        self.ui.show_info("Feature Store ÏÑ§Ï†ï")
        feature_stores = [
            "ÏóÜÏùå",
            "Feast"
        ]
        
        feature_store = self.ui.select_from_list(
            "Feature StoreÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            feature_stores
        )
        selections["feature_store"] = feature_store
        
        # Feature StoreÎ≥Ñ Ï∂îÍ∞Ä ÏÑ§Ï†ï
        if feature_store == "Feast":
            # Registry ÏúÑÏπò ÏÑ†ÌÉù
            registry_location = self.ui.select_from_list(
                "Feast Registry Ï†ÄÏû• ÏúÑÏπò",
                ["Î°úÏª¨", "S3", "GCS"]
            )
            selections["feast_registry_location"] = registry_location
            
            # Offline StoreÎäî data_sourceÏóê Îî∞Îùº ÏûêÎèô Í≤∞Ï†ï
            self.ui.show_info(f"Offline StoreÎäî {data_source}Ïóê Îî∞Îùº ÏûêÎèô ÏÑ§Ï†ïÎê©ÎãàÎã§.")
            
            # Offline StoreÍ∞Ä FileÏù∏ Í≤ΩÏö∞
            if data_source in ["PostgreSQL", "Local Files", "S3", "GCS"]:
                self.ui.show_info("Offline StoreÎäî Parquet ÌååÏùº ÌòïÏãùÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.")
                selections["feast_needs_offline_path"] = True
            
            # Online Store ÏÑ§Ï†ï
            use_online_store = self.ui.confirm(
                "Online StoreÎ•º ÏÇ¨Ïö©ÌïòÏãúÍ≤†ÏäµÎãàÍπå? (Ïã§ÏãúÍ∞Ñ ÏÑúÎπôÏö©)",
                default=False
            )
            
            if use_online_store:
                online_store_type = self.ui.select_from_list(
                    "Online Store ÌÉÄÏûÖ",
                    ["Redis", "SQLite", "DynamoDB"]
                )
                selections["feast_online_store"] = online_store_type
            else:
                selections["feast_online_store"] = "SQLite"
        
        self.ui.print_divider()
        
        # 5. Artifact Storage ÏÑ†ÌÉù
        self.ui.show_info("Artifact Storage ÏÑ§Ï†ï")
        
        if use_mlflow:
            storages = [
                "Local",
                "S3",
                "GCS"
            ]
            
            artifact_storage = self.ui.select_from_list(
                "MLflow ArtifactsÎ•º Ï†ÄÏû•Ìï† Ïä§ÌÜ†Î¶¨ÏßÄÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                storages
            )
            selections["artifact_storage"] = artifact_storage
            # StorageÎ≥Ñ Íµ¨Ï≤¥Ï†Å ÏÑ§Ï†ïÏùÄ .env ÌååÏùºÏóêÏÑú
        
        self.ui.print_divider()
        
        # 6. Output targets ÏÑ§Ï†ï
        self.ui.show_info("Output Ï†ÄÏû• ÏÑ§Ï†ï")
        # Inference output
        infer_enabled = self.ui.confirm("Î∞∞Ïπò Ï∂îÎ°† Í≤∞Í≥ºÎ•º Ï†ÄÏû•ÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True)
        selections["inference_output_enabled"] = infer_enabled
        if infer_enabled:
            infer_source = self.ui.select_from_list(
                "Ï∂îÎ°† Í≤∞Í≥º Ï†ÄÏû• Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                ["PostgreSQL", "BigQuery", "Local Files", "S3", "GCS"]
            )
            selections["inference_output_source"] = infer_source
        
        # Preprocessed output
        preproc_enabled = self.ui.confirm("Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å Í≤∞Í≥ºÎ•º Ï†ÄÏû•ÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True)
        selections["preproc_output_enabled"] = preproc_enabled
        if preproc_enabled:
            preproc_source = self.ui.select_from_list(
                "Ï†ÑÏ≤òÎ¶¨ Í≤∞Í≥º Ï†ÄÏû• Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                ["PostgreSQL", "BigQuery", "Local Files", "S3", "GCS"]
            )
            selections["preproc_output_source"] = preproc_source
        
        self.ui.print_divider()
        
        # ÏÑ†ÌÉù ÏÇ¨Ìï≠ ÌôïÏù∏
        self._show_selections_summary(selections)
        
        if not self.ui.confirm("\nÏù¥ ÏÑ§Ï†ïÏúºÎ°ú ÏßÑÌñâÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True):
            self.ui.show_warning("ÏÑ§Ï†ïÏù¥ Ï∑®ÏÜåÎêòÏóàÏäµÎãàÎã§. Îã§Ïãú ÏãúÏûëÌï¥Ï£ºÏÑ∏Ïöî.")
            return self.run_interactive_flow(env_name)
        
        return selections
    
    def _show_selections_summary(self, selections: Dict[str, Any]) -> None:
        """
        ÏÑ†ÌÉù ÏÇ¨Ìï≠ ÏöîÏïΩ ÌëúÏãú.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
        """
        summary = f"""
ÌôòÍ≤Ω Ïù¥Î¶Ñ: {selections['env_name']}
MLflow ÏÇ¨Ïö©: {'Ïòà' if selections.get('use_mlflow') else 'ÏïÑÎãàÏò§'}
Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§: {selections.get('data_source', 'N/A')}
Feature Store: {selections.get('feature_store', 'ÏóÜÏùå')}
Artifact Storage: {selections.get('artifact_storage', 'Local')}
API Serving: {'ÌôúÏÑ±Ìôî' if selections.get('enable_serving') else 'ÎπÑÌôúÏÑ±Ìôî'}
Inference Output: {selections.get('inference_output_source', 'Disabled' if not selections.get('inference_output_enabled', True) else 'Local Files')}
Preprocessed Output: {selections.get('preproc_output_source', 'Disabled' if not selections.get('preproc_output_enabled', True) else 'Local Files')}
"""
        self.ui.show_panel(summary, title="üìã ÏÑ§Ï†ï ÏöîÏïΩ", style="cyan")
    
    def generate_config_file(self, env_name: str, selections: Dict[str, Any]) -> Path:
        """
        ÏÑ§Ï†ï ÌååÏùº ÏÉùÏÑ±.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÏÉùÏÑ±Îêú ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        """
        # ÌÖúÌîåÎ¶ø Ïª®ÌÖçÏä§Ìä∏ Ï§ÄÎπÑ
        context = self._prepare_template_context(selections)
        
        # ÏÑ§Ï†ï ÌååÏùº Í≤ΩÎ°ú
        config_dir = Path("configs")
        config_dir.mkdir(exist_ok=True)
        config_path = config_dir / f"{env_name}.yaml"
        
        # ÌÖúÌîåÎ¶ø Î†åÎçîÎßÅ Î∞è ÌååÏùº ÏÉùÏÑ±
        self.template_engine.write_rendered_file(
            "configs/config.yaml.j2",
            config_path,
            context
        )
        
        return config_path
    
    def generate_env_template(self, env_name: str, selections: Dict[str, Any]) -> Path:
        """
        ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÌååÏùº ÏÉùÏÑ±.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÏÉùÏÑ±Îêú ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÌååÏùº Í≤ΩÎ°ú
        """
        env_template_path = Path(f".env.{env_name}.template")
        
        # ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÎÇ¥Ïö© ÏÉùÏÑ±
        env_content = self._generate_env_template_content(selections)
        
        # ÌååÏùº Ïì∞Í∏∞
        env_template_path.write_text(env_content, encoding='utf-8')
        
        return env_template_path
    
    def _prepare_template_context(self, selections: Dict[str, Any]) -> Dict[str, Any]:
        """
        ÌÖúÌîåÎ¶ø Î†åÎçîÎßÅÏùÑ ÏúÑÌïú Ïª®ÌÖçÏä§Ìä∏ Ï§ÄÎπÑ.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÌÖúÌîåÎ¶ø Ïª®ÌÖçÏä§Ìä∏
        """
        context = selections.copy()
        context["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # Feature Store ÌîåÎûòÍ∑∏
        feature_store = selections.get("feature_store", "ÏóÜÏùå")
        context["use_feast"] = feature_store == "Feast"
        
        # Í∏∞ÌÉÄ ÌîåÎûòÍ∑∏
        context["enable_auth"] = False  # Í∏∞Î≥∏Í∞í
        
        # Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï
        context.setdefault("serving_workers", 1)
        context.setdefault("model_stage", "None")
        
        # Output sources (ÌÖúÌîåÎ¶ø Î∂ÑÍ∏∞Ïö©)
        if selections.get("inference_output_enabled", True):
            context["inference_output_source"] = selections.get("inference_output_source", "Local Files")
        if selections.get("preproc_output_enabled", True):
            context["preproc_output_source"] = selections.get("preproc_output_source", "Local Files")
        
        return context
    
    def _generate_env_template_content(self, selections: Dict[str, Any]) -> str:
        """
        ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÎÇ¥Ïö© ÏÉùÏÑ±.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÌôòÍ≤Ω Î≥ÄÏàò ÌÖúÌîåÎ¶ø ÎÇ¥Ïö©
        """
        lines = [
            f"# Environment variables for {selections['env_name']}",
            f"# Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            "",
        ]
        
        # MLflow ÏÑ§Ï†ï
        if selections.get("use_mlflow"):
            lines.extend([
                "# MLflow Configuration",
                "MLFLOW_TRACKING_URI=./mlruns  # or http://mlflow-server:5000",
                f"MLFLOW_EXPERIMENT_NAME=mmp-{selections['env_name']}",
                "# Optional MLflow authentication",
                "MLFLOW_TRACKING_USERNAME=",
                "MLFLOW_TRACKING_PASSWORD=",
                "# Optional S3-compatible storage",
                "MLFLOW_S3_ENDPOINT_URL=",
                "",
            ])
        
        # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ§Ï†ï
        data_source = selections.get("data_source", "")
        
        if data_source == "PostgreSQL":
            lines.extend([
                "# PostgreSQL Configuration",
                "DB_HOST=localhost",
                "DB_PORT=5432",
                "DB_NAME=mlpipeline",
                "DB_USER=your_username",
                "DB_PASSWORD=your_password",
                "DB_TIMEOUT=30",
                "",
            ])
        elif data_source == "BigQuery":
            lines.extend([
                "# BigQuery Configuration",
                "GCP_PROJECT_ID=your-project-id",
                "BQ_DATASET_ID=ml_dataset",
                "BQ_LOCATION=US",
                "BQ_TIMEOUT=30",
                "",
            ])
        elif data_source == "S3":
            lines.extend([
                "# S3 Configuration",
                "S3_BUCKET=your-data-bucket",
                f"S3_PREFIX={selections['env_name']}",
                "AWS_REGION=us-east-1",
                "AWS_ACCESS_KEY_ID=your_access_key",
                "AWS_SECRET_ACCESS_KEY=your_secret_key",
                "",
            ])
        elif data_source == "GCS":
            lines.extend([
                "# GCS Configuration",
                "GCP_PROJECT_ID=your-project-id",
                "GCS_BUCKET=your-data-bucket",
                f"GCS_PREFIX={selections['env_name']}",
                "GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json",
                "",
            ])
        elif data_source == "Local Files":
            lines.extend([
                "# Local Files Configuration",
                "DATA_PATH=./data",
                "",
            ])
        
        # Feature Store ÏÑ§Ï†ï
        feature_store = selections.get("feature_store", "ÏóÜÏùå")
        
        if feature_store == "Feast":
            lines.extend([
                "# Feast Configuration",
                f"FEAST_PROJECT=feast_{selections['env_name']}",
                "",
            ])
            
            # Registry ÏÑ§Ï†ï
            registry_location = selections.get("feast_registry_location", "Î°úÏª¨")
            if registry_location == "Î°úÏª¨":
                lines.extend([
                    "# Feast Registry (Local)",
                    "FEAST_REGISTRY_PATH=./feast_repo/registry.db",
                    "",
                ])
            elif registry_location == "S3":
                lines.extend([
                    "# Feast Registry (S3)",
                    f"FEAST_REGISTRY_PATH=s3://your-bucket/feast-registry/{selections['env_name']}/registry.db",
                    "",
                ])
            else:  # GCS
                lines.extend([
                    "# Feast Registry (GCS)",
                    f"FEAST_REGISTRY_PATH=gs://your-bucket/feast-registry/{selections['env_name']}/registry.db",
                    "",
                ])
            
            # Offline Store ÏÑ§Ï†ï (File ÌÉÄÏûÖÏù∏ Í≤ΩÏö∞)
            if selections.get("feast_needs_offline_path"):
                lines.extend([
                    "# Feast Offline Store (Parquet files)",
                    "FEAST_OFFLINE_PATH=./feast_repo/data",
                    "",
                ])
            
            # Online Store ÏÑ§Ï†ï
            online_store = selections.get("feast_online_store", "SQLite")
            if online_store == "Redis":
                lines.extend([
                    "# Feast Online Store (Redis)",
                    "REDIS_HOST=localhost",
                    "REDIS_PORT=6379",
                    "REDIS_PASSWORD=",  # Optional
                    "",
                ])
            elif online_store == "DynamoDB":
                lines.extend([
                    "# Feast Online Store (DynamoDB)",
                    "DYNAMODB_REGION=us-east-1",
                    "DYNAMODB_TABLE_NAME=feast-online-store",
                    "",
                ])
            else:  # SQLite
                lines.extend([
                    "# Feast Online Store (SQLite)",
                    "FEAST_ONLINE_STORE_PATH=./feast_repo/online_store.db",
                    "",
                ])
        
        # Artifact Storage ÏÑ§Ï†ï
        artifact_storage = selections.get("artifact_storage", "Local")
        
        if artifact_storage == "S3":
            lines.extend([
                "# MLflow Artifact Storage (S3)",
                "ARTIFACT_S3_BUCKET=mlflow-artifacts",
                f"ARTIFACT_S3_PREFIX={selections['env_name']}",
                "# Reuse AWS credentials from data source if same",
                "",
            ])
        elif artifact_storage == "GCS":
            lines.extend([
                "# MLflow Artifact Storage (GCS)",
                "ARTIFACT_GCS_BUCKET=mlflow-artifacts",
                f"ARTIFACT_GCS_PREFIX={selections['env_name']}",
                "# Reuse GCP credentials from data source if same",
                "",
            ])
        elif artifact_storage == "Local":
            lines.extend([
                "# MLflow Artifact Storage (Local)",
                "MLFLOW_ARTIFACT_PATH=./mlruns/artifacts",
                "",
            ])
        
        # API Serving ÏÑ§Ï†ï
        if selections.get("enable_serving"):
            lines.extend([
                "# API Serving Configuration",
                "API_HOST=0.0.0.0",
                "API_PORT=8000",
                "API_WORKERS=1",
                "",
            ])
        
        # Output: Inference
        infer_enabled = selections.get("inference_output_enabled", True)
        lines.extend([
            "# Inference Output",
            f"INFER_OUTPUT_ENABLED={'true' if infer_enabled else 'false'}",
        ])
        if infer_enabled:
            infer_src = selections.get("inference_output_source", "Local Files")
            if infer_src == "Local Files":
                lines.extend([
                    "INFER_OUTPUT_BASE_PATH=./artifacts/predictions",
                    "",
                ])
            elif infer_src == "S3":
                lines.extend([
                    "INFER_OUTPUT_S3_BUCKET=mmp-out",
                    f"INFER_OUTPUT_S3_PREFIX={selections['env_name']}/preds",
                    "# AWS credentials (if not already set above)",
                    "AWS_ACCESS_KEY_ID=",
                    "AWS_SECRET_ACCESS_KEY=",
                    "AWS_REGION=us-east-1",
                    "",
                ])
            elif infer_src == "GCS":
                lines.extend([
                    "INFER_OUTPUT_GCS_BUCKET=mmp-out",
                    f"INFER_OUTPUT_GCS_PREFIX={selections['env_name']}/preds",
                    "# GCP credentials (if not already set above)",
                    "GCP_PROJECT_ID=",
                    "GOOGLE_APPLICATION_CREDENTIALS=",
                    "",
                ])
            elif infer_src == "PostgreSQL":
                lines.extend([
                    f"INFER_OUTPUT_PG_TABLE=predictions_{selections['env_name']}",
                    "# Reuse DB_* settings above",
                    "",
                ])
            else:  # BigQuery
                lines.extend([
                    "INFER_OUTPUT_BQ_DATASET=analytics",
                    f"INFER_OUTPUT_BQ_TABLE=predictions_{selections['env_name']}",
                    "# Reuse GCP credentials above",
                    "BQ_LOCATION=US",
                    "",
                ])
        
        # Output: Preprocessed
        preproc_enabled = selections.get("preproc_output_enabled", True)
        lines.extend([
            "# Preprocessed Output",
            f"PREPROC_OUTPUT_ENABLED={'true' if preproc_enabled else 'false'}",
        ])
        if preproc_enabled:
            pre_src = selections.get("preproc_output_source", "Local Files")
            if pre_src == "Local Files":
                lines.extend([
                    "PREPROC_OUTPUT_BASE_PATH=./artifacts/preprocessed",
                    "",
                ])
            elif pre_src == "S3":
                lines.extend([
                    "PREPROC_OUTPUT_S3_BUCKET=mmp-out",
                    f"PREPROC_OUTPUT_S3_PREFIX={selections['env_name']}/preproc",
                    "# AWS credentials (if not already set above)",
                    "AWS_ACCESS_KEY_ID=",
                    "AWS_SECRET_ACCESS_KEY=",
                    "AWS_REGION=us-east-1",
                    "",
                ])
            elif pre_src == "GCS":
                lines.extend([
                    "PREPROC_OUTPUT_GCS_BUCKET=mmp-out",
                    f"PREPROC_OUTPUT_GCS_PREFIX={selections['env_name']}/preproc",
                    "# GCP credentials (if not already set above)",
                    "GCP_PROJECT_ID=",
                    "GOOGLE_APPLICATION_CREDENTIALS=",
                    "",
                ])
            elif pre_src == "PostgreSQL":
                lines.extend([
                    f"PREPROC_OUTPUT_PG_TABLE=preprocessed_{selections['env_name']}",
                    "# Reuse DB_* settings above",
                    "",
                ])
            else:  # BigQuery
                lines.extend([
                    "PREPROC_OUTPUT_BQ_DATASET=feature_store",
                    f"PREPROC_OUTPUT_BQ_TABLE=preprocessed_{selections['env_name']}",
                    "# Reuse GCP credentials above",
                    "BQ_LOCATION=US",
                    "",
                ])
        
        return "\n".join(lines)