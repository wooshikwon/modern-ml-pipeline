"""
Interactive Config Builder
Phase 1: ÎåÄÌôîÌòï ÏÑ§Ï†ï ÏÉùÏÑ±Í∏∞

CLAUDE.md ÏõêÏπô Ï§ÄÏàò:
- ÌÉÄÏûÖ ÌûåÌä∏ ÌïÑÏàò
- Google Style Docstring
- TDD Í∏∞Î∞ò Í∞úÎ∞ú
"""

from typing import Dict, Any, List, Optional, Tuple
import yaml
from pathlib import Path
from jinja2 import Environment, FileSystemLoader, select_autoescape
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.table import Table

from src.cli.ui.interactive_selector import InteractiveSelector


class InteractiveConfigBuilder:
    """ÎåÄÌôîÌòï Config ÎπåÎçî."""
    
    def __init__(self) -> None:
        """Initialize InteractiveConfigBuilder."""
        self.console = Console()
        self.selector = InteractiveSelector()
        
        # Setup Jinja2 environment
        template_dir = Path(__file__).parent.parent / 'templates' / 'configs'
        self.jinja_env = Environment(
            loader=FileSystemLoader(str(template_dir)),
            autoescape=select_autoescape(['yaml', 'yml']),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
    def run_interactive_flow(self, env_name: Optional[str] = None) -> Dict[str, Any]:
        """
        Ï†ÑÏ≤¥ ÎåÄÌôîÌòï ÌîåÎ°úÏö∞ Ïã§Ìñâ.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ (ÏÑ†ÌÉùÏ†Å)
            
        Returns:
            ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠ÏùÑ Îã¥ÏùÄ ÎîïÏÖîÎÑàÎ¶¨
        """
        selections = {}
        
        # 1. Í∏∞Î≥∏ Ï†ïÎ≥¥
        self.console.print("\n[bold cyan]üè∑Ô∏è Í∏∞Î≥∏ Ï†ïÎ≥¥[/bold cyan]")
        selections['env_name'] = env_name or Prompt.ask(
            "ÌôòÍ≤Ω Ïù¥Î¶ÑÏùÑ ÏûÖÎ†•ÌïòÏÑ∏Ïöî", 
            default="local"
        )
        
        # 2. Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§
        self.console.print("\n[bold cyan]üóÑÔ∏è Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ§Ï†ï[/bold cyan]")
        selections.update(self._select_data_source())
        
        # 3. MLflow
        self.console.print("\n[bold cyan]üìä MLflow ÏÑ§Ï†ï[/bold cyan]")
        selections.update(self._select_mlflow())
        
        # 4. Feature Store
        self.console.print("\n[bold cyan]üéØ Feature Store ÏÑ§Ï†ï[/bold cyan]")
        selections.update(self._select_feature_store())
        
        # 5. ÏïÑÌã∞Ìå©Ìä∏ Ï†ÄÏû•ÏÜå
        self.console.print("\n[bold cyan]üíæ ÏïÑÌã∞Ìå©Ìä∏ Ï†ÄÏû•ÏÜå ÏÑ§Ï†ï[/bold cyan]")
        selections.update(self._select_storage())
        
        # 6. Í≥†Í∏â ÏÑ§Ï†ï
        if Confirm.ask("\n‚öôÔ∏è Í≥†Í∏â ÏÑ§Ï†ïÏùÑ Íµ¨ÏÑ±ÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=False):
            selections.update(self._advanced_settings())
        
        return selections
    
    def _select_data_source(self) -> Dict[str, Any]:
        """
        Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ ÏÑ†ÌÉù Î∞è ÏÑ§Ï†ï.
        
        Returns:
            Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        options = [
            ("PostgreSQL (Î°úÏª¨ Í∞úÎ∞úÏö©)", "postgresql"),
            ("MySQL (ÌåÄ Í∞úÎ∞ú ÏÑúÎ≤Ñ)", "mysql"),
            ("BigQuery (GCP ÌîÑÎ°úÎçïÏÖò)", "bigquery"),
            ("SQLite (ÌÖåÏä§Ìä∏Ïö©)", "sqlite"),
        ]
        
        data_source = self.selector.select(
            "Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            options
        )
        
        config = {'data_source': data_source}
        
        # Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§Î≥Ñ Ï∂îÍ∞Ä ÏÑ§Ï†ï
        if data_source == 'postgresql':
            config['db_host'] = Prompt.ask("  Ìò∏Ïä§Ìä∏", default="localhost")
            config['db_port'] = Prompt.ask("  Ìè¨Ìä∏", default="5432")
            config['db_name'] = Prompt.ask("  Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î™Ö", default="mlflow")
            config['db_user'] = Prompt.ask("  ÏÇ¨Ïö©ÏûêÎ™Ö", default="postgres")
            config['db_connection_uri'] = (
                f"postgresql://${{DB_USER:={config['db_user']}}}:${{DB_PASSWORD}}@"
                f"{config['db_host']}:{config['db_port']}/{config['db_name']}"
            )
        elif data_source == 'mysql':
            config['db_host'] = Prompt.ask("  Ìò∏Ïä§Ìä∏", default="localhost")
            config['db_port'] = Prompt.ask("  Ìè¨Ìä∏", default="3306")
            config['db_name'] = Prompt.ask("  Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Î™Ö", default="mlflow")
            config['db_user'] = Prompt.ask("  ÏÇ¨Ïö©ÏûêÎ™Ö", default="root")
            config['db_connection_uri'] = (
                f"mysql+pymysql://${{DB_USER:={config['db_user']}}}:${{DB_PASSWORD}}@"
                f"{config['db_host']}:{config['db_port']}/{config['db_name']}"
            )
        elif data_source == 'bigquery':
            config['bq_project'] = Prompt.ask("  GCP ÌîÑÎ°úÏ†ùÌä∏ ID", default="your-project")
            config['bq_dataset'] = Prompt.ask("  BigQuery Îç∞Ïù¥ÌÑ∞ÏÖã", default="ml_data")
            config['db_connection_uri'] = f"bigquery://{config['bq_project']}/{config['bq_dataset']}"
        elif data_source == 'sqlite':
            config['db_path'] = Prompt.ask("  Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌååÏùº Í≤ΩÎ°ú", default="./data/mlflow.db")
            config['db_connection_uri'] = f"sqlite:///{config['db_path']}"
        
        return config
    
    def _select_mlflow(self) -> Dict[str, Any]:
        """
        MLflow ÏÑ§Ï†ï ÏÑ†ÌÉù.
        
        Returns:
            MLflow Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        options = [
            ("Local (./mlruns)", "local"),
            ("Remote Server", "remote"),
            ("Cloud Storage (GCS/S3)", "cloud"),
        ]
        
        mlflow_type = self.selector.select(
            "MLflow Tracking Î∞©ÏãùÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            options
        )
        
        config = {'mlflow_type': mlflow_type}
        
        if mlflow_type == 'local':
            config['mlflow_uri'] = Prompt.ask("  Ï†ÄÏû• Í≤ΩÎ°ú", default="./mlruns")
            config['mlflow_experiment'] = Prompt.ask("  Í∏∞Î≥∏ Experiment Ïù¥Î¶Ñ", default="${ENV_NAME}-experiment")
        elif mlflow_type == 'remote':
            config['mlflow_uri'] = Prompt.ask("  ÏÑúÎ≤Ñ URL", default="http://localhost:5000")
            config['mlflow_experiment'] = Prompt.ask("  Í∏∞Î≥∏ Experiment Ïù¥Î¶Ñ", default="${ENV_NAME}-experiment")
        elif mlflow_type == 'cloud':
            storage_type = self.selector.select(
                "  ÌÅ¥ÎùºÏö∞Îìú Ïä§ÌÜ†Î¶¨ÏßÄ ÌÉÄÏûÖ",
                [("Google Cloud Storage", "gcs"), ("AWS S3", "s3")]
            )
            if storage_type == 'gcs':
                config['mlflow_uri'] = Prompt.ask("    GCS Î≤ÑÌÇ∑ Í≤ΩÎ°ú", default="gs://your-bucket/mlflow")
            else:
                config['mlflow_uri'] = Prompt.ask("    S3 Î≤ÑÌÇ∑ Í≤ΩÎ°ú", default="s3://your-bucket/mlflow")
            config['mlflow_experiment'] = Prompt.ask("  Í∏∞Î≥∏ Experiment Ïù¥Î¶Ñ", default="${ENV_NAME}-experiment")
        
        return config
    
    def _select_feature_store(self) -> Dict[str, Any]:
        """
        Feature Store ÏÑ§Ï†ï ÏÑ†ÌÉù.
        
        Returns:
            Feature Store Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        config = {}
        
        if Confirm.ask("Feature StoreÎ•º ÏÇ¨Ïö©ÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True):
            config['feature_store_enabled'] = True
            
            # Offline Store (Ìï≠ÏÉÅ ÌïÑÏöî)
            self.console.print("\n  [cyan]Offline Store ÏÑ§Ï†ï[/cyan]")
            config['offline_store_type'] = 'file'  # Í∏∞Î≥∏Í∞í
            config['offline_store_path'] = Prompt.ask("    Ï†ÄÏû• Í≤ΩÎ°ú", default="./feature_repo/data")
            
            # Online Store
            self.console.print("\n  [cyan]Online Store ÏÑ§Ï†ï[/cyan]")
            options = [
                ("Redis (Ïã§ÏãúÍ∞Ñ ÏÑúÎπô)", "redis"),
                ("SQLite (Í∞úÎ∞úÏö©)", "sqlite"),
                ("None (Î∞∞Ïπò Ï∂îÎ°†Îßå)", "none"),
            ]
            
            online_store = self.selector.select(
                "    Online StoreÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                options
            )
            
            config['online_store_type'] = online_store
            
            if online_store == 'redis':
                config['redis_host'] = Prompt.ask("    Redis Ìò∏Ïä§Ìä∏", default="localhost")
                config['redis_port'] = Prompt.ask("    Redis Ìè¨Ìä∏", default="6379")
                config['redis_db'] = Prompt.ask("    Redis DB Î≤àÌò∏", default="0")
            elif online_store == 'sqlite':
                config['sqlite_path'] = Prompt.ask("    SQLite Í≤ΩÎ°ú", default="./feature_repo/online_store.db")
        else:
            config['feature_store_enabled'] = False
        
        return config
    
    def _select_storage(self) -> Dict[str, Any]:
        """
        ÏïÑÌã∞Ìå©Ìä∏ Ï†ÄÏû•ÏÜå ÏÑ§Ï†ï ÏÑ†ÌÉù.
        
        Returns:
            Ïä§ÌÜ†Î¶¨ÏßÄ Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        options = [
            ("Local (./data)", "local"),
            ("Google Cloud Storage", "gcs"),
            ("AWS S3", "s3"),
        ]
        
        storage_type = self.selector.select(
            "ÏïÑÌã∞Ìå©Ìä∏ Ï†ÄÏû•ÏÜåÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            options
        )
        
        config = {'storage_type': storage_type}
        
        if storage_type == 'local':
            config['storage_path'] = Prompt.ask("  Ï†ÄÏû• Í≤ΩÎ°ú", default="./data")
        elif storage_type == 'gcs':
            config['gcs_bucket'] = Prompt.ask("  GCS Î≤ÑÌÇ∑ Ïù¥Î¶Ñ", default="your-bucket")
            config['gcs_prefix'] = Prompt.ask("  Î≤ÑÌÇ∑ ÎÇ¥ Í≤ΩÎ°ú", default="ml-artifacts")
        elif storage_type == 's3':
            config['s3_bucket'] = Prompt.ask("  S3 Î≤ÑÌÇ∑ Ïù¥Î¶Ñ", default="your-bucket")
            config['s3_prefix'] = Prompt.ask("  Î≤ÑÌÇ∑ ÎÇ¥ Í≤ΩÎ°ú", default="ml-artifacts")
        
        return config
    
    def _select_serving(self) -> Dict[str, Any]:
        """
        API Serving ÏÑ§Ï†ï ÏÑ†ÌÉù.
        
        Returns:
            Serving Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        config = {}
        
        config['enable_serving'] = Confirm.ask(
            "API ServingÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
            default=False
        )
        
        if config['enable_serving']:
            config['serving_workers'] = Prompt.ask(
                "  Worker ÌîÑÎ°úÏÑ∏Ïä§ Ïàò",
                default="1"
            )
            
            # Model stage ÏÑ†ÌÉù
            model_stages = [
                ("None (Î™®Îç∏ ÏóÜÏùå)", "None"),
                ("Staging (Ïä§ÌÖåÏù¥Ïßï Î™®Îç∏)", "Staging"),
                ("Production (ÌîÑÎ°úÎçïÏÖò Î™®Îç∏)", "Production"),
                ("Archived (ÏïÑÏπ¥Ïù¥Î∏åÎêú Î™®Îç∏)", "Archived"),
            ]
            config['model_stage'] = self.selector.select(
                "  Î™®Îç∏ Ïä§ÌÖåÏù¥ÏßÄÎ•º ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                model_stages
            )
            
            # Authentication ÏÑ§Ï†ï
            config['enable_auth'] = Confirm.ask(
                "  API Ïù∏Ï¶ùÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
                default=False
            )
        
        return config
    
    def _select_hyperparameter_tuning(self) -> Dict[str, Any]:
        """
        Hyperparameter Tuning ÏÑ§Ï†ï ÏÑ†ÌÉù.
        
        Returns:
            Hyperparameter tuning Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        config = {}
        
        config['enable_hyperparameter_tuning'] = Confirm.ask(
            "Hyperparameter TuningÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
            default=False
        )
        
        if config['enable_hyperparameter_tuning']:
            # Tuning engine ÏÑ†ÌÉù
            engines = [
                ("Optuna (Í∂åÏû•)", "optuna"),
                ("Hyperopt", "hyperopt"),
                ("Ray Tune", "ray"),
            ]
            config['tuning_engine'] = self.selector.select(
                "  Tuning ÏóîÏßÑÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                engines
            )
            
            config['tuning_timeout'] = Prompt.ask(
                "  ÏµúÎåÄ Ïã§Ìñâ ÏãúÍ∞Ñ (Ï¥à)",
                default="300"
            )
            
            config['tuning_jobs'] = Prompt.ask(
                "  Î≥ëÎ†¨ Ïã§Ìñâ ÏûëÏóÖ Ïàò",
                default="2"
            )
            
            if config['tuning_engine'] == 'optuna':
                directions = [
                    ("Maximize (ÏµúÎåÄÌôî)", "maximize"),
                    ("Minimize (ÏµúÏÜåÌôî)", "minimize"),
                ]
                config['tuning_direction'] = self.selector.select(
                    "  ÏµúÏ†ÅÌôî Î∞©Ìñ•ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
                    directions
                )
        
        return config
    
    def _select_monitoring(self) -> Dict[str, Any]:
        """
        Monitoring ÏÑ§Ï†ï ÏÑ†ÌÉù.
        
        Returns:
            Monitoring Í¥ÄÎ†® ÏÑ§Ï†ï
        """
        config = {}
        
        config['enable_monitoring'] = Confirm.ask(
            "MonitoringÏùÑ ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
            default=False
        )
        
        if config['enable_monitoring']:
            config['prometheus_port'] = Prompt.ask(
                "  Prometheus Ìè¨Ìä∏",
                default="9090"
            )
            
            config['enable_grafana'] = Confirm.ask(
                "  Grafana ÎåÄÏãúÎ≥¥ÎìúÎ•º ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?",
                default=False
            )
            
            if config['enable_grafana']:
                config['grafana_port'] = Prompt.ask(
                    "    Grafana Ìè¨Ìä∏",
                    default="3000"
                )
        
        return config
    
    def _advanced_settings(self) -> Dict[str, Any]:
        """
        Í≥†Í∏â ÏÑ§Ï†ï Íµ¨ÏÑ±.
        
        Returns:
            Í≥†Í∏â ÏÑ§Ï†ï ÏÇ¨Ìï≠
        """
        config = {}
        
        # Î°úÍπÖ Î†àÎ≤®
        log_level = self.selector.select(
            "Î°úÍπÖ Î†àÎ≤®ÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî",
            [
                ("DEBUG", "DEBUG"),
                ("INFO", "INFO"),
                ("WARNING", "WARNING"),
                ("ERROR", "ERROR"),
            ]
        )
        config['log_level'] = log_level
        
        # Î≥ëÎ†¨ Ï≤òÎ¶¨
        config['n_jobs'] = Prompt.ask("Î≥ëÎ†¨ Ï≤òÎ¶¨ ÏõåÏª§ Ïàò", default="4")
        
        # Ï∫êÏãú ÏÑ§Ï†ï
        config['enable_cache'] = Confirm.ask("Ï∫êÏãúÎ•º ÌôúÏÑ±ÌôîÌïòÏãúÍ≤†ÏäµÎãàÍπå?", default=True)
        
        return config
    
    def generate_config_file(self, env_name: str, selections: Dict[str, Any]) -> Path:
        """
        ÏÑ†ÌÉù ÏÇ¨Ìï≠ÏùÑ Í∏∞Î∞òÏúºÎ°ú config YAML ÌååÏùº ÏÉùÏÑ±.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÏÉùÏÑ±Îêú config ÌååÏùº Í≤ΩÎ°ú
        """
        # configs ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±
        config_dir = Path("configs")
        config_dir.mkdir(exist_ok=True)
        
        # Config Íµ¨Ï°∞ ÏÉùÏÑ±
        config = self._build_config_structure(selections)
        
        # YAML ÌååÏùº Ï†ÄÏû•
        config_path = config_dir / f"{env_name}.yaml"
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
        
        return config_path
    
    def generate_env_template(self, env_name: str, selections: Dict[str, Any]) -> Path:
        """
        ÏÑ†ÌÉù ÏÇ¨Ìï≠ÏùÑ Í∏∞Î∞òÏúºÎ°ú .env ÌÖúÌîåÎ¶ø ÌååÏùº ÏÉùÏÑ±.
        
        Args:
            env_name: ÌôòÍ≤Ω Ïù¥Î¶Ñ
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            ÏÉùÏÑ±Îêú .env ÌÖúÌîåÎ¶ø ÌååÏùº Í≤ΩÎ°ú
        """
        env_vars = []
        
        # Í∏∞Î≥∏ ÌôòÍ≤Ω Î≥ÄÏàò
        env_vars.append(f"# Environment: {env_name}")
        env_vars.append(f"ENV_NAME={env_name}")
        env_vars.append("")
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í¥ÄÎ†®
        if selections.get('data_source') in ['postgresql', 'mysql']:
            env_vars.append("# Database")
            env_vars.append(f"DB_HOST={selections.get('db_host', 'localhost')}")
            env_vars.append(f"DB_PORT={selections.get('db_port', '5432')}")
            env_vars.append(f"DB_NAME={selections.get('db_name', 'mmp_db')}")
            env_vars.append(f"DB_USER={selections.get('db_user', 'postgres')}")
            env_vars.append("DB_PASSWORD=your_password_here")
            env_vars.append("DB_TIMEOUT=30")
            env_vars.append("")
        
        # BigQuery Í¥ÄÎ†®
        if selections.get('data_source') == 'bigquery' or selections.get('use_gcp'):
            env_vars.append("# Google Cloud")
            env_vars.append(f"GCP_PROJECT_ID={selections.get('bq_project', 'your-project')}")
            if selections.get('data_source') == 'bigquery':
                env_vars.append(f"BQ_DATASET_ID={selections.get('bq_dataset', 'mmp_dataset')}")
                env_vars.append("BQ_LOCATION=US")
                env_vars.append("BQ_TIMEOUT=30")
            env_vars.append("GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json")
            env_vars.append("")
        
        # MLflow Í¥ÄÎ†®
        if selections.get('mlflow_enabled'):
            env_vars.append("# MLflow")
            env_vars.append(f"MLFLOW_TRACKING_URI={selections.get('mlflow_uri', './mlruns')}")
            env_vars.append(f"MLFLOW_EXPERIMENT_NAME={selections.get('mlflow_experiment', f'mmp-{env_name}')}")
            env_vars.append(f"MLFLOW_ARTIFACT_ROOT={selections.get('mlflow_artifact_root', './mlruns')}")
            env_vars.append("")
        
        # Feature Store (Redis) Í¥ÄÎ†®
        if selections.get('online_store_type') == 'redis':
            env_vars.append("# Redis (Feature Store)")
            env_vars.append(f"REDIS_HOST={selections.get('redis_host', 'localhost')}")
            env_vars.append(f"REDIS_PORT={selections.get('redis_port', '6379')}")
            env_vars.append("REDIS_PASSWORD=")  # Optional
            env_vars.append("")
        
        # Feast Registry
        if selections.get('feature_store_enabled'):
            env_vars.append("# Feast Feature Store")
            env_vars.append(f"FEAST_REGISTRY_PATH={selections.get('feast_registry', './feast_repo/registry.db')}")
            if selections.get('online_store_type') != 'redis':
                env_vars.append(f"FEAST_ONLINE_STORE_PATH={selections.get('feast_online_store', './feast_repo/online_store.db')}")
            env_vars.append("")
        
        # Cloud Storage Í¥ÄÎ†®
        if selections.get('storage_type') == 'gcs':
            env_vars.append("# Google Cloud Storage")
            env_vars.append(f"GCS_BUCKET={selections.get('gcs_bucket', 'your-bucket')}")
            env_vars.append(f"GCS_PREFIX={selections.get('gcs_prefix', env_name)}")
            env_vars.append("")
        elif selections.get('storage_type') == 's3':
            env_vars.append("# AWS S3")
            env_vars.append(f"S3_BUCKET={selections.get('s3_bucket', 'your-bucket')}")
            env_vars.append(f"S3_PREFIX={selections.get('s3_prefix', env_name)}")
            env_vars.append("AWS_ACCESS_KEY_ID=your_access_key")
            env_vars.append("AWS_SECRET_ACCESS_KEY=your_secret_key")
            env_vars.append("AWS_REGION=us-east-1")
            env_vars.append("S3_ENDPOINT_URL=")  # For MinIO compatibility
            env_vars.append("")
        elif selections.get('storage_type') == 'local':
            env_vars.append("# Local Storage")
            env_vars.append(f"LOCAL_ARTIFACT_PATH={selections.get('storage_path', './artifacts')}")
            env_vars.append("")
        
        # API Serving Í¥ÄÎ†®
        if selections.get('enable_serving'):
            env_vars.append("# API Serving")
            env_vars.append("API_HOST=0.0.0.0")
            env_vars.append("API_PORT=8000")
            env_vars.append(f"API_WORKERS={selections.get('serving_workers', '1')}")
            if selections.get('enable_auth'):
                env_vars.append("AUTH_TYPE=jwt")
                env_vars.append("AUTH_SECRET_KEY=your_secret_key_here")
            env_vars.append("")
        
        # Hyperparameter Tuning Í¥ÄÎ†®
        if selections.get('enable_hyperparameter_tuning'):
            env_vars.append("# Hyperparameter Tuning")
            env_vars.append(f"HYPERPARAM_TIMEOUT={selections.get('tuning_timeout', '300')}")
            env_vars.append(f"HYPERPARAM_JOBS={selections.get('tuning_jobs', '2')}")
            if selections.get('tuning_engine') == 'optuna':
                env_vars.append("OPTUNA_STUDY_NAME=mmp_study")
                env_vars.append("OPTUNA_STORAGE=sqlite:///optuna.db")
            env_vars.append("")
        
        # Monitoring Í¥ÄÎ†®
        if selections.get('enable_monitoring'):
            env_vars.append("# Monitoring")
            env_vars.append("ENABLE_METRICS=true")
            env_vars.append(f"METRICS_PORT={selections.get('prometheus_port', '9090')}")
            if selections.get('enable_grafana'):
                env_vars.append("GRAFANA_HOST=localhost")
                env_vars.append(f"GRAFANA_PORT={selections.get('grafana_port', '3000')}")
            env_vars.append("COLLECT_SYSTEM_METRICS=true")
            env_vars.append("COLLECT_MODEL_METRICS=true")
            env_vars.append("COLLECT_DATA_METRICS=true")
            env_vars.append("")
        
        # ÌååÏùº Ï†ÄÏû•
        env_template_path = Path(f".env.{env_name}.template")
        with open(env_template_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(env_vars))
        
        return env_template_path
    
    def _build_config_structure(self, selections: Dict[str, Any]) -> Dict[str, Any]:
        """
        ÏÑ†ÌÉù ÏÇ¨Ìï≠ÏùÑ Í∏∞Î∞òÏúºÎ°ú config Íµ¨Ï°∞ ÏÉùÏÑ±.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            Config ÎîïÏÖîÎÑàÎ¶¨ Íµ¨Ï°∞
        """
        # Prepare context for Jinja2 template
        context = self._prepare_template_context(selections)
        
        # Render template
        template = self.jinja_env.get_template('config.yaml.j2')
        rendered_yaml = template.render(**context)
        
        # Parse rendered YAML to dict
        config = yaml.safe_load(rendered_yaml)
        return config
    
    def _prepare_template_context(self, selections: Dict[str, Any]) -> Dict[str, Any]:
        """
        Prepare context for Jinja2 template rendering.
        
        Args:
            selections: User selections from interactive flow
            
        Returns:
            Context dictionary for template
        """
        context = {
            'env_name': selections['env_name'],
            'use_mlflow': 'mlflow_enabled' in selections and selections['mlflow_enabled'],
            'use_sql': selections.get('data_source') in ['postgresql', 'mysql', 'sqlite'],
            'use_bq': selections.get('data_source') == 'bigquery',
            'use_storage': selections.get('storage_type') in ['local', 's3', 'gcs'],
            'use_gcp': selections.get('data_source') == 'bigquery' or selections.get('storage_type') == 'gcs',
            'gcp_project': selections.get('bq_project', ''),
            'use_feast': selections.get('feature_store_enabled', False),
            'use_redis': selections.get('online_store_type') == 'redis',
            'use_local_storage': selections.get('storage_type') == 'local',
            'use_s3': selections.get('storage_type') == 's3',
            'use_gcs': selections.get('storage_type') == 'gcs',
            'enable_serving': False,  # Will be added in next task
            'enable_hyperparameter_tuning': False,  # Will be added in next task
            'enable_monitoring': False,  # Will be added in next task
        }
        
        # Add additional context from selections
        context.update(selections)
        return context
    
    def _build_config_structure_legacy(self, selections: Dict[str, Any]) -> Dict[str, Any]:
        """
        Legacy config builder - kept for fallback.
        
        Args:
            selections: ÏÇ¨Ïö©Ïûê ÏÑ†ÌÉù ÏÇ¨Ìï≠
            
        Returns:
            Config ÎîïÏÖîÎÑàÎ¶¨ Íµ¨Ï°∞
        """
        config = {
            'environment': {
                'env_name': selections['env_name'],
                'gcp_project_id': selections.get('bq_project', '${GCP_PROJECT:}')
            },
            'mlflow': {
                'tracking_uri': selections.get('mlflow_uri', './mlruns'),
                'experiment_name': selections.get('mlflow_experiment', f"{selections['env_name']}-experiment")
            },
            'data_adapters': {
                'default_loader': 'sql',
                'default_storage': 'storage',
                'adapters': {}
            },
            'serving': {
                'enabled': False,
                'model_stage': 'None'
            },
            'artifact_stores': {},
            'hyperparameter_tuning': {
                'enabled': False
            }
        }
        
        # SQL Adapter ÏÑ§Ï†ï
        if 'db_connection_uri' in selections:
            config['data_adapters']['adapters']['sql'] = {
                'class_name': 'SqlAdapter',
                'config': {
                    'connection_uri': selections['db_connection_uri'],
                    'query_timeout': 30
                }
            }
        
        # Storage Adapter ÏÑ§Ï†ï
        if selections.get('storage_type') == 'local':
            config['data_adapters']['adapters']['storage'] = {
                'class_name': 'StorageAdapter',
                'config': {
                    'storage_options': {}
                }
            }
            config['artifact_stores']['local'] = {
                'enabled': True,
                'base_uri': selections.get('storage_path', './data')
            }
        elif selections.get('storage_type') == 'gcs':
            config['data_adapters']['adapters']['storage'] = {
                'class_name': 'StorageAdapter',
                'config': {
                    'storage_options': {
                        'project': '${GCP_PROJECT}',
                        'token': '${GOOGLE_APPLICATION_CREDENTIALS:}'
                    }
                }
            }
            config['artifact_stores']['gcs'] = {
                'enabled': True,
                'bucket': selections.get('gcs_bucket', '${GCS_BUCKET}'),
                'prefix': selections.get('gcs_prefix', 'ml-artifacts')
            }
        
        # Feature Store ÏÑ§Ï†ï
        if selections.get('feature_store_enabled'):
            config['serving']['realtime_feature_store'] = {
                'store_type': selections.get('online_store_type', 'redis')
            }
            
            if selections.get('online_store_type') == 'redis':
                config['serving']['realtime_feature_store']['connection'] = {
                    'host': selections.get('redis_host', '${REDIS_HOST:localhost}'),
                    'port': int(selections.get('redis_port', 6379)),
                    'db': int(selections.get('redis_db', 0))
                }
        
        # Í≥†Í∏â ÏÑ§Ï†ï
        if 'log_level' in selections:
            config['environment']['log_level'] = selections['log_level']
        
        return config