import pandas as pd
from typing import Dict, Any, Optional, List
from urllib.parse import urlparse
from pathlib import Path

from src.interface.base_augmenter import BaseAugmenter
from src.utils.system.logger import logger
from src.settings.settings import Settings
from src.utils.system import sql_utils
# FactoryëŠ” dynamic importë¡œ ì‚¬ìš©í•˜ì—¬ ìˆœí™˜ ì°¸ì¡° ë°©ì§€

class LocalFileAugmenter(BaseAugmenter):
    """ë¡œì»¬ í”¼ì²˜ íŒŒì¼ê³¼ ì¡°ì¸í•˜ì—¬ ë°ì´í„°ë¥¼ ì¦ê°•í•˜ëŠ” í´ë˜ìŠ¤. (ê°œë°œìš©)"""
    def __init__(self, uri: str):
        parsed_uri = urlparse(uri)
        self.feature_path = Path(parsed_uri.path.lstrip('/'))
        if not self.feature_path.is_absolute():
            self.feature_path = Path(__file__).resolve().parent.parent.parent / self.feature_path

    def augment(self, data: pd.DataFrame, **kwargs) -> pd.DataFrame:
        logger.info(f"ë¡œì»¬ í”¼ì²˜ íŒŒì¼ë¡œ ì¦ê°•ì„ ì‹œì‘í•©ë‹ˆë‹¤: {self.feature_path}")
        if not self.feature_path.exists():
            raise FileNotFoundError(f"ë¡œì»¬ í”¼ì²˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.feature_path}")
        feature_df = pd.read_parquet(self.feature_path)
        return pd.merge(data, feature_df, on="member_id", how="left")

class Augmenter(BaseAugmenter):
    """
    ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸(run_mode)ì— ë”°ë¼ ë°°ì¹˜ ë˜ëŠ” ì‹¤ì‹œê°„ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ë‹¨ì¼ ì¦ê°•ê¸° í´ë˜ìŠ¤.
    ğŸ†• Blueprint v17.0: Feature Store ì„ ì–¸ì  ë°©ì‹ê³¼ ê¸°ì¡´ SQL ë°©ì‹ ëª¨ë‘ ì§€ì›
    """
    def __init__(self, source_uri: Optional[str] = None, settings: Optional[Settings] = None, augmenter_config: Optional[Dict[str, Any]] = None):
        self.settings = settings
        self.augmenter_config = augmenter_config or {}
        
        # ğŸ†• Blueprint v17.0: type ê¸°ë°˜ ë™ì‘ ë°©ì‹ ê²°ì •
        self.augmenter_type = self.augmenter_config.get('type', 'sql')  # ê¸°ë³¸ê°’: ê¸°ì¡´ SQL ë°©ì‹
        
        if self.augmenter_type == 'feature_store':
            # ğŸ†• ìƒˆë¡œìš´ Feature Store ë°©ì‹
            self._init_feature_store_mode()
        else:
            # ğŸ”„ ê¸°ì¡´ SQL ë°©ì‹ (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)
            self._init_sql_mode(source_uri)
    
    def _init_feature_store_mode(self):
        """ğŸ†• Feature Store ëª¨ë“œ ì´ˆê¸°í™”"""
        logger.info("ğŸ†• Feature Store ëª¨ë“œë¡œ Augmenter ì´ˆê¸°í™”")
        
        self.source_uri = None
        self.sql_template_str = None
        self.realtime_features_list = []
        
        # Feature Store ì„¤ì • íŒŒì‹±
        self.feature_config = self.augmenter_config.get('features', [])
        
        # ëª¨ë“  í”¼ì²˜ ëª©ë¡ ì¶”ì¶œ (ì‹¤ì‹œê°„ ì¡°íšŒìš©)
        for namespace_config in self.feature_config:
            features = namespace_config.get('features', [])
            namespace = namespace_config.get('feature_namespace', '')
            self.realtime_features_list.extend([f"{namespace}.{feature}" for feature in features])
        
        logger.info(f"Feature Store í”¼ì²˜ ì„¤ì •: {len(self.feature_config)}ê°œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤, {len(self.realtime_features_list)}ê°œ í”¼ì²˜")
        
        # Feature Store ì–´ëŒ‘í„° ì´ˆê¸°í™”
        self._init_feature_store_adapters()
    
    def _init_sql_mode(self, source_uri: str):
        """ğŸ”„ ê¸°ì¡´ SQL ëª¨ë“œ ì´ˆê¸°í™” (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)"""
        logger.info("ğŸ”„ ê¸°ì¡´ SQL ëª¨ë“œë¡œ Augmenter ì´ˆê¸°í™”")
        
        self.source_uri = source_uri
        self.sql_template_str = self._load_sql_template()
        self.realtime_features_list = sql_utils.get_selected_columns(self.sql_template_str)
        
        # ê¸°ì¡´ ì–´ëŒ‘í„° ì´ˆê¸°í™”
        self._init_sql_adapters()
    
    def _init_feature_store_adapters(self):
        """Feature Store ì–´ëŒ‘í„° ì´ˆê¸°í™”"""
        from src.core.factory import Factory
        factory = Factory(self.settings)
        
        try:
            self.feature_store_adapter = factory.create_feature_store_adapter()
            logger.info("Feature Store ì–´ëŒ‘í„° ì´ˆê¸°í™” ì„±ê³µ")
        except (ValueError, Exception) as e:
            logger.warning(f"Feature Store ì–´ëŒ‘í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.feature_store_adapter = None
        
        # Redis ì–´ëŒ‘í„° (ì‹¤ì‹œê°„ìš©) - ì—°ê²° ì‹¤íŒ¨ ì‹œì—ë„ ê³„ì† ì§„í–‰
        try:
            self.redis_adapter = factory.create_redis_adapter()
            logger.info("Redis ì–´ëŒ‘í„° ì´ˆê¸°í™” ì„±ê³µ")
        except (ImportError, Exception) as e:
            logger.warning(f"Redis ì–´ëŒ‘í„° ì´ˆê¸°í™” ì‹¤íŒ¨ (ì •ìƒì ì¸ ê°œë°œ í™˜ê²½ ìƒí™©): {e}")
            self.redis_adapter = None
    
    def _init_sql_adapters(self):
        """ê¸°ì¡´ SQL ì–´ëŒ‘í„° ì´ˆê¸°í™” (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)"""
        from src.core.factory import Factory
        factory = Factory(self.settings)
        self.batch_adapter = factory.create_data_adapter('bq')  # AugmenterëŠ” í•­ìƒ BigQueryë¥¼ ì‚¬ìš©
        
        # ì‹¤ì‹œê°„ ëª¨ë“œë¥¼ ìœ„í•œ Redis ì–´ëŒ‘í„° (ì„ íƒì )
        try:
            self.redis_adapter = factory.create_redis_adapter()
        except ImportError:
            logger.warning("Redisê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            self.redis_adapter = None

    def _load_sql_template(self) -> str:
        """ê¸°ì¡´ SQL í…œí”Œë¦¿ ë¡œë”© (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)"""
        parsed_uri = urlparse(self.source_uri)
        path = Path(parsed_uri.path.lstrip('/'))
        if not path.is_absolute():
            path = Path(__file__).resolve().parent.parent.parent / path
        if not path.exists():
            raise FileNotFoundError(f"Augmenter SQL í…œí”Œë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        return path.read_text(encoding="utf-8")

    def augment(
        self,
        data: pd.DataFrame,
        run_mode: str,
        context_params: Optional[Dict[str, Any]] = None,
        **kwargs,
    ) -> pd.DataFrame:
        """
        ğŸ”„ ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ 100% ìœ ì§€í•˜ë©´ì„œ Feature Store ë°©ì‹ ì§€ì› ì¶”ê°€
        """
        if self.augmenter_type == 'feature_store':
            # ğŸ†• Feature Store ë°©ì‹
            return self._augment_feature_store(data, run_mode, context_params, **kwargs)
        else:
            # ğŸ”„ ê¸°ì¡´ SQL ë°©ì‹ (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)
            if run_mode == "batch":
                return self._augment_batch(data, context_params)
            elif run_mode == "serving":
                return self._augment_realtime(data, kwargs.get("feature_store_config"))
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” Augmenter ì‹¤í–‰ ëª¨ë“œì…ë‹ˆë‹¤: {run_mode}")
    
    def _augment_feature_store(self, data: pd.DataFrame, run_mode: str, context_params: Optional[Dict[str, Any]], **kwargs):
        """ğŸ†• Feature Store ë°©ì‹ í”¼ì²˜ ì¦ê°•"""
        logger.info(f"ğŸ†• Feature Store ë°©ì‹ í”¼ì²˜ ì¦ê°• ì‹œì‘ (ëª¨ë“œ: {run_mode})")
        
        if not self.feature_store_adapter:
            logger.warning("Feature Store ì–´ëŒ‘í„°ê°€ ì—†ì–´ ì›ë³¸ ë°ì´í„° ë°˜í™˜")
            return data
        
        try:
            # FeatureStoreAdapterì˜ ìƒˆë¡œìš´ ë©”ì„œë“œ ì‚¬ìš©
            augmented_df = self.feature_store_adapter.get_features_from_config(
                entity_df=data,
                feature_config=self.feature_config,
                run_mode=run_mode
            )
            
            logger.info(f"Feature Store í”¼ì²˜ ì¦ê°• ì™„ë£Œ: {len(augmented_df.columns)}ê°œ ì»¬ëŸ¼")
            return augmented_df
            
        except Exception as e:
            logger.error(f"Feature Store í”¼ì²˜ ì¦ê°• ì‹¤íŒ¨: {e}")
            # ì•ˆì „í•œ fallback: ì›ë³¸ ë°ì´í„° ë°˜í™˜
            return data

    def _augment_batch(
        self, data: pd.DataFrame, context_params: Optional[Dict[str, Any]]
    ) -> pd.DataFrame:
        """ğŸ”„ ê¸°ì¡´ ë°°ì¹˜ ëª¨ë“œ í”¼ì²˜ ì¦ê°• (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)"""
        logger.info(f"ğŸ”„ ê¸°ì¡´ ë°°ì¹˜ ëª¨ë“œ í”¼ì²˜ ì¦ê°•ì„ ì‹œì‘í•©ë‹ˆë‹¤. (URI: {self.source_uri})")
        
        # ë¯¸ë¦¬ ìƒì„±ëœ ë°°ì¹˜ ì–´ëŒ‘í„° ì‚¬ìš© (Factory ìƒì„± ë¡œì§ ì œê±°)
        feature_df = self.batch_adapter.read(self.source_uri, params=context_params)
        return pd.merge(data, feature_df, on="member_id", how="left")

    def _augment_realtime(
        self, data: pd.DataFrame, feature_store_config: Optional[Dict[str, Any]]
    ) -> pd.DataFrame:
        """ğŸ”„ ê¸°ì¡´ ì‹¤ì‹œê°„ ëª¨ë“œ í”¼ì²˜ ì¦ê°• (ì™„ì „ í˜¸í™˜ì„± ìœ ì§€)"""
        if not feature_store_config:
            raise ValueError("ì‹¤ì‹œê°„ ì¦ê°•ì„ ìœ„í•´ì„œëŠ” feature_store_configê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        if "member_id" not in data.columns:
            raise ValueError("'member_id' ì»¬ëŸ¼ì´ ì—†ì–´ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        user_ids = data["member_id"].tolist()
        logger.info(f"ğŸ”„ ê¸°ì¡´ ë°©ì‹: {len(user_ids)}ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•œ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

        store_type = feature_store_config.get("store_type")
        
        if store_type == "redis":
            if self.redis_adapter is None:
                logger.warning("Redisê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                feature_map = {}
            else:
                # ë¯¸ë¦¬ ìƒì„±ëœ Redis ì–´ëŒ‘í„° ì‚¬ìš© (Factory ìƒì„± ë¡œì§ ì œê±°)
                feature_map = self.redis_adapter.get_features(user_ids, self.realtime_features_list)
        else:
            raise NotImplementedError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¤ì‹œê°„ ìŠ¤í† ì–´ íƒ€ì…ì…ë‹ˆë‹¤: {store_type}")

        if not feature_map:
            logger.warning("ì¡°íšŒëœ ì‹¤ì‹œê°„ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            feature_df = pd.DataFrame(columns=["member_id"] + self.realtime_features_list)
        else:
            feature_df = pd.DataFrame.from_records(list(feature_map.values()))
            feature_df["member_id"] = list(feature_map.keys())

        for col in self.realtime_features_list:
            if col not in feature_df.columns:
                feature_df[col] = None
        
        return pd.merge(data, feature_df, on="member_id", how="left")

    # ğŸ”„ ê¸°ì¡´ ë©”ì„œë“œë“¤ ì™„ì „ ìœ ì§€ (Blueprint v13.0 í˜¸í™˜ì„±)
    def augment_batch(
        self, data: pd.DataFrame, sql_snapshot: str, context_params: Optional[Dict[str, Any]] = None
    ) -> pd.DataFrame:
        """
        ğŸ”„ ë°°ì¹˜ ëª¨ë“œ í”¼ì²˜ ì¦ê°• (Blueprint v13.0 í˜¸í™˜ì„± ìœ ì§€)
        SQL ìŠ¤ëƒ…ìƒ·ì„ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ ì¶”ë¡  ì‹œ í”¼ì²˜ ì¦ê°•
        """
        logger.info(f"ğŸ”„ ê¸°ì¡´ ë°°ì¹˜ ëª¨ë“œ í”¼ì²˜ ì¦ê°•ì„ ì‹œì‘í•©ë‹ˆë‹¤. (SQL ìŠ¤ëƒ…ìƒ· ì‚¬ìš©)")
        
        # SQL ìŠ¤ëƒ…ìƒ·ì„ ì§ì ‘ ì‹¤í–‰
        if sql_snapshot and hasattr(self, 'batch_adapter') and self.batch_adapter:
            feature_df = self.batch_adapter.read(sql_snapshot, params=context_params)
            return pd.merge(data, feature_df, on="member_id", how="left")
        else:
            logger.warning("SQL ìŠ¤ëƒ…ìƒ·ì´ ì—†ê±°ë‚˜ ë°°ì¹˜ ì–´ëŒ‘í„°ê°€ ì—†ì–´ í”¼ì²˜ ì¦ê°•ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return data

    def augment_realtime(
        self, 
        data: pd.DataFrame, 
        sql_snapshot: str,
        feature_store_config: Optional[Dict[str, Any]] = None,
        feature_columns: Optional[List[str]] = None
    ) -> pd.DataFrame:
        """
        ğŸ”„ ì‹¤ì‹œê°„ ëª¨ë“œ í”¼ì²˜ ì¦ê°• (Blueprint v13.0 í˜¸í™˜ì„± ìœ ì§€)
        SQL ìŠ¤ëƒ…ìƒ·ì„ íŒŒì‹±í•˜ì—¬ Feature Store ì¡°íšŒë¡œ ë³€í™˜
        """
        if not feature_store_config:
            raise ValueError("ì‹¤ì‹œê°„ ì¦ê°•ì„ ìœ„í•´ì„œëŠ” feature_store_configê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        if "member_id" not in data.columns:
            raise ValueError("'member_id' ì»¬ëŸ¼ì´ ì—†ì–´ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒë¥¼ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        user_ids = data["member_id"].tolist()
        logger.info(f"ğŸ”„ ê¸°ì¡´ ì‹¤ì‹œê°„ ë°©ì‹: {len(user_ids)}ëª…ì˜ ì‚¬ìš©ìì— ëŒ€í•œ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

        # SQL ìŠ¤ëƒ…ìƒ·ì—ì„œ í”¼ì²˜ ì»¬ëŸ¼ ì¶”ì¶œ
        if not feature_columns:
            from src.utils.system.sql_utils import get_selected_columns
            feature_columns = get_selected_columns(sql_snapshot)
        
        store_type = feature_store_config.get("store_type")
        
        if store_type == "redis":
            if self.redis_adapter is None:
                logger.warning("Redisê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹¤ì‹œê°„ í”¼ì²˜ ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                feature_map = {}
            else:
                # SQL ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ Feature Store ì¡°íšŒ
                feature_map = self.redis_adapter.get_features(user_ids, feature_columns)
        else:
            raise NotImplementedError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‹¤ì‹œê°„ ìŠ¤í† ì–´ íƒ€ì…ì…ë‹ˆë‹¤: {store_type}")

        if not feature_map:
            logger.warning("ì¡°íšŒëœ ì‹¤ì‹œê°„ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
            feature_df = pd.DataFrame(columns=["member_id"] + feature_columns)
        else:
            feature_df = pd.DataFrame.from_records(list(feature_map.values()))
            feature_df["member_id"] = list(feature_map.keys())

        for col in feature_columns:
            if col not in feature_df.columns:
                feature_df[col] = None
        
        return pd.merge(data, feature_df, on="member_id", how="left")
