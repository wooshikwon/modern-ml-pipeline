import re
from typing import Any, Dict, List, Type

from pydantic import BaseModel, Field, create_model

# Jinja2 í…œí”Œë¦¿ì—ì„œ ë³€ìˆ˜ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì •ê·œì‹
# ì˜ˆ: {{ campaign_id }}, {{ member_id }}
JINJA_VAR_PATTERN = re.compile(r"{{\s*(\w+)\s*}}")


def get_pk_from_loader_sql(sql_template: str) -> List[str]:
    """
    Loaderì˜ SQL í…œí”Œë¦¿ ë¬¸ìì—´ì—ì„œ Jinja2 ë³€ìˆ˜ë¥¼ ì¶”ì¶œí•˜ì—¬ APIì˜ PK ëª©ë¡ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    í™˜ê²½ ë³€ìˆ˜ì¸ gcp_project_idëŠ” ì œì™¸í•©ë‹ˆë‹¤.
    """
    # ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  Jinja2 ë³€ìˆ˜ ì°¾ê¸°
    variables = JINJA_VAR_PATTERN.findall(sql_template)
    # ì¤‘ë³µ ì œê±° ë° í™˜ê²½ ë³€ìˆ˜ ì œì™¸
    pk_list = sorted(list(set(v for v in variables if v != "gcp_project_id")))
    return pk_list


def create_dynamic_prediction_request(model_name: str, pk_fields: List[str]) -> Type[BaseModel]:
    """
    ì¶”ì¶œëœ PK í•„ë“œ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ Pydantic ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # í•„ë“œ ë”•ì…”ë„ˆë¦¬ ìƒì„±
    field_annotations = {}
    field_defaults = {}

    for field in pk_fields:
        field_annotations[field] = Any
        field_defaults[field] = Field(..., description=f"Primary Key: {field}")

    # type()ì„ ì‚¬ìš©í•˜ì—¬ ë™ì  í´ë˜ìŠ¤ ìƒì„±
    class_name = f"{model_name}PredictionRequest"

    # í´ë˜ìŠ¤ ì†ì„± ë”•ì…”ë„ˆë¦¬
    class_dict = {"__annotations__": field_annotations, **field_defaults}

    # BaseModelì„ ìƒì†ë°›ëŠ” ë™ì  í´ë˜ìŠ¤ ìƒì„±
    DynamicModel = type(class_name, (BaseModel,), class_dict)

    return DynamicModel


# create_datainterface_based_prediction_request v1 ì‚­ì œë¨
# v2 ë²„ì „ ì‚¬ìš© (target_column ìë™ ì œì™¸ ê¸°ëŠ¥ í¬í•¨)


class MinimalPredictionResponse(BaseModel):
    """ì¼ë°˜ íƒœìŠ¤í¬ì— ê³µí†µì ì¸ ìµœì†Œ ì˜ˆì¸¡ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""

    model_config = {"protected_namespaces": ()}

    prediction: Any = Field(..., description="ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼")
    model_uri: str = Field(..., description="ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ëª¨ë¸ì˜ MLflow URI")


class PredictionResponse(BaseModel):
    """
    ë‹¨ì¼ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìœ„í•œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆì…ë‹ˆë‹¤.
    (ê¸°ì¡´ uplift ì¤‘ì‹¬ í•„ë“œ ìœ ì§€; ì¼ë°˜ íƒœìŠ¤í¬ëŠ” MinimalPredictionResponse ì‚¬ìš©ì„ ê¶Œì¥)
    """

    model_config = {"protected_namespaces": ()}

    uplift_score: float = Field(
        ..., json_schema_extra={"example": 0.0}, description="ê³„ì‚°ëœ ì˜ˆì¸¡ ì ìˆ˜"
    )
    model_uri: str = Field(
        ...,
        json_schema_extra={"example": "runs:/<run_id>/model"},
        description="ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ëª¨ë¸ì˜ MLflow URI",
    )
    # ìµœì í™” ì •ë³´ í¬í•¨ (Optionalë¡œ í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥)
    optimization_enabled: bool = Field(default=False, description="í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì—¬ë¶€")
    best_score: float = Field(default=0.0, description="ìµœì í™” ë‹¬ì„± ì ìˆ˜ (í™œì„±í™”ëœ ê²½ìš°)")


def create_batch_prediction_request(
    prediction_request_model: Type[BaseModel],
) -> Type[BaseModel]:
    """
    ë™ì ìœ¼ë¡œ ìƒì„±ëœ PredictionRequest ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ ìš”ì²­ ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    model_name = prediction_request_model.__name__
    return create_model(
        f"Batch{model_name}",
        samples=(
            List[prediction_request_model],
            Field(..., description="ì˜ˆì¸¡ì„ ìœ„í•œ ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸"),
        ),
    )


class BatchPredictionResponse(BaseModel):
    """
    ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ìœ„í•œ ì‘ë‹µ ìŠ¤í‚¤ë§ˆì…ë‹ˆë‹¤.
    """

    model_config = {"protected_namespaces": ()}

    predictions: List[Dict[str, Any]] = Field(..., description="ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (PK í¬í•¨)")
    model_uri: str = Field(
        ...,
        json_schema_extra={"example": "runs:/<run_id>/model"},
        description="ì˜ˆì¸¡ì— ì‚¬ìš©ëœ ëª¨ë¸ì˜ MLflow URI",
    )
    sample_count: int = Field(..., json_schema_extra={"example": 100}, description="ì²˜ë¦¬ëœ ìƒ˜í”Œ ìˆ˜")
    #  ìµœì í™” ì •ë³´ í¬í•¨ (Optionalë¡œ í•˜ìœ„ í˜¸í™˜ì„± ë³´ì¥)
    optimization_enabled: bool = Field(default=False, description="í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì—¬ë¶€")
    best_score: float = Field(default=0.0, description="ìµœì í™” ë‹¬ì„± ì ìˆ˜ (í™œì„±í™”ëœ ê²½ìš°)")


class HealthCheckResponse(BaseModel):
    """
    Liveness ì²´í¬ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ (K8s livenessProbeìš©).
    í”„ë¡œì„¸ìŠ¤ ìƒì¡´ ì—¬ë¶€ë§Œ í™•ì¸í•˜ëŠ” ê²½ëŸ‰ ì‘ë‹µ.
    """

    status: str = Field(
        default="ok", json_schema_extra={"example": "ok"}, description="í”„ë¡œì„¸ìŠ¤ ìƒíƒœ"
    )


class ReadyCheckResponse(BaseModel):
    """
    Readiness ì²´í¬ ì‘ë‹µ ìŠ¤í‚¤ë§ˆ (K8s readinessProbeìš©).
    ëª¨ë¸ ë¡œë“œ ìƒíƒœê¹Œì§€ í™•ì¸í•˜ì—¬ íŠ¸ë˜í”½ ìˆ˜ì‹  ì¤€ë¹„ ì—¬ë¶€ ë°˜í™˜.
    """

    model_config = {"protected_namespaces": ()}

    status: str = Field(..., json_schema_extra={"example": "ready"}, description="ì„œë¹„ìŠ¤ ìƒíƒœ")
    model_uri: str = Field(
        ...,
        json_schema_extra={"example": "runs:/<run_id>/model"},
        description="í˜„ì¬ ë¡œë“œëœ ëª¨ë¸ì˜ MLflow URI",
    )
    model_name: str = Field(
        ..., json_schema_extra={"example": "your_model_name"}, description="ë¡œë“œëœ ëª¨ë¸ ì´ë¦„"
    )


#  ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° ì‘ë‹µ ìŠ¤í‚¤ë§ˆë“¤


class HyperparameterOptimizationInfo(BaseModel):
    """
    í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê²°ê³¼ ì •ë³´
    """

    enabled: bool = Field(..., description="í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ìˆ˜í–‰ ì—¬ë¶€")
    engine: str = Field(default="", description="ì‚¬ìš©ëœ ìµœì í™” ì—”ì§„ (optuna ë“±)")
    best_params: Dict[str, Any] = Field(default={}, description="ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°í•©")
    best_score: float = Field(default=0.0, description="ë‹¬ì„±í•œ ìµœê³  ì ìˆ˜")
    total_trials: int = Field(default=0, description="ìˆ˜í–‰ëœ ì´ trial ìˆ˜")
    pruned_trials: int = Field(default=0, description="ì¡°ê¸° ì¤‘ë‹¨ëœ trial ìˆ˜")
    optimization_time: str = Field(default="", description="ì´ ìµœì í™” ì†Œìš” ì‹œê°„")


class TrainingMethodologyInfo(BaseModel):
    """
    í•™ìŠµ ë°©ë²•ë¡  ë° Data Leakage ë°©ì§€ ì •ë³´
    """

    train_test_split_method: str = Field(default="", description="ë°ì´í„° ë¶„í•  ë°©ë²•")
    train_ratio: float = Field(default=0.8, description="í•™ìŠµ ë°ì´í„° ë¹„ìœ¨")
    validation_strategy: str = Field(default="", description="ê²€ì¦ ì „ëµ")
    preprocessing_fit_scope: str = Field(
        default="", description="ì „ì²˜ë¦¬ fit ë²”ìœ„ (Data Leakage ë°©ì§€)"
    )
    random_state: int = Field(default=42, description="ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œê°’")


class ModelMetadataResponse(BaseModel):
    """
    ëª¨ë¸ì˜ ì™„ì „í•œ ë©”íƒ€ë°ì´í„° ì‘ë‹µ
    """

    model_config = {"protected_namespaces": ()}

    model_uri: str = Field(..., description="ëª¨ë¸ MLflow URI")
    model_class_path: str = Field(default="", description="ëª¨ë¸ í´ë˜ìŠ¤ ê²½ë¡œ")
    hyperparameter_optimization: HyperparameterOptimizationInfo = Field(
        ..., description="í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì •ë³´"
    )
    training_methodology: TrainingMethodologyInfo = Field(..., description="í•™ìŠµ ë°©ë²•ë¡  ì •ë³´")
    training_metadata: Dict[str, Any] = Field(default={}, description="ê¸°íƒ€ í•™ìŠµ ë©”íƒ€ë°ì´í„°")
    api_schema: Dict[str, Any] = Field(default={}, description="ë™ì  ìƒì„±ëœ API ìŠ¤í‚¤ë§ˆ ì •ë³´")


class OptimizationHistoryResponse(BaseModel):
    """
    í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ê³¼ì • ìƒì„¸ íˆìŠ¤í† ë¦¬
    """

    enabled: bool = Field(..., description="ìµœì í™” ìˆ˜í–‰ ì—¬ë¶€")
    optimization_history: List[Dict[str, Any]] = Field(
        default=[], description="ì „ì²´ ìµœì í™” ê³¼ì • ê¸°ë¡"
    )
    search_space: Dict[str, Any] = Field(default={}, description="íƒìƒ‰í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê³µê°„")
    convergence_info: Dict[str, Any] = Field(default={}, description="ìˆ˜ë ´ ì •ë³´")
    timeout_occurred: bool = Field(default=False, description="íƒ€ì„ì•„ì›ƒ ë°œìƒ ì—¬ë¶€")


def create_datainterface_based_prediction_request_v2(
    model_name: str, data_interface_schema: Dict[str, Any], exclude_target: bool = True
) -> Type[BaseModel]:
    """
    ğŸš€ Improved: DataInterface ìŠ¤í‚¤ë§ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ API ìš”ì²­ ëª¨ë¸ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
    Target ì»¬ëŸ¼ì€ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.

    Args:
        model_name: ìƒì„±í•  ëª¨ë¸ì˜ ì´ë¦„
        data_interface_schema: PyfuncWrapperì— ì €ì¥ëœ DataInterface ìŠ¤í‚¤ë§ˆ
        exclude_target: target_column ìë™ ì œì™¸ ì—¬ë¶€ (ê¸°ë³¸: True)

    Returns:
        ë™ì ìœ¼ë¡œ ìƒì„±ëœ Pydantic ëª¨ë¸ í´ë˜ìŠ¤
    """
    field_annotations = {}
    field_defaults = {}

    # Target column ì¶”ì¶œ (ì œì™¸ìš©)
    target_column = data_interface_schema.get("target_column")

    # 1. Entity columns (í•­ìƒ í•„ìš”, target ì œì™¸)
    entity_columns = data_interface_schema.get("entity_columns", []) or []
    for col in entity_columns:
        if exclude_target and col == target_column:
            continue  # target column ìë™ ì œì™¸
        field_annotations[col] = Any
        field_defaults[col] = Field(..., description=f"Entity column: {col}")

    # 2. Feature columns (ëª…ì‹œëœ ê²½ìš°)
    feature_columns = data_interface_schema.get("feature_columns", []) or []
    if feature_columns:
        for col in feature_columns:
            if exclude_target and col == target_column:
                continue  # target column ìë™ ì œì™¸
            if col not in field_annotations:  # ì¤‘ë³µ ë°©ì§€
                field_annotations[col] = Any
                field_defaults[col] = Field(..., description=f"Feature column: {col}")

    # 3. Task-specific columns
    task_type = data_interface_schema.get("task_type", "")

    # Timeseries: timestamp column
    if task_type == "timeseries":
        timestamp_col = data_interface_schema.get("timestamp_column")
        if timestamp_col and timestamp_col != target_column:
            field_annotations[timestamp_col] = Any
            field_defaults[timestamp_col] = Field(
                ..., description=f"Timestamp column: {timestamp_col}"
            )

    # Causal: treatment column
    elif task_type == "causal":
        treatment_col = data_interface_schema.get("treatment_column")
        if treatment_col and treatment_col != target_column:
            field_annotations[treatment_col] = Any
            field_defaults[treatment_col] = Field(
                ..., description=f"Treatment column: {treatment_col}"
            )

    # 4. Required columns from training (í•™ìŠµ ì‹œ ì‚¬ìš©ëœ ì»¬ëŸ¼ë“¤)
    required_columns = data_interface_schema.get("required_columns", []) or []
    for col in required_columns:
        if exclude_target and col == target_column:
            continue  # target column ìë™ ì œì™¸
        if col not in field_annotations:  # ì¤‘ë³µ ë°©ì§€
            field_annotations[col] = Any
            field_defaults[col] = Field(..., description=f"Required column: {col}")

    # 5. ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ (feature_columnsê°€ Noneì¸ ê²½ìš°)
    all_columns = data_interface_schema.get("all_columns", []) or []
    if not feature_columns and all_columns:  # feature_columnsê°€ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°
        exclude_cols = set([target_column] if exclude_target else [])
        exclude_cols.update(entity_columns)  # entityëŠ” ì´ë¯¸ ì¶”ê°€ë¨
        if task_type == "causal":
            exclude_cols.add(data_interface_schema.get("treatment_column"))

        for col in all_columns:
            if col not in exclude_cols and col not in field_annotations:
                field_annotations[col] = Any
                field_defaults[col] = Field(..., description=f"Feature: {col}")

    # í´ë˜ìŠ¤ ì´ë¦„ ìƒì„±
    class_name = f"{model_name}PredictionRequest"

    # í´ë˜ìŠ¤ ì†ì„± ë”•ì…”ë„ˆë¦¬
    class_dict = {
        "__annotations__": field_annotations,
        **field_defaults,
        "__doc__": f"Auto-generated prediction request schema for {model_name} (target_column '{target_column}' excluded)",
    }

    # BaseModelì„ ìƒì†ë°›ëŠ” ë™ì  í´ë˜ìŠ¤ ìƒì„±
    DynamicModel = type(class_name, (BaseModel,), class_dict)

    return DynamicModel
