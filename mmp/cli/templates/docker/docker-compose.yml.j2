# =============================================================================
# Docker Compose for {{ project_name }}
# Generated by Modern ML Pipeline
# =============================================================================
# 사용법:
#   docker-compose up api                           # API 서버 시작
#   docker-compose --profile training up training   # 학습 실행 (일회성)
#   docker-compose --profile inference up inference # 배치 추론 (일회성)
#   docker-compose --profile mlflow up mlflow       # MLflow UI (선택)
#
# 환경변수 (.env 파일 또는 export):
#   MODEL_RUN_ID=<mlflow_run_id>   # API/추론 시 필수
#   CONFIG_PATH=configs/prod.yaml  # 설정 파일 경로
#   RECIPE_PATH=recipes/model.yaml # 학습 시 레시피 경로
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # API 서버 (상시 실행)
  # ---------------------------------------------------------------------------
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: api
    image: {{ project_name }}:api
    container_name: {{ project_name }}_api
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./configs:/app/configs:ro      # 설정 파일 (읽기 전용)
      - ./mlruns:/app/mlruns:ro        # 모델 아티팩트 (읽기 전용)
      - ./logs:/app/logs               # 로그 출력
    environment:
      MODEL_RUN_ID: ${MODEL_RUN_ID}    # 필수: mmp train 완료 후 출력되는 run_id
      CONFIG_PATH: ${CONFIG_PATH:-configs/production.yaml}
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-./mlruns}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/ready"]
      interval: 30s
      timeout: 10s
      start_period: 60s
      retries: 3

  # ---------------------------------------------------------------------------
  # 학습 (on-demand: --profile training 필요)
  # ---------------------------------------------------------------------------
  training:
    build:
      context: .
      dockerfile: Dockerfile
      target: training
    image: {{ project_name }}:training
    container_name: {{ project_name }}_training
    volumes:
      - ./configs:/app/configs:ro
      - ./recipes:/app/recipes:ro
      - ./data:/app/data:ro
      - ./sql:/app/sql:ro
      - ./mlruns:/app/mlruns          # 모델 저장 (쓰기 필요)
      - ./logs:/app/logs
    environment:
      RECIPE_PATH: ${RECIPE_PATH:-recipes/model.yaml}
      CONFIG_PATH: ${CONFIG_PATH:-configs/production.yaml}
      TRAIN_DATA_PATH: ${TRAIN_DATA_PATH:-data/train.csv}
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-./mlruns}
    profiles:
      - training  # docker-compose --profile training up training

  # ---------------------------------------------------------------------------
  # 배치 추론 (on-demand: --profile inference 필요)
  # ---------------------------------------------------------------------------
  inference:
    build:
      context: .
      dockerfile: Dockerfile
      target: inference
    image: {{ project_name }}:inference
    container_name: {{ project_name }}_inference
    volumes:
      - ./configs:/app/configs:ro
      - ./data:/app/data:ro
      - ./mlruns:/app/mlruns:ro
      - ./artifacts:/app/artifacts     # 추론 결과 저장
      - ./logs:/app/logs
    environment:
      MODEL_RUN_ID: ${MODEL_RUN_ID}    # 필수
      CONFIG_PATH: ${CONFIG_PATH:-configs/production.yaml}
      INFERENCE_DATA_PATH: ${INFERENCE_DATA_PATH}  # 필수: 추론할 데이터 경로
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-./mlruns}
    profiles:
      - inference  # docker-compose --profile inference up inference

  # ---------------------------------------------------------------------------
  # MLflow UI (on-demand: --profile mlflow 필요)
  # ---------------------------------------------------------------------------
  mlflow:
    image: python:3.11-slim
    container_name: {{ project_name }}_mlflow
    command: >
      bash -c "pip install --no-cache-dir mlflow && mlflow ui --host 0.0.0.0 --port 5000 --backend-store-uri ./mlruns"
    ports:
      - "${MLFLOW_PORT:-5000}:5000"  # http://localhost:5000 에서 실험 결과 확인
    volumes:
      - ./mlruns:/app/mlruns
    working_dir: /app
    profiles:
      - mlflow  # docker-compose --profile mlflow up mlflow
