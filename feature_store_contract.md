# Feature Store & Infrastructure Contract

## π“‹ **λ¬Έμ„ λ©μ **

μ΄ λ¬Έμ„λ” **modern-ml-pipeline**κ³Ό **mmp-local-dev** ν”„λ΅μ νΈ κ°„μ μΈν”„λΌ μ±…μ„ λ¶„λ¦¬μ™€ μ—°λ™ λ°©μ‹μ„ μ •μν•©λ‹λ‹¤. Blueprint v17.0μ **"λ μ‹ν”Όλ” λ…Όλ¦¬, μ„¤μ •μ€ μΈν”„λΌ"** μ›μΉ™μ— λ”°λΌ **μ™„μ „ν• μ±…μ„ λ¶„λ¦¬**λ¥Ό κµ¬ν„ν•λ” κ³„μ•½μ„μ…λ‹λ‹¤.

---

## π—οΈ **μ•„ν‚¤ν…μ² μ±…μ„ λ¶„λ¦¬**

### **modern-ml-pipeline ν”„λ΅μ νΈ μ±…μ„**
```yaml
μ—­ν• : ML λ΅μ§ λ° μ–΄λ‘ν„° νƒ€μ… μ •μ
μ±…μ„:
  - Recipe νμΌ κ΄€λ¦¬ (λ¨λΈ λ…Όλ¦¬)
  - μ–΄λ‘ν„° νƒ€μ… μ„ νƒ (config/*.yaml)
  - ν™κ²½λ³€μ μ½κΈ° λ° μ—°κ²°
  - Factory Registry ν¨ν„΄ κµ¬ν„

κ΄€μ—¬ν•μ§€ μ•λ” μμ—­:
  - μ‹¤μ  μΈν”„λΌ κµ¬μ¶•
  - λ°μ΄ν„°λ² μ΄μ¤ μ„¤μ •
  - μ»¨ν…μ΄λ„ κ΄€λ¦¬
  - μ—°κ²° μ •λ³΄ κ΄€λ¦¬
```

### **mmp-local-dev ν”„λ΅μ νΈ μ±…μ„**
```yaml
μ—­ν• : μ™„μ „ν• μΈν”„λΌ κ΄€λ¦¬ λ° μ κ³µ
μ±…μ„:
  - Docker Compose μΈν”„λΌ κµ¬μ¶•
  - ν™κ²½λ³€μ ν…ν”λ¦Ώ μ κ³µ
  - μ‹¤μ  μ—°κ²° μ •λ³΄ κ΄€λ¦¬
  - Feature Store λ°μ΄ν„° κµ¬μ¶•
  - Health Check λ° λ¨λ‹ν„°λ§

μ κ³µν•μ§€ μ•λ” μμ—­:
  - ML λ¨λΈ λ…Όλ¦¬
  - Recipe νμΌ κ΄€λ¦¬
  - μ–΄λ‘ν„° κµ¬ν„
  - λΉ„μ¦λ‹μ¤ λ΅μ§
```

---

## π”§ **ν™κ²½λ³€μ κΈ°λ° μ—°κ²° μ²΄κ³„**

### **ν™κ²½λ³€μ κµ¬μ΅° μ„¤κ³„**
```bash
# mmp-local-dev/.env.example
# PostgreSQL (ν•„μ)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=mluser
POSTGRES_DB=mlpipeline
POSTGRES_PASSWORD=  # ν•„μ μ„¤μ •

# Redis (μ„ νƒμ )
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=  # μ„ νƒμ  μ„¤μ •

# MLflow (μ„ νƒμ )
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_ARTIFACT_ROOT=./mlruns

# Feature Store (μ„ νƒμ )
FEATURE_STORE_OFFLINE_URI=postgresql://mluser:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
FEATURE_STORE_ONLINE_URI=redis://${REDIS_HOST}:${REDIS_PORT}
```

### **ν™κ²½λ³€μ μ‚¬μ© μ›μΉ™**
```yaml
1. ν•„μ vs μ„ νƒμ  λ¶„λ¦¬:
   - ν•„μ: POSTGRES_PASSWORD (λ³΄μ•μƒ λ°λ“μ‹ μ‚¬μ©μ μ…λ ¥)
   - μ„ νƒμ : κΈ°λ³Έκ°’ μ κ³µ, ν•„μ”μ‹ μ¤λ²„λΌμ΄λ“

2. μ΅°ν•© κ°€λ¥ν• κµ¬μ΅°:
   - Base μ„¤μ • + ν™κ²½λ³„ μ¤λ²„λΌμ΄λ“
   - κ°λ°μλ³„ λ΅μ»¬ μ„¤μ • κ°€λ¥

3. λ³΄μ• κ³ λ ¤μ‚¬ν•­:
   - λ―Όκ°μ •λ³΄λ” .envμ—λ§ μ €μ¥
   - κΈ°λ³Έκ°’μ€ κ°λ°ν™κ²½μ— μ ν•©ν•κ² μ„¤μ •
```

---

## π­ **Factory Registry ν¨ν„΄**

### **ν™•μ¥μ  μ–΄λ‘ν„° μ‹μ¤ν…**
```python
# modern-ml-pipeline/src/core/registry.py
class AdapterRegistry:
    """μ™„μ „ν ν™•μ¥μ μΈ μ–΄λ‘ν„° λ“±λ΅ μ‹μ¤ν…"""
    
    _adapters = {}
    
    @classmethod
    def register(cls, adapter_type: str):
        """μ–΄λ‘ν„° λ“±λ΅ λ°μ½”λ μ΄ν„°"""
        def decorator(adapter_class):
            cls._adapters[adapter_type] = adapter_class
            return adapter_class
        return decorator
    
    @classmethod
    def create(cls, adapter_type: str, settings: Settings) -> BaseAdapter:
        """λ™μ  μ–΄λ‘ν„° μƒμ„±"""
        if adapter_type not in cls._adapters:
            raise ValueError(f"Unknown adapter type: {adapter_type}")
        return cls._adapters[adapter_type](settings)
```

### **μ–΄λ‘ν„° κµ¬ν„ μμ‹**
```python
# modern-ml-pipeline/src/utils/adapters/postgresql_adapter.py
from src.core.registry import AdapterRegistry
import os

@AdapterRegistry.register("postgresql")
class PostgreSQLAdapter(BaseAdapter):
    """ν™κ²½λ³€μ κΈ°λ° PostgreSQL μ–΄λ‘ν„°"""
    
    def __init__(self, settings: Settings):
        super().__init__(settings)
        self.host = os.getenv('POSTGRES_HOST', 'localhost')
        self.port = int(os.getenv('POSTGRES_PORT', '5432'))
        self.user = os.getenv('POSTGRES_USER', 'mluser')
        self.database = os.getenv('POSTGRES_DB', 'mlpipeline')
        self.password = os.getenv('POSTGRES_PASSWORD')  # ν•„μ
        
        if not self.password:
            raise ValueError("POSTGRES_PASSWORD ν™κ²½λ³€μκ°€ μ„¤μ •λμ§€ μ•μ•μµλ‹λ‹¤")
    
    def read(self, source_uri: str, **kwargs) -> pd.DataFrame:
        """SQL νμΌ μ‹¤ν–‰ λ° κ²°κ³Ό λ°ν™"""
        # ν™κ²½λ³€μ κΈ°λ° μ—°κ²° μ •λ³΄λ΅ PostgreSQL μ ‘μ†
        pass
```

### **Config κΈ°λ° λ™μ  κ²°μ •**
```yaml
# modern-ml-pipeline/config/dev.yaml
data_adapters:
  loader: "postgresql"        # Registryμ—μ„ PostgreSQLAdapter μ„ νƒ
  storage: "filesystem"       # Registryμ—μ„ FileSystemAdapter μ„ νƒ
  feature_store: "postgresql" # Registryμ—μ„ PostgreSQLAdapter μ„ νƒ

# μ‹¤μ  μ—°κ²° μ •λ³΄λ” ν™κ²½λ³€μμ—μ„ μ£Όμ…
# if-else λ¶„κΈ° μ—†μ΄ YAML μ„¤μ •μΌλ΅ μμ—°μ¤λ½κ² κ²°μ •
```

---

## π³ **mmp-local-dev ν”„λ΅μ νΈ κµ¬μ΅°**

### **λ””λ ‰ν† λ¦¬ κµ¬μ΅°**
```
mmp-local-dev/
β”β”€β”€ docker-compose.yml          # ν•µμ‹¬ μΈν”„λΌ μ •μ
β”β”€β”€ .env.example               # ν™κ²½λ³€μ ν…ν”λ¦Ώ
β”β”€β”€ setup.sh                   # μ›μ¤ν†± μ„¤μΉ μ¤ν¬λ¦½νΈ
β”β”€β”€ scripts/
β”‚   β”β”€β”€ init-database.sql      # PostgreSQL μ΄κΈ°ν™”
β”‚   β”β”€β”€ seed-features.sql      # μƒν” Feature λ°μ΄ν„°
β”‚   β””β”€β”€ health-check.sh        # μ„λΉ„μ¤ μƒνƒ ν™•μΈ
β”β”€β”€ config/
β”‚   β”β”€β”€ postgres.conf          # PostgreSQL μ„¤μ •
β”‚   β””β”€β”€ redis.conf             # Redis μ„¤μ •
β”β”€β”€ feast/
β”‚   β”β”€β”€ feature_store.yaml     # Feast μ„¤μ •
β”‚   β””β”€β”€ feature_definitions.py # ν”Όμ² μ •μ
β””β”€β”€ README.md                  # μ‚¬μ©λ²• κ°€μ΄λ“
```

### **ν•µμ‹¬ κµ¬μ„± μ”μ†**

#### **1. Docker Compose μΈν”„λΌ**
```yaml
# docker-compose.yml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - "${POSTGRES_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-database.sql:/docker-entrypoint-initdb.d/init.sql
      - ./scripts/seed-features.sql:/docker-entrypoint-initdb.d/seed.sql
  
  redis:
    image: redis:7-alpine
    ports:
      - "${REDIS_PORT}:6379"
    volumes:
      - redis_data:/data
  
  mlflow:
    image: python:3.11-slim
    command: >
      sh -c "pip install mlflow psycopg2-binary &&
             mlflow server --host 0.0.0.0 --port 5000"
    ports:
      - "5000:5000"
    depends_on:
      - postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}

volumes:
  postgres_data:
  redis_data:
```

#### **2. μ›μ¤ν†± μ„¤μΉ μ¤ν¬λ¦½νΈ**
```bash
# setup.sh
#!/bin/bash
set -e

echo "π€ MMP Local Dev Environment Setup"

# ν™κ²½λ³€μ νμΌ ν™•μΈ
if [ ! -f .env ]; then
    cp .env.example .env
    echo "β οΈ  .env νμΌμ—μ„ POSTGRES_PASSWORDλ¥Ό μ„¤μ •ν•΄μ£Όμ„Έμ”"
    exit 1
fi

# μΈν”„λΌ μ‹μ‘
echo "π³ Docker μΈν”„λΌ μ‹μ‘ μ¤‘..."
docker-compose up -d

# μ„λΉ„μ¤ λ€κΈ°
echo "β³ μ„λΉ„μ¤ μ¤€λΉ„ λ€κΈ° μ¤‘..."
./scripts/health-check.sh

echo "β… κ°λ° ν™κ²½ μ¤€λΉ„ μ™„λ£!"
echo "  PostgreSQL: localhost:${POSTGRES_PORT}"
echo "  Redis: localhost:${REDIS_PORT}"
echo "  MLflow: http://localhost:5000"
```

#### **3. Feature Store λ°μ΄ν„° κµ¬μ¶•**
```sql
-- scripts/seed-features.sql
-- μƒν” ν”Όμ² λ°μ΄ν„° μƒμ„±
CREATE SCHEMA IF NOT EXISTS features;

-- μ‚¬μ©μ κΈ°λ³Έ μ •λ³΄
CREATE TABLE features.user_demographics (
    user_id VARCHAR(50) PRIMARY KEY,
    age INTEGER,
    country_code VARCHAR(2),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- μ‚¬μ©μ κµ¬λ§¤ μ”μ•½
CREATE TABLE features.user_purchase_summary (
    user_id VARCHAR(50) PRIMARY KEY,
    ltv DECIMAL(10,2),
    total_purchase_count INTEGER,
    last_purchase_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- μ ν’ μƒμ„Έ μ •λ³΄
CREATE TABLE features.product_details (
    product_id VARCHAR(50) PRIMARY KEY,
    price DECIMAL(10,2),
    category VARCHAR(100),
    brand VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- μƒν” λ°μ΄ν„° μ‚½μ…
INSERT INTO features.user_demographics (user_id, age, country_code) VALUES
    ('user_001', 25, 'US'),
    ('user_002', 32, 'UK'),
    ('user_003', 28, 'CA');

INSERT INTO features.user_purchase_summary (user_id, ltv, total_purchase_count, last_purchase_date) VALUES
    ('user_001', 1250.50, 15, '2025-01-10'),
    ('user_002', 850.75, 8, '2025-01-08'),
    ('user_003', 2100.30, 25, '2025-01-12');

INSERT INTO features.product_details (product_id, price, category, brand) VALUES
    ('prod_001', 29.99, 'Electronics', 'TechBrand'),
    ('prod_002', 149.99, 'Fashion', 'StyleCorp'),
    ('prod_003', 79.99, 'Home', 'HomeInc');
```

---

## π”„ **μ—°λ™ μ›ν¬ν”λ΅μ°**

### **κ°λ° ν™κ²½ κµ¬μ„± ν”„λ΅μ„Έμ¤**
```bash
# 1. mmp-local-dev ν΄λ΅  λ° μ„¤μ •
git clone https://github.com/your-org/mmp-local-dev.git
cd mmp-local-dev
cp .env.example .env
# .env νμΌμ—μ„ POSTGRES_PASSWORD μ„¤μ •

# 2. μΈν”„λΌ μ‹μ‘
./setup.sh

# 3. modern-ml-pipeline ν”„λ΅μ νΈλ΅ μ΄λ™
cd ../modern-ml-pipeline

# 4. ν™κ²½λ³€μ λ΅λ“ λ° μ‹¤ν–‰
source ../mmp-local-dev/.env  # λλ” direnv μ‚¬μ©
APP_ENV=dev python main.py train --recipe-file dev_classification_test
```

### **μ–΄λ‘ν„° μ—°λ™ νλ¦„**
```mermaid
graph TD
    A[Recipe μ‹¤ν–‰] --> B[Config μ½κΈ°]
    B --> C[data_adapters.loader = 'postgresql']
    C --> D[Factory.create_data_adapter('loader')]
    D --> E[AdapterRegistry.create('postgresql')]
    E --> F[PostgreSQLAdapter.__init__]
    F --> G[ν™κ²½λ³€μ μ½κΈ°]
    G --> H[POSTGRES_HOST, POSTGRES_PORT, POSTGRES_PASSWORD]
    H --> I[μ‹¤μ  PostgreSQL μ—°κ²°]
```

---

## π€ **ν™•μ¥ λ°©μ‹**

### **μƒλ΅μ΄ μ–΄λ‘ν„° μ¶”κ°€**
```python
# 1. μƒ μ–΄λ‘ν„° κµ¬ν„
@AdapterRegistry.register("snowflake")
class SnowflakeAdapter(BaseAdapter):
    def __init__(self, settings: Settings):
        super().__init__(settings)
        self.account = os.getenv('SNOWFLAKE_ACCOUNT')
        self.user = os.getenv('SNOWFLAKE_USER')
        self.password = os.getenv('SNOWFLAKE_PASSWORD')
        # ... ν™κ²½λ³€μ κΈ°λ° μ„¤μ •

# 2. Configμ—μ„ μ„ νƒ
# config/prod.yaml
data_adapters:
  loader: "snowflake"  # Registryμ—μ„ SnowflakeAdapter μλ™ μ„ νƒ

# 3. ν™κ²½λ³€μ μ„¤μ •
# .env
SNOWFLAKE_ACCOUNT=your-account
SNOWFLAKE_USER=your-user
SNOWFLAKE_PASSWORD=your-password
```

### **μƒλ΅μ΄ ν™κ²½ μ¶”κ°€**
```yaml
# config/staging.yaml
data_adapters:
  loader: "bigquery"
  storage: "gcs"
  feature_store: "bigquery"

# ν™κ²½λ³€μλ§ μ„¤μ •ν•λ©΄ μλ™μΌλ΅ μ—°κ²°
# GCP_PROJECT_ID, GCP_CREDENTIALS_PATH λ“±
```

---

## π›΅οΈ **λ³΄μ• κ³ λ ¤μ‚¬ν•­**

### **ν™κ²½λ³€μ κ΄€λ¦¬**
```bash
# κ°λ°ν™κ²½
# mmp-local-dev/.env (git ignoreμ— ν¬ν•¨)
POSTGRES_PASSWORD=local_dev_password

# μ΄μν™κ²½
# μ‹μ¤ν… ν™κ²½λ³€μ λλ” μ‹ν¬λ¦Ώ κ΄€λ¦¬ λ„κµ¬ μ‚¬μ©
export POSTGRES_PASSWORD="$(kubectl get secret postgres-secret -o jsonpath='{.data.password}' | base64 -d)"
```

### **μ ‘κ·Ό μ μ–΄**
```yaml
λ³΄μ• μ›μΉ™:
  - λ―Όκ°μ •λ³΄λ” ν™κ²½λ³€μμ—λ§ μ €μ¥
  - .env νμΌμ€ λ°λ“μ‹ .gitignoreμ— ν¬ν•¨
  - μ΄μν™κ²½μ—μ„λ” μ‹ν¬λ¦Ώ κ΄€λ¦¬ λ„κµ¬ μ‚¬μ©
  - κ°λ°ν™κ²½κ³Ό μ΄μν™κ²½μ μ™„μ „ν• λ¶„λ¦¬
```

---

## π“ **μ„±λ¥ λ° λ¨λ‹ν„°λ§**

### **Health Check μ‹μ¤ν…**
```bash
# scripts/health-check.sh
#!/bin/bash

echo "π” μ„λΉ„μ¤ μƒνƒ ν™•μΈ μ¤‘..."

# PostgreSQL μ—°κ²° ν…μ¤νΈ
docker-compose exec postgres pg_isready -U $POSTGRES_USER -d $POSTGRES_DB
if [ $? -eq 0 ]; then
    echo "β… PostgreSQL μ •μƒ"
else
    echo "β PostgreSQL μ—°κ²° μ‹¤ν¨"
    exit 1
fi

# Redis μ—°κ²° ν…μ¤νΈ
docker-compose exec redis redis-cli ping
if [ $? -eq 0 ]; then
    echo "β… Redis μ •μƒ"
else
    echo "β Redis μ—°κ²° μ‹¤ν¨"
    exit 1
fi

echo "π‰ λ¨λ“  μ„λΉ„μ¤ μ •μƒ λ™μ‘ μ¤‘"
```

### **λ¨λ‹ν„°λ§ λ€μ‹λ³΄λ“**
```yaml
μ κ³µ μ„λΉ„μ¤:
  - MLflow UI: http://localhost:5000 (μ‹¤ν— μ¶”μ )
  - pgAdmin: http://localhost:8082 (PostgreSQL κ΄€λ¦¬)
  - Redis Commander: http://localhost:8081 (Redis λ¨λ‹ν„°λ§)
```

---

## π― **μ‚¬μ© μ‹λ‚λ¦¬μ¤**

### **μ‹λ‚λ¦¬μ¤ 1: μƒλ΅μ΄ κ°λ°μ μ¨λ³΄λ”©**
```bash
# 1. μ €μ¥μ† ν΄λ΅ 
git clone https://github.com/your-org/mmp-local-dev.git
git clone https://github.com/your-org/modern-ml-pipeline.git

# 2. κ°λ°ν™κ²½ κµ¬μ„± (5λ¶„)
cd mmp-local-dev
cp .env.example .env
# .envμ—μ„ POSTGRES_PASSWORD μ„¤μ •
./setup.sh

# 3. μ²« λ²μ§Έ μ‹¤ν— μ‹¤ν–‰ (2λ¶„)
cd ../modern-ml-pipeline
APP_ENV=dev python main.py train --recipe-file dev_classification_test

# μ΄ 7λ¶„ μ΄λ‚΄ μ™„μ „ν• κ°λ°ν™κ²½ κµ¬μ¶• μ™„λ£
```

### **μ‹λ‚λ¦¬μ¤ 2: μƒλ΅μ΄ λ°μ΄ν„° μ†μ¤ μ¶”κ°€**
```python
# 1. μ–΄λ‘ν„° κµ¬ν„
@AdapterRegistry.register("mongodb")
class MongoDBAdapter(BaseAdapter):
    def __init__(self, settings: Settings):
        self.connection_string = os.getenv('MONGODB_CONNECTION_STRING')
        # ... κµ¬ν„

# 2. Config μμ •
# config/dev.yaml
data_adapters:
  loader: "mongodb"  # Factoryκ°€ μλ™μΌλ΅ MongoDBAdapter μ„ νƒ

# 3. ν™κ²½λ³€μ μ„¤μ •
# .env
MONGODB_CONNECTION_STRING=mongodb://localhost:27017/mlpipeline
```

### **μ‹λ‚λ¦¬μ¤ 3: μ΄μν™κ²½ λ°°ν¬**
```yaml
# 1. μ΄μν™κ²½ Config μƒμ„±
# config/prod.yaml
data_adapters:
  loader: "bigquery"
  storage: "gcs"
  feature_store: "bigquery"

# 2. μ΄μν™κ²½ ν™κ²½λ³€μ μ„¤μ •
# μ‹ν¬λ¦Ώ κ΄€λ¦¬ λ„κµ¬ λλ” μ‹μ¤ν… ν™κ²½λ³€μ
export GCP_PROJECT_ID="your-prod-project"
export GCP_CREDENTIALS_PATH="/path/to/credentials.json"

# 3. λ™μΌν• μ½”λ“λ΅ μ΄μν™κ²½ μ‹¤ν–‰
APP_ENV=prod python main.py train --recipe-file prod_model_recipe
```

---

## π† **ν•µμ‹¬ μ¥μ **

### **Blueprint μ² ν•™ μ™„μ „ κµ¬ν„**
```yaml
1. μ™„μ „ν• μ±…μ„ λ¶„λ¦¬:
   - ML μ½”λ“λ” μ–΄λ‘ν„° νƒ€μ…λ§ μ„ νƒ
   - μΈν”„λΌλ” mmp-local-devκ°€ μ™„μ „ κ΄€λ¦¬
   - ν™κ²½λ³€μλ¥Ό ν†µν• λμ¨ν• κ²°ν•©

2. ν™•μ¥μ„± λ³΄μ¥:
   - μƒ μ–΄λ‘ν„° μ¶”κ°€ μ‹ Factory μ½”λ“ λ³€κ²½ λ¶ν•„μ”
   - Registry ν¨ν„΄μΌλ΅ μ™„μ „ λ™μ  μƒμ„±
   - YAML μ„¤μ •μΌλ΅ μμ—°μ¤λ¬μ΄ μ„ νƒ

3. κ°λ°μ κ²½ν—:
   - 5λ¶„ μ΄λ‚΄ μ™„μ „ν• κ°λ°ν™κ²½ κµ¬μ¶•
   - μ½”λ“ λ³€κ²½ μ—†μ΄ ν™κ²½λ³„ μ „ν™
   - λ…ν™•ν• μ—λ¬ λ©”μ‹μ§€μ™€ λ””λ²„κΉ… μ§€μ›
```

---

μ΄ κ³„μ•½μ— λ”°λΌ **modern-ml-pipeline**μ€ ML λ΅μ§μ—λ§ μ§‘μ¤‘ν•κ³ , **mmp-local-dev**λ” μΈν”„λΌ κ΄€λ¦¬μ—λ§ μ§‘μ¤‘ν•μ—¬ **Blueprint v17.0μ μ™„μ „ν• μ‹¤ν„**μ„ λ‹¬μ„±ν•  μ μμµλ‹λ‹¤. π€