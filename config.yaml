# 1. 실행 환경 설정
environment:
  run_mode: ${RUN_MODE:local}
  gcp_credential_path: ${GCP_CREDENTIAL_PATH}
  gcp_project_id: ${GCP_PROJECT_ID}

# 2-1. loader.py 관련 설정
loader:
  abt_logs: # 데이터셋 이름 (여러개가 될 수 있음)
    sql_file_path: "src/sql/abt_logs.sql"
    output: # output 저장 경로
      type: "bigquery"
      project_id: ${GCP_PROJECT_ID}
      dataset_id: "uplift_virtual_coupon"
      table_id: "abt_logs"
      unique_column: "member_id"

# 2-2. augmenter.py 관련 설정
augmenter:
  batch:
    feature_store_sql_path: "src/sql/user_features.sql"
  realtime:
    type: "redis"
    host: ${REDIS_HOST:localhost}
    port: ${REDIS_PORT:6379}

# 2-3. preprocessor.py 관련 설정
preprocessor:
  params:
    criterion_col: 'rsvn_30_count' # categorical 컬럼별로 grouping하여 기준 컬럼의 중앙값이 큰 순서대로 0 ~ 정수형 순서가 부여됨, 공란인 경우 빈도 기반으로 순서가 부여됨
    exclude_cols: ['member_id', 'grp', 'outcome'] # PK나 y값, treatment 컬럼 등 학습 컬럼이 아닌 컬럼들은 변환에서 제외
  output:
    type: "gcs"
    bucket_name: ${GCS_BUCKET_NAME}

# 3. 실험 관리 도구 설정 (mlflow)
mlflow:
  tracking_uri: ${MLFLOW_TRACKING_URI:"./local/artifacts"}
  experiment_name: "uplift-virtual-coupon"