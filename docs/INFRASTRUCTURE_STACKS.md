# ğŸ—ï¸ Infrastructure Stacks Guide

**Modern ML Pipeline ì¸í”„ë¼ êµ¬ì„± ê°€ì´ë“œ - ë‹¹ì‹ ì˜ í™˜ê²½ì— ë§ëŠ” ìµœì  ì¡°í•© ì°¾ê¸°**

ì´ ë¬¸ì„œëŠ” Modern ML Pipelineì„ ë‹¤ì–‘í•œ ì¸í”„ë¼ í™˜ê²½ì—ì„œ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ë¡œì»¬ ê°œë°œë¶€í„° ì—”í„°í”„ë¼ì´ì¦ˆ í´ë¼ìš°ë“œê¹Œì§€, ë‹¹ì‹ ì´ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ê¸°ìˆ  ìŠ¤íƒì— ë§ì¶° íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ¯ **ì§€ì›í•˜ëŠ” ì¸í”„ë¼ êµ¬ì„±ìš”ì†Œ**

Modern ML Pipelineì€ 3ê°€ì§€ í•µì‹¬ êµ¬ì„±ìš”ì†Œë¡œ ë‚˜ë‰©ë‹ˆë‹¤:

### **1. ë°ì´í„° ë ˆì´ì–´**
- **SQL ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL, BigQuery, Snowflake, MySQL, SQLite
- **íŒŒì¼ ìŠ¤í† ë¦¬ì§€**: ë¡œì»¬ íŒŒì¼, Google Cloud Storage, Amazon S3, Azure Blob Storage
- **Feature Store**: Feast ê¸°ë°˜ (Redis, DynamoDB, PostgreSQL, Bigtable ë“±)

### **2. ML í”Œë«í¼**
- **ì‹¤í—˜ ì¶”ì **: MLflow (ë¡œì»¬/ì„œë²„/í´ë¼ìš°ë“œ)
- **ëª¨ë¸ ì €ì¥ì†Œ**: íŒŒì¼ ì‹œìŠ¤í…œ, GCS, S3, Azure Blob

### **3. ì„œë¹™ í”Œë«í¼**
- **API ì„œë²„**: FastAPI (ë¡œì»¬/Docker/Kubernetes/ì„œë²„ë¦¬ìŠ¤)
- **ë°°ì¹˜ ì²˜ë¦¬**: ë¡œì»¬ Python, í´ë¼ìš°ë“œ ì‘ì—…, ì»¨í…Œì´ë„ˆ

---

## ğŸ  **í™˜ê²½ë³„ êµ¬ì„± ê°€ì´ë“œ**

### **LOCAL í™˜ê²½: ì¦‰ì‹œ ì‹œì‘**

**ì¶”ì²œ ëŒ€ìƒ**: ê°œì¸ ê°œë°œì, í”„ë¡œí† íƒ€ì´í•‘, í•™ìŠµ ëª©ì 

```yaml
# í•„ìš”í•œ ê²ƒ: ì•„ë¬´ê²ƒë„ ì—†ìŒ (git cloneë§Œ)

ë°ì´í„° ë ˆì´ì–´:
  ë°ì´í„° ì†ŒìŠ¤: ë¡œì»¬ íŒŒì¼ (Parquet, CSV)
  Feature Store: ë¹„í™œì„±í™” (ìë™)
  
ML í”Œë«í¼:
  MLflow: ë¡œì»¬ ë””ë ‰í† ë¦¬ (./mlruns)
  ëª¨ë¸ ì €ì¥: ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ
  
ì„œë¹™:
  ë°°ì¹˜ ì¶”ë¡ : âœ… ì§€ì›
  API ì„œë¹™: âŒ ì˜ë„ì  ë¹„í™œì„±í™” (ë‹¨ìˆœì„± ìœ ì§€)
```

**ì„¤ì • ë°©ë²•:**
```bash
# 1. í´ë¡  í›„ ì¦‰ì‹œ ì‹¤í–‰
git clone https://github.com/wooshikwon/modern-ml-pipeline.git
cd modern-ml-pipeline
uv venv && uv sync

# 2. ë°ì´í„° íŒŒì¼ ì¤€ë¹„
# data/ ë””ë ‰í† ë¦¬ì— .parquet ë˜ëŠ” .csv íŒŒì¼ ë°°ì¹˜

# 3. ë°”ë¡œ í•™ìŠµ ì‹œì‘
uv run python main.py train --recipe-file recipes/local_classification_test.yaml
```

### **DEV í™˜ê²½: ì™„ì „í•œ ê¸°ëŠ¥**

**ì¶”ì²œ ëŒ€ìƒ**: íŒ€ ê°œë°œ, ëª¨ë“  ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸, Feature Store í™œìš©

```yaml
# í•„ìš”í•œ ê²ƒ: Docker, Docker Compose

ë°ì´í„° ë ˆì´ì–´:
  SQL DB: PostgreSQL (Docker)
  Feature Store: PostgreSQL + Redis (Docker)
  
ML í”Œë«í¼:
  MLflow: HTTP ì„œë²„ (Docker)
  ëª¨ë¸ ì €ì¥: PostgreSQL ë°±ì—”ë“œ
  
ì„œë¹™:
  ë°°ì¹˜ ì¶”ë¡ : âœ… ì™„ì „ ì§€ì›
  API ì„œë¹™: âœ… ì™„ì „ ì§€ì›
```

**ì„¤ì • ë°©ë²•:**
```bash
# 1. mmp-local-dev ì¸í”„ë¼ ì„¤ì •
git clone https://github.com/wooshikwon/mmp-local-dev.git ../mmp-local-dev
cd ../mmp-local-dev
docker-compose up -d

# 2. ì—°ê²° í™•ì¸
curl http://localhost:5002/health  # MLflow
redis-cli ping                     # Redis
psql -h localhost -p 5432 -U mlpipeline_user -d mlpipeline_db -c "SELECT 1;"

# 3. DEV í™˜ê²½ì—ì„œ ì‹¤í–‰
cd modern-ml-pipeline
APP_ENV=dev uv run python main.py train --recipe-file recipes/dev_classification_test.yaml
```

### **PROD í™˜ê²½: í´ë¼ìš°ë“œ í™•ì¥**

**ì¶”ì²œ ëŒ€ìƒ**: ìš´ì˜ ì„œë¹„ìŠ¤, ëŒ€ìš©ëŸ‰ ë°ì´í„°, ê³ ê°€ìš©ì„± í•„ìš”

#### **Google Cloud Platform êµ¬ì„±**

```yaml
ë°ì´í„° ë ˆì´ì–´:
  SQL DB: BigQuery
  Feature Store: BigQuery + Redis Labs
  íŒŒì¼ ì €ì¥: Google Cloud Storage
  
ML í”Œë«í¼:
  MLflow: Cloud Run + GCS
  ëª¨ë¸ ì €ì¥: GCS
  
ì„œë¹™:
  API ì„œë²„: Cloud Run
  ë°°ì¹˜ ì²˜ë¦¬: Cloud Run Jobs
```

**ì„¤ì • íŒŒì¼ ì˜ˆì‹œ:**
```yaml
# config/prod.yaml
data_adapters:
  adapters:
    sql:
      class_name: SqlAdapter
      config:
        connection_uri: "bigquery://your-project-id/your-dataset"
    storage:
      class_name: StorageAdapter
      config: {}

mlflow:
  tracking_uri: "https://your-mlflow-server.run.app"

feature_store:
  feast_config:
    offline_store:
      type: "bigquery"
      project_id: "your-project-id"
      dataset: "feast_offline"
    online_store:
      type: "redis"
      connection_string: "redis://your-redis-endpoint:6379"
```

#### **Amazon Web Services êµ¬ì„±**

```yaml
ë°ì´í„° ë ˆì´ì–´:
  SQL DB: Snowflake ë˜ëŠ” Redshift
  Feature Store: Snowflake + DynamoDB
  íŒŒì¼ ì €ì¥: Amazon S3
  
ML í”Œë«í¼:
  MLflow: ECS + S3
  ëª¨ë¸ ì €ì¥: S3
  
ì„œë¹™:
  API ì„œë²„: Lambda ë˜ëŠ” ECS
  ë°°ì¹˜ ì²˜ë¦¬: ECS Tasks
```

**ì„¤ì • íŒŒì¼ ì˜ˆì‹œ:**
```yaml
# config/prod_aws.yaml
data_adapters:
  adapters:
    sql:
      class_name: SqlAdapter
      config:
        connection_uri: "snowflake://user:pass@account/database/schema"
    storage:
      class_name: StorageAdapter
      config: {}

feature_store:
  feast_config:
    offline_store:
      type: "snowflake"
      account: "your-account"
      database: "feast_db"
    online_store:
      type: "dynamodb"
      region: "us-east-1"
```

#### **Microsoft Azure êµ¬ì„±**

```yaml
ë°ì´í„° ë ˆì´ì–´:
  SQL DB: Synapse Analytics
  Feature Store: Synapse + Cosmos DB
  íŒŒì¼ ì €ì¥: Azure Blob Storage
  
ML í”Œë«í¼:
  MLflow: Container Instances + Blob
  ëª¨ë¸ ì €ì¥: Blob Storage
  
ì„œë¹™:
  API ì„œë²„: Container Instances
  ë°°ì¹˜ ì²˜ë¦¬: Container Instances
```

---

## ğŸ”§ **ì¸í”„ë¼ë³„ ì„¤ì • ê°€ì´ë“œ**

### **ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •**

#### **PostgreSQL**
```yaml
# config/your_env.yaml
data_adapters:
  adapters:
    sql:
      class_name: SqlAdapter
      config:
        connection_uri: "postgresql://user:password@host:5432/database"
```

#### **BigQuery**
```yaml
data_adapters:
  adapters:
    sql:
      class_name: SqlAdapter
      config:
        connection_uri: "bigquery://project-id/dataset-id"
```

#### **Snowflake**
```yaml
data_adapters:
  adapters:
    sql:
      class_name: SqlAdapter
      config:
        connection_uri: "snowflake://user:password@account/database/schema"
```

### **íŒŒì¼ ìŠ¤í† ë¦¬ì§€ ì„¤ì •**

#### **ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ**
```yaml
# Recipeì—ì„œ ì§ì ‘ ê²½ë¡œ ì§€ì •
model:
  loader:
    source_uri: "data/my_dataset.parquet"
```

#### **Google Cloud Storage**
```yaml
model:
  loader:
    source_uri: "gs://your-bucket/path/to/data.parquet"
```

#### **Amazon S3**
```yaml
model:
  loader:
    source_uri: "s3://your-bucket/path/to/data.parquet"
```

#### **Azure Blob Storage**
```yaml
model:
  loader:
    source_uri: "abfs://container@account.dfs.core.windows.net/path/to/data.parquet"
```

### **Feature Store ì„¤ì •**

#### **Redis (ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤)**
```yaml
feature_store:
  feast_config:
    online_store:
      type: "redis"
      connection_string: "redis://localhost:6379"
```

#### **Redis (í´ëŸ¬ìŠ¤í„°)**
```yaml
feature_store:
  feast_config:
    online_store:
      type: "redis"
      redis_type: "redis_cluster"
      connection_string: "redis://redis-cluster-endpoint:6379"
```

#### **DynamoDB**
```yaml
feature_store:
  feast_config:
    online_store:
      type: "dynamodb"
      region: "us-west-2"
      table_name: "feast_online_store"
```

#### **Bigtable**
```yaml
feature_store:
  feast_config:
    online_store:
      type: "bigtable"
      project_id: "your-gcp-project"
      instance_id: "feast-instance"
```

---

## ğŸ¯ **ìƒí™©ë³„ ì¶”ì²œ êµ¬ì„±**

### **ìŠ¤íƒ€íŠ¸ì—… / ê°œì¸ í”„ë¡œì íŠ¸**

**ì‹œë‚˜ë¦¬ì˜¤**: ë¹„ìš© ìµœì†Œí™”, ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘

```yaml
ì¶”ì²œ ìŠ¤íƒ:
  ê°œë°œ: LOCAL í™˜ê²½
  í…ŒìŠ¤íŠ¸: DEV í™˜ê²½ (mmp-local-dev)
  ìš´ì˜: GCP Cloud Run + PostgreSQL

ì›” ì˜ˆìƒ ë¹„ìš©: $0 (ê°œë°œ) + $50-100 (ìš´ì˜)
```

### **ì¤‘ì†Œê¸°ì—…**

**ì‹œë‚˜ë¦¬ì˜¤**: ì•ˆì •ì„±ê³¼ ë¹„ìš© ê· í˜•, íŒ€ í˜‘ì—…

```yaml
ì¶”ì²œ ìŠ¤íƒ:
  ê°œë°œ: DEV í™˜ê²½ (ê³µìœ )
  ìŠ¤í…Œì´ì§•: DEV í™˜ê²½ (ë³„ë„ ì¸ìŠ¤í„´ìŠ¤)
  ìš´ì˜: GCP ê´€ë¦¬í˜• ì„œë¹„ìŠ¤

ì›” ì˜ˆìƒ ë¹„ìš©: $100-500
```

### **ëŒ€ê¸°ì—… / ì—”í„°í”„ë¼ì´ì¦ˆ**

**ì‹œë‚˜ë¦¬ì˜¤**: ê±°ë²„ë„ŒìŠ¤, ë³´ì•ˆ, í™•ì¥ì„±

```yaml
ì¶”ì²œ ìŠ¤íƒ:
  ê°œë°œ: DEV í™˜ê²½ (ê°œì¸ë³„)
  ìŠ¤í…Œì´ì§•: í´ë¼ìš°ë“œ (ìš´ì˜ê³¼ ë™ì¼)
  ìš´ì˜: ë©€í‹°í´ë¼ìš°ë“œ ë˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ

ì›” ì˜ˆìƒ ë¹„ìš©: $1,000+
```

### **ë°ì´í„° ì§‘ì•½ì  ì„œë¹„ìŠ¤**

**ì‹œë‚˜ë¦¬ì˜¤**: í˜íƒ€ë°”ì´íŠ¸ê¸‰ ë°ì´í„°, ì‹¤ì‹œê°„ ì²˜ë¦¬

```yaml
ì¶”ì²œ ìŠ¤íƒ:
  SQL: BigQuery ë˜ëŠ” Snowflake
  Feature Store: Redis Labs (í´ëŸ¬ìŠ¤í„°)
  API: ê¸€ë¡œë²Œ ì—£ì§€ ë°°í¬

ì›” ì˜ˆìƒ ë¹„ìš©: ì‚¬ìš©ëŸ‰ ê¸°ë°˜
```

---

## ğŸ”„ **í™˜ê²½ ì „í™˜ ê°€ì´ë“œ**

### **ë¡œì»¬ â†’ í´ë¼ìš°ë“œ ì „í™˜**

```bash
# 1. í´ë¼ìš°ë“œ ì¸ì¦ ì„¤ì •
gcloud auth application-default login  # GCP
aws configure                          # AWS
az login                              # Azure

# 2. ì„¤ì • íŒŒì¼ ë³€ê²½
# config/prod.yamlì—ì„œ ì—°ê²° ì •ë³´ ìˆ˜ì •

# 3. ë™ì¼í•œ Recipeë¡œ ì‹¤í–‰
APP_ENV=prod uv run python main.py train --recipe-file recipes/my_model.yaml
```

### **í´ë¼ìš°ë“œ ê°„ ì „í™˜**

```bash
# GCP â†’ AWS ì „í™˜ ì˜ˆì‹œ
# 1. Snowflake ì„¤ì • (ë©€í‹°í´ë¼ìš°ë“œ DB)
# 2. config/prod_aws.yaml ìƒì„±
# 3. í™˜ê²½ ë³€ìˆ˜ë§Œ ë³€ê²½
APP_ENV=prod_aws uv run python main.py train --recipe-file recipes/my_model.yaml
```

---

## ğŸ› ï¸ **ì„¤ì • ê²€ì¦ ê°€ì´ë“œ**

### **ì—°ê²° í…ŒìŠ¤íŠ¸**

```bash
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
uv run python -c "
from src.settings import load_config_files
from src.engine.factory import Factory
settings = load_config_files()
factory = Factory(settings)
adapter = factory.create_data_adapter('sql')
print('DB ì—°ê²° ì„±ê³µ!')
"

# Feature Store ì—°ê²° í™•ì¸  
uv run python -c "
from src.settings import load_config_files
from src.engine.factory import Factory
settings = load_config_files()
factory = Factory(settings)
adapter = factory.create_feature_store_adapter()
print('Feature Store ì—°ê²° ì„±ê³µ!')
"
```

### **ì„¤ì • íŒŒì¼ ê²€ì¦**

```bash
# Recipe íŒŒì¼ ê²€ì¦
uv run python main.py validate --recipe-file recipes/my_model.yaml

# ì „ì²´ ì¸í”„ë¼ ê³„ì•½ í…ŒìŠ¤íŠ¸
uv run python main.py test-contract
```

---

## ğŸ“Š **ì„±ëŠ¥ ê°€ì´ë“œë¼ì¸**

### **ë°ì´í„° í¬ê¸°ë³„ ê¶Œì¥ êµ¬ì„±**

| ë°ì´í„° í¬ê¸° | ì¶”ì²œ SQL DB | ì¶”ì²œ Feature Store | ì˜ˆìƒ ì„±ëŠ¥ |
|------------|-------------|------------------|-----------|
| < 1GB | PostgreSQL | Redis (ë‹¨ì¼) | 1K rows/sec |
| 1GB - 100GB | PostgreSQL/BigQuery | Redis (ë‹¨ì¼) | 10K rows/sec |
| 100GB - 10TB | BigQuery/Snowflake | Redis (í´ëŸ¬ìŠ¤í„°) | 100K rows/sec |
| 10TB+ | BigQuery/Snowflake | Redis Labs/Bigtable | 1M+ rows/sec |

### **ë™ì‹œ ì‚¬ìš©ìë³„ ê¶Œì¥ êµ¬ì„±**

| ë™ì‹œ ì‚¬ìš©ì | ì¶”ì²œ ì„œë¹™ ë°©ì‹ | ì¶”ì²œ ì¸í”„ë¼ |
|------------|---------------|-------------|
| 1-10 | ë¡œì»¬ API ì„œë²„ | ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ |
| 10-100 | Docker ì»¨í…Œì´ë„ˆ | ë¡œë“œ ë°¸ëŸ°ì„œ |
| 100-1K | Kubernetes | ì˜¤í† ìŠ¤ì¼€ì¼ë§ |
| 1K+ | ì„œë²„ë¦¬ìŠ¤ (Cloud Run/Lambda) | ê¸€ë¡œë²Œ ë°°í¬ |

---

## ğŸ”§ **íŠ¸ëŸ¬ë¸”ìŠˆíŒ…**

### **ì—°ê²° ë¬¸ì œ í•´ê²°**

**ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨**
```bash
# 1. ì—°ê²° ë¬¸ìì—´ í™•ì¸
echo $DATABASE_URL

# 2. ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ í™•ì¸  
telnet your-db-host 5432

# 3. ì¸ì¦ ì •ë³´ í™•ì¸
psql "your-connection-string" -c "SELECT 1;"
```

**Feature Store ì—°ê²° ì‹¤íŒ¨**
```bash
# Redis ì—°ê²° í™•ì¸
redis-cli -h your-redis-host ping

# DynamoDB ê¶Œí•œ í™•ì¸
aws dynamodb list-tables --region your-region
```

### **ì„±ëŠ¥ ìµœì í™”**

**ëŠë¦° ì¿¼ë¦¬ ê°œì„ **
```yaml
# BigQuery ìµœì í™”
model:
  loader:
    source_uri: |
      SELECT *
      FROM your_table
      WHERE _PARTITIONTIME >= '2024-01-01'  # íŒŒí‹°ì…˜ í™œìš©
      LIMIT 1000000  # ì ì ˆí•œ ì œí•œ
```

**ë©”ëª¨ë¦¬ ë¶€ì¡± í•´ê²°**
```yaml
# ë°°ì¹˜ í¬ê¸° ì¡°ì •
model:
  loader:
    source_uri: "SELECT * FROM large_table LIMIT 100000"  # ìƒ˜í”Œë§
```

---

**ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ ë‹¹ì‹ ì˜ í˜„ì¬ ì¸í”„ë¼ì— ë§ëŠ” ìµœì ì˜ Modern ML Pipeline êµ¬ì„±ì„ ë§Œë“¤ì–´ë³´ì„¸ìš”!** 