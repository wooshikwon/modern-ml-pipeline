# ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

ê¸°ì¡´ ML íŒŒì´í”„ë¼ì¸ í”„ë¡œì íŠ¸ë¥¼ Modern ML Pipeline CLIë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤.

## ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡° ë¶„ì„
- [ ] Configì™€ Recipe ë¶„ë¦¬
- [ ] í™˜ê²½ë³„ ì„¤ì • íŒŒì¼ ìƒì„±
- [ ] SQL ì¿¼ë¦¬ íŒŒì¼ ì´ë™
- [ ] ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë¥¼ CLI ëª…ë ¹ì–´ë¡œ êµì²´
- [ ] í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
- [ ] íŒ€ì› êµìœ¡

## ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë‹¨ì¼ Config íŒŒì¼ ì‚¬ìš© ì¤‘

**í˜„ì¬ êµ¬ì¡°:**
```
project/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml    # ëª¨ë“  í™˜ê²½ ì„¤ì •ì´ í•˜ë‚˜ì—
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train.py       # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ models/
    â””â”€â”€ model.pkl      # ì €ì¥ëœ ëª¨ë¸
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„:**

#### 1. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
```bash
# Modern ML Pipeline êµ¬ì¡° ìƒì„±
mmp init --project-name migrated_project
cd migrated_project
```

#### 2. Config ë¶„ë¦¬
```bash
# ê¸°ì¡´ configë¥¼ í™˜ê²½ë³„ë¡œ ë¶„ë¦¬
cp ../config/config.yaml configs/local.yaml

# í™˜ê²½ë³„ ì„¤ì • ìƒì„±
mmp get-config --env-name dev
mmp get-config --env-name prod
```

#### 3. Config íŒŒì¼ ìˆ˜ì •
```yaml
# Before (config/config.yaml)
database:
  host: localhost
  port: 5432
  user: postgres
  password: secret123
  
mlflow:
  tracking_uri: http://localhost:5000

# After (configs/dev.yaml)
data_adapters:
  adapters:
    sql:
      config:
        connection_uri: "postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}"
        
mlflow:
  tracking_uri: "${MLFLOW_TRACKING_URI:http://localhost:5000}"
```

#### 4. í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
```bash
# .env.dev
ENV_NAME=dev
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=secret123
DB_NAME=ml_dev
MLFLOW_TRACKING_URI=http://localhost:5000
```

#### 5. Recipe ìƒì„±
```yaml
# recipes/model.yaml
name: "migrated_model"
model:
  class_path: "sklearn.ensemble.RandomForestClassifier"
  loader:
    adapter: "sql"
    source_uri: "sql/train_query.sql"
  data_interface:
    task_type: "classification"
    target_column: "target"
  hyperparameters:
    n_estimators: 100
    max_depth: 10
```

#### 6. ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ êµì²´
```bash
# Before
python scripts/train.py --config config/config.yaml

# After
mmp train --recipe-file recipes/model.yaml --env-name dev
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: í™˜ê²½ë³„ Config íŒŒì¼ ì‚¬ìš© ì¤‘

**í˜„ì¬ êµ¬ì¡°:**
```
project/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dev.yaml
â”‚   â”œâ”€â”€ staging.yaml
â”‚   â””â”€â”€ prod.yaml
â””â”€â”€ train.py
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„:**

#### 1. Config íŒŒì¼ ì´ë™
```bash
# configs ë””ë ‰í† ë¦¬ë¡œ ì´ë™
mkdir -p migrated_project/configs
cp config/*.yaml migrated_project/configs/
```

#### 2. í™˜ê²½ë³€ìˆ˜ ì¶”ì¶œ
ê° config íŒŒì¼ì—ì„œ í•˜ë“œì½”ë”©ëœ ê°’ì„ í™˜ê²½ë³€ìˆ˜ë¡œ ì¶”ì¶œ:

```yaml
# Before (config/dev.yaml)
database:
  connection: "postgresql://user:pass@localhost:5432/dev_db"

# After (configs/dev.yaml)
data_adapters:
  adapters:
    sql:
      config:
        connection_uri: "${DB_CONNECTION_URI}"
```

#### 3. .env íŒŒì¼ ìƒì„±
```bash
# ê° í™˜ê²½ë³„ë¡œ .env íŒŒì¼ ìƒì„±
for env in dev staging prod; do
  mmp get-config --env-name $env --template $env
  # ìƒì„±ëœ í…œí”Œë¦¿ í¸ì§‘
  vim .env.$env
done
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: Notebook ê¸°ë°˜ ê°œë°œ

**í˜„ì¬ êµ¬ì¡°:**
```
notebooks/
â”œâ”€â”€ 01_data_exploration.ipynb
â”œâ”€â”€ 02_feature_engineering.ipynb
â””â”€â”€ 03_model_training.ipynb
```

**ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„:**

#### 1. ì½”ë“œ ì¶”ì¶œ ë° ëª¨ë“ˆí™”
```python
# notebooks/utils.pyë¡œ ê³µí†µ í•¨ìˆ˜ ì¶”ì¶œ
def load_data(connection_string):
    # ë°ì´í„° ë¡œë“œ ë¡œì§
    pass

def preprocess_features(df):
    # íŠ¹ì„± ì „ì²˜ë¦¬ ë¡œì§
    pass
```

#### 2. SQL ì¿¼ë¦¬ ë¶„ë¦¬
```sql
-- sql/train_features.sql
SELECT 
    user_id,
    feature_1,
    feature_2,
    target
FROM ml_features
WHERE created_at >= '{{ start_date }}'
  AND created_at < '{{ end_date }}'
```

#### 3. Recipe ìƒì„±
```yaml
# recipes/notebook_model.yaml
name: "notebook_migrated_model"
model:
  class_path: "xgboost.XGBClassifier"
  loader:
    adapter: "sql"
    source_uri: "sql/train_features.sql"
  preprocessor:
    steps:
      - type: "standard_scaler"
        columns: ["feature_1", "feature_2"]
  hyperparameters:
    # Notebookì—ì„œ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„°
    n_estimators: 150
    max_depth: 8
    learning_rate: 0.1
```

#### 4. íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
# Notebook ëŒ€ì‹  CLIë¡œ ì‹¤í–‰
mmp train --recipe-file recipes/notebook_model.yaml --env-name dev
```

---

## ğŸ”§ ì¼ë°˜ì ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì—…

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë§ˆì´ê·¸ë ˆì´ì…˜

#### SQLAlchemyì—ì„œ
```python
# Before
from sqlalchemy import create_engine
engine = create_engine("postgresql://user:pass@localhost/db")
df = pd.read_sql("SELECT * FROM table", engine)

# After (config)
data_adapters:
  adapters:
    sql:
      config:
        connection_uri: "${DB_CONNECTION_URI}"

# After (recipe)
loader:
  adapter: "sql"
  source_uri: "sql/query.sql"
```

#### psycopg2ì—ì„œ
```python
# Before
import psycopg2
conn = psycopg2.connect(
    host="localhost",
    database="db",
    user="user",
    password="pass"
)

# After (.env.dev)
DB_HOST=localhost
DB_NAME=db
DB_USER=user
DB_PASSWORD=pass
DB_CONNECTION_URI=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:5432/${DB_NAME}
```

### MLflow í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜

#### ìˆ˜ë™ MLflow ë¡œê¹…ì—ì„œ
```python
# Before
import mlflow
mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("my_experiment")

with mlflow.start_run():
    mlflow.log_param("n_estimators", 100)
    mlflow.log_metric("accuracy", 0.95)
    mlflow.sklearn.log_model(model, "model")

# After (ìë™ìœ¼ë¡œ ì²˜ë¦¬ë¨)
# configs/dev.yaml
mlflow:
  tracking_uri: "${MLFLOW_TRACKING_URI}"
  experiment_name: "my_experiment"
```

### Feature Store ë§ˆì´ê·¸ë ˆì´ì…˜

#### Feast í†µí•©
```yaml
# configs/prod.yamlì— ì¶”ê°€
feature_store:
  provider: "feast"
  feast_config:
    project: "ml_features"
    registry: "gs://bucket/registry.pb"
    online_store:
      type: "redis"
      connection_string: "${REDIS_HOST}:${REDIS_PORT}"
```

### ëª¨ë¸ ì„œë¹™ ë§ˆì´ê·¸ë ˆì´ì…˜

#### Flask/FastAPIì—ì„œ
```python
# Before (app.py)
from flask import Flask, request, jsonify
app = Flask(__name__)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    prediction = model.predict(data)
    return jsonify(prediction)

# After
mmp serve-api --run-id <mlflow-run-id> --env-name prod --port 8000
```

---

## ğŸ“ Recipe ì‘ì„± ê°€ì´ë“œ

### ê¸°ì¡´ í•™ìŠµ ì½”ë“œë¥¼ Recipeë¡œ ë³€í™˜

#### 1. ëª¨ë¸ ì •ì˜
```python
# Before (train.py)
from xgboost import XGBClassifier
model = XGBClassifier(n_estimators=100, max_depth=6)

# After (recipe.yaml)
model:
  class_path: "xgboost.XGBClassifier"
  hyperparameters:
    n_estimators: 100
    max_depth: 6
```

#### 2. ë°ì´í„° ë¡œë“œ
```python
# Before
df = pd.read_sql("SELECT * FROM features", connection)

# After
loader:
  adapter: "sql"
  source_uri: "sql/features.sql"
```

#### 3. ì „ì²˜ë¦¬
```python
# Before
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# After
preprocessor:
  steps:
    - type: "standard_scaler"
      columns: ["feature_1", "feature_2"]
```

---

## ğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# migrate.sh - ê¸°ì¡´ í”„ë¡œì íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ë„ìš°ë¯¸

# 1. ë°±ì—… ìƒì„±
echo "Creating backup..."
cp -r . ../project_backup_$(date +%Y%m%d)

# 2. Modern ML Pipeline êµ¬ì¡° ìƒì„±
echo "Initializing MMP structure..."
mmp init --project-name $(basename $PWD)_migrated

# 3. Config íŒŒì¼ ë³µì‚¬
echo "Migrating config files..."
if [ -d "config" ]; then
    cp config/*.yaml configs/
elif [ -d "configs" ]; then
    cp configs/*.yaml configs/
fi

# 4. SQL íŒŒì¼ ë³µì‚¬
echo "Migrating SQL files..."
if [ -d "sql" ]; then
    cp -r sql/* sql/
fi

# 5. í™˜ê²½ë³„ ì„¤ì • ìƒì„±
echo "Creating environment configs..."
for env in dev staging prod; do
    if [ -f "configs/$env.yaml" ]; then
        mmp get-config --env-name $env --template $env --non-interactive
    fi
done

echo "Migration structure created. Please:"
echo "1. Update config files to use environment variables"
echo "2. Create Recipe files for your models"
echo "3. Set up .env files with actual values"
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. ë°ì´í„° ë³´ì•ˆ
- ì ˆëŒ€ ë¹„ë°€ë²ˆí˜¸ë‚˜ API í‚¤ë¥¼ Config íŒŒì¼ì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ˆì„¸ìš”
- .env íŒŒì¼ì€ ë°˜ë“œì‹œ .gitignoreì— ì¶”ê°€í•˜ì„¸ìš”
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” Secret Manager ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤

### 2. ê²½ë¡œ ì²˜ë¦¬
- ìƒëŒ€ ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±
- SQL íŒŒì¼ì€ sql/ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜
- Recipe íŒŒì¼ì€ recipes/ ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜

### 3. í˜¸í™˜ì„±
- Python 3.8+ í•„ìš”
- uv íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € ì‚¬ìš©
- ê¸°ì¡´ requirements.txtëŠ” pyproject.tomlë¡œ ë³€í™˜

---

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ: Import ì˜¤ë¥˜
```python
ModuleNotFoundError: No module named 'src'
```

**í•´ê²°:**
```bash
# PYTHONPATH ì„¤ì •
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# ë˜ëŠ” uv ì‚¬ìš©
uv sync
uv run mmp train --recipe-file recipes/model.yaml --env-name dev
```

### ë¬¸ì œ: Config íŒŒì¼ í˜•ì‹ ì˜¤ë¥˜
```
ValueError: Config file format invalid
```

**í•´ê²°:**
```bash
# YAML ê²€ì¦
python -c "import yaml; yaml.safe_load(open('configs/dev.yaml'))"

# í™˜ê²½ë³€ìˆ˜ ì¹˜í™˜ í…ŒìŠ¤íŠ¸
python -c "
from src.cli.utils.env_loader import load_config_with_env
config = load_config_with_env('dev')
print(config)
"
```

### ë¬¸ì œ: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨
```
psycopg2.OperationalError: could not connect to server
```

**í•´ê²°:**
```bash
# ì—°ê²° í…ŒìŠ¤íŠ¸
mmp system-check --env-name dev --actionable

# í™˜ê²½ë³€ìˆ˜ í™•ì¸
cat .env.dev
source .env.dev
echo $DB_HOST
```

---

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [ì‚¬ìš©ì ê°€ì´ë“œ](./USER_GUIDE.md)
- [API ë ˆí¼ëŸ°ìŠ¤](./API_REFERENCE.md)
- [ì˜ˆì œ í”„ë¡œì íŠ¸](https://github.com/your-org/mmp-examples)
- [FAQ](./FAQ.md)

## ğŸ¤ ë„ì›€ ìš”ì²­

ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. [GitHub Issues](https://github.com/your-org/modern-ml-pipeline/issues)ì— ë¬¸ì˜
2. [Discord ì»¤ë®¤ë‹ˆí‹°](https://discord.gg/your-invite) ì°¸ì—¬
3. ì´ë©”ì¼: support@your-org.com