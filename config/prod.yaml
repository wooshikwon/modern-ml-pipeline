# =============================================================================
# config/prod.yaml - 프로덕션 환경 설정
# =============================================================================
# 
# 🎯 PROD 환경 철학: "성능, 안정성, 관측 가능성의 완벽한 삼위일체"
# - 클라우드 네이티브 서비스 활용
# - 무제한 확장성과 운영 안정성
# - 완전한 관측 가능성과 모니터링
#
# 📋 주요 Use Cases:
# 1. 대규모 프로덕션 ML 서빙 (1M+ requests/day)
# 2. 엔터프라이즈 배치 추론 (TB급 데이터 처리)
# 3. 멀티 리전 글로벌 서비스
# 4. 고가용성 미션 크리티컬 시스템
# 5. 규제 준수 및 감사 추적
# =============================================================================

# 📊 MLflow 설정 - 클라우드 네이티브
mlflow:
  tracking_uri: ${MLFLOW_TRACKING_URI}  # 클라우드 MLflow 서버
  experiment_name: "MMP-Prod-Experiment"
  
  # 🌍 Use Case별 MLflow 설정 예시:
  #
  # 🏢 GCP 환경:
  #   tracking_uri: "https://mlflow.your-company.com"
  #   artifact_location: "gs://mmp-prod-artifacts"
  #
  # ☁️ AWS 환경:  
  #   tracking_uri: "https://mlflow.amazonaws.com"
  #   artifact_location: "s3://mmp-prod-artifacts"
  #
  # 🔵 Azure 환경:
  #   tracking_uri: "https://mlflow.azureml.com"
  #   artifact_location: "abfss://artifacts@company.dfs.core.windows.net"
  #
  # 🏭 멀티 리전:
  #   tracking_uri: "${MLFLOW_TRACKING_URI_${REGION}}"
  #   experiment_name: "MMP-Prod-${REGION}-${ENVIRONMENT}"

# 🗃️ 데이터 어댑터 - 엔터프라이즈급 스케일
data_adapters:
  default_loader: "sql"              # 대규모 SQL 쿼리 실행
  default_storage: "storage"         # 클라우드 스토리지
  default_feature_store: "feature_store"  # Feature Store 활용
  
  adapters:
    # SQL 어댑터 - 대규모 데이터 웨어하우스
    sql:
      class_name: SqlAdapter
      config:
        # 🌍 Use Case별 데이터베이스 설정:
        #
        # 🏢 BigQuery (GCP):
        connection_uri: "bigquery://${GCP_PROJECT_ID}/${DATASET_ID}"
        # 추가 옵션:
        # job_config:
        #   maximum_bytes_billed: 1000000000  # 10GB 제한
        #   use_query_cache: true
        #   dry_run: false
        #
        # ❄️ Snowflake (Multi-cloud):
        # connection_uri: "snowflake://${SNOWFLAKE_USER}:${SNOWFLAKE_PASSWORD}@${SNOWFLAKE_ACCOUNT}/${SNOWFLAKE_DATABASE}/${SNOWFLAKE_SCHEMA}?warehouse=${SNOWFLAKE_WAREHOUSE}"
        #
        # 🟦 Azure Synapse:
        # connection_uri: "mssql+pyodbc://${AZURE_SQL_USER}:${AZURE_SQL_PASSWORD}@${AZURE_SQL_SERVER}.database.windows.net:1433/${AZURE_SQL_DATABASE}?driver=ODBC+Driver+17+for+SQL+Server"
        #
        # 🐘 PostgreSQL (Enterprise):
        # connection_uri: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}"
        # pool_size: 20
        # max_overflow: 0
        # pool_pre_ping: true
    
    # Storage 어댑터 - 클라우드 스토리지
    storage:
      class_name: StorageAdapter
      config:
        # 🌍 Use Case별 스토리지 설정:
        #
        # 🏢 Google Cloud Storage:
        storage_options:
          project: ${GCP_PROJECT_ID}
          token: ${GCS_SERVICE_ACCOUNT_KEY}
        # 추가 옵션:
        # default_cache_type: "simple"
        # default_cache_storage: "gs://mmp-cache"
        #
        # ☁️ AWS S3:
        # storage_options:
        #   key: ${AWS_ACCESS_KEY_ID}
        #   secret: ${AWS_SECRET_ACCESS_KEY}
        #   client_kwargs:
        #     region_name: ${AWS_REGION}
        #     endpoint_url: https://s3.${AWS_REGION}.amazonaws.com
        #
        # 🔵 Azure Blob Storage:
        # storage_options:
        #   account_name: ${AZURE_STORAGE_ACCOUNT}
        #   account_key: ${AZURE_STORAGE_KEY}
        #   connection_string: ${AZURE_STORAGE_CONNECTION_STRING}
    
    # Feature Store 어댑터 - 엔터프라이즈 Feature Store
    feature_store:
      class_name: FeastAdapter
      config: {}  # Feast 설정은 feature_store 섹션에서 관리

# 🍽️ Feature Store 설정 - 엔터프라이즈급 피처 관리
feature_store:
  provider: "feast"
  feast_config:
    project: "mmp-prod"
    provider: "gcp"  # 또는 "aws", "azure", "local"
    registry: "gs://mmp-prod-registry/registry.db"
    
    # Offline Store - 대규모 배치 피처 처리
    offline_store:
      type: "bigquery"
      project_id: ${GCP_PROJECT_ID}
      dataset_id: "feature_store"
      
      # 🌍 Alternative Offline Stores:
      #
      # ❄️ Snowflake:
      # type: "snowflake"
      # account: ${SNOWFLAKE_ACCOUNT}
      # user: ${SNOWFLAKE_USER}
      # password: ${SNOWFLAKE_PASSWORD}
      # database: "FEATURE_STORE"
      # warehouse: "COMPUTE_WH"
      #
      # 🔵 Azure Synapse:
      # type: "synapse"
      # jdbc_driver: "com.microsoft.sqlserver.jdbc.SQLServerDriver"
      # jdbc_url: "jdbc:sqlserver://${AZURE_SYNAPSE_ENDPOINT}"
    
    # Online Store - 실시간 피처 서빙
    online_store:
      type: "redis"
      connection_string: ${REDIS_CONNECTION_STRING}
      ssl: true
      
      # 🌍 Alternative Online Stores:
      #
      # ⚡ Redis Cluster (고가용성):
      # type: "redis"
      # redis_type: "redis_cluster"
      # connection_string: ${REDIS_CLUSTER_CONNECTION_STRING}
      # startup_nodes:
      #   - host: redis-cluster-1.company.com
      #     port: 6379
      #   - host: redis-cluster-2.company.com
      #     port: 6379
      #
      # 🗄️ DynamoDB (AWS):
      # type: "dynamodb"
      # region: ${AWS_REGION}
      # table_name: "feast_online_store"
      # aws_access_key_id: ${AWS_ACCESS_KEY_ID}
      # aws_secret_access_key: ${AWS_SECRET_ACCESS_KEY}
      #
      # 🟦 Azure Cosmos DB:
      # type: "cosmosdb"
      # connection_string: ${COSMOSDB_CONNECTION_STRING}
      # database_name: "feast_online_store"

# ⚡ 하이퍼파라미터 튜닝 - 대규모 최적화
hyperparameter_tuning:
  enabled: true
  timeout: 7200           # 2시간 (충분한 탐색 시간)
  engine: "optuna"
  
  # 🏭 프로덕션급 최적화 설정
  pruning:
    enabled: true
    algorithm: "MedianPruner"
    n_startup_trials: 10    # 충분한 초기 trial
    n_warmup_steps: 20
  
  parallelization:
    n_jobs: 16             # 고성능 병렬 처리
    
  # 🎯 Use Case별 튜닝 전략:
  #
  # 🚀 빠른 배포 (1시간 제한):
  #   timeout: 3600
  #   parallelization:
  #     n_jobs: 32
  #
  # 🔬 심층 최적화 (하루 종일):
  #   timeout: 86400        # 24시간
  #   parallelization:
  #     n_jobs: 64
  #   advanced_pruning:
  #     enabled: true
  #     min_trials: 100
  #
  # 💰 비용 최적화:
  #   timeout: 1800         # 30분
  #   cost_aware_pruning: true
  #   resource_limits:
  #     max_memory_gb: 32
  #     max_cpu_cores: 8

# 🌐 환경 변수 - 프로덕션 인프라
environment:
  app_env: "prod"
  gcp_project_id: ${GCP_PROJECT_ID}
  
  # 🔒 보안 설정
  security:
    enable_authentication: true
    api_key_required: true
    rate_limiting: true
    
  # 📊 모니터링 설정
  monitoring:
    enable_metrics: true
    enable_tracing: true
    enable_profiling: false  # 성능상 기본 비활성화
    
  # 🚨 알림 설정
  alerting:
    enable_alerts: true
    error_threshold: 0.01    # 1% 에러율에서 알림
    latency_threshold: 1000  # 1초 이상에서 알림

# 🔄 API 서빙 - 엔터프라이즈급 서빙
serving:
  enabled: true
  model_stage: "Production"  # MLflow 모델 스테이지
  
  # 🎯 Use Case별 서빙 설정:
  #
  # 🚀 고성능 서빙:
  #   autoscaling:
  #     min_replicas: 3
  #     max_replicas: 100
  #     target_cpu_utilization: 70
  #   resources:
  #     cpu: "2000m"
  #     memory: "4Gi"
  #
  # 🌍 글로벌 서빙:
  #   multi_region:
  #     enabled: true
  #     regions: ["us-central1", "europe-west1", "asia-southeast1"]
  #     load_balancing: "round_robin"
  #
  # 🔒 보안 강화:
  #   security:
  #     enable_https: true
  #     require_api_key: true
  #     enable_cors: false
  #     allowed_origins: ["https://company.com"]

# 📦 아티팩트 저장소 - 엔터프라이즈 데이터 관리
artifact_stores:
  # 피처 증강 데이터
  augmented_dataset:
    enabled: true
    base_uri: "gs://mmp-prod-datasets/augmented"
    
    # 🌍 Use Case별 저장소 설정:
    # base_uri: "s3://mmp-prod-datasets/augmented"              # AWS
    # base_uri: "abfss://datasets@company.dfs.core.windows.net" # Azure
    # base_uri: "hdfs://hdfs-cluster/mmp/datasets"              # On-premise
    
  # 전처리 데이터 (감사용)
  preprocessed_dataset:
    enabled: true
    base_uri: "gs://mmp-prod-datasets/preprocessed"
    retention_days: 90    # 90일 보관
    
  # 예측 결과 (규제 준수용)
  prediction_results:
    enabled: true
    base_uri: "gs://mmp-prod-predictions"
    
    # 📊 데이터 거버넌스
    governance:
      enable_lineage: true      # 데이터 계보 추적
      enable_versioning: true   # 버전 관리
      retention_policy: "5_years"  # 5년 보관
      
    # 🗄️ 백업 설정
    backup:
      enabled: true
      schedule: "0 2 * * *"     # 매일 새벽 2시
      retention: "1_year"
      
    # PostgreSQL 저장 (실시간 조회용)
    postgres_storage:
      enabled: true
      table_name: "batch_predictions"
      connection_uri: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:5432/${POSTGRES_DB}"
      
      # 🎯 Use Case별 DB 설정:
      # 
      # 🏢 Cloud SQL (GCP):
      # connection_uri: "postgresql://postgres:${POSTGRES_PASSWORD}@${CLOUD_SQL_IP}:5432/mmp_prod"
      # ssl_mode: "require"
      #
      # ☁️ RDS (AWS):
      # connection_uri: "postgresql://postgres:${POSTGRES_PASSWORD}@${RDS_ENDPOINT}:5432/mmp_prod"
      # pool_size: 20
      #
      # 🔵 Azure Database:
      # connection_uri: "postgresql://postgres@azure-server:${POSTGRES_PASSWORD}@azure-server.postgres.database.azure.com:5432/mmp_prod"

# 🔍 로깅 및 모니터링 - 운영 관측성
logging:
  level: "INFO"
  format: "json"          # 구조화된 로깅
  
  # 📊 로그 수집
  aggregation:
    enabled: true
    
    # 🌍 Use Case별 로그 수집:
    # 
    # 🏢 Google Cloud Logging:
    # service: "cloud_logging"
    # project_id: ${GCP_PROJECT_ID}
    #
    # ☁️ AWS CloudWatch:
    # service: "cloudwatch"
    # log_group: "/aws/lambda/mmp-prod"
    # region: ${AWS_REGION}
    #
    # 🔵 Azure Monitor:
    # service: "azure_monitor"
    # workspace_id: ${AZURE_WORKSPACE_ID}

# 💡 운영자 가이드:
#
# 🚀 프로덕션 배포:
#   APP_ENV=prod uv run python main.py train --recipe-file production_model
#
# 📊 배치 추론 실행:
#   APP_ENV=prod uv run python main.py batch-inference --run-id <PROD_RUN_ID>
#
# 🌐 API 서버 시작:
#   APP_ENV=prod uv run python main.py serve-api --run-id <PROD_RUN_ID> --host 0.0.0.0 --port 8080
#
# 📈 모니터링 대시보드:
#   https://monitoring.company.com/mmp-prod
#
# 🚨 알림 설정:
#   Slack: #mmp-alerts, PagerDuty: mmp-prod-oncall