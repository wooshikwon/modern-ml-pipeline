# config/prod.yaml: 'prod' í™˜ê²½ ì „ìš© ì„¤ì •
# -----------------------------------------------------------------------------
# ì´ íŒŒì¼ì€ APP_ENV=prod í™˜ê²½ì—ì„œ base.yamlê³¼ dev.yamlì˜ ì„¤ì •ì„ ë®ì–´ì“°ëŠ”
# ì‹¤ì œ ìš´ì˜ í™˜ê²½ì„ ìœ„í•œ ê°’ë§Œ ì •ì˜í•©ë‹ˆë‹¤.
# ì´ íŒŒì¼ì€ ë§¤ìš° ì‹ ì¤‘í•˜ê²Œ ê´€ë¦¬ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
# ğŸ†• GCP + BigQuery + Redis Labs + Cloud Run ìŠ¤íƒ ì„¤ì •
# -----------------------------------------------------------------------------

# ğŸ†• ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (BigQuery)
database:
  type: "bigquery"
  project_id: "${GCP_PROJECT_ID}"
  dataset_id: "ml_pipeline_prod"
  location: "us-central1"
  
  # BigQuery ìµœì í™”
  query_job_config:
    use_legacy_sql: false
    maximum_bytes_billed: 10737418240  # 10GB ì œí•œ
    use_query_cache: true
  
  # ì¸ì¦
  credentials_path: "${GOOGLE_APPLICATION_CREDENTIALS}"
  service_account_key: "${GCP_SERVICE_ACCOUNT_KEY}"

# ï¿½ï¿½ Feature Store ì„¤ì • (Blueprint v17.0: config í†µí•©)
feature_store:
  provider: "feast"
  
  # ğŸ¯ Blueprint ì›ì¹™ 1 ì¤€ìˆ˜: ëª¨ë“  ì„¤ì •ì„ configì— í†µí•©
  # feast ë³„ë„ íŒŒì¼ ëŒ€ì‹  ì—¬ê¸°ì„œ ì™„ì „íˆ ì •ì˜
  feast_config:
    project: "ml_pipeline_prod"
    provider: "gcp"
    registry: "gs://${GCS_FEAST_BUCKET}/feast-registry/registry.db"
    
    # Offline Store (BigQuery)
    offline_store:
      type: "bigquery"
      project_id: "${GCP_PROJECT_ID}"
      dataset: "feature_mart"
      location: "us-central1"
      
      # BigQuery ìµœì í™” ì„¤ì •
      billing_project_id: "${GCP_PROJECT_ID}"
      table_expiration_days: 365
      
      # ì¿¼ë¦¬ ìµœì í™”
      job_config:
        query:
          use_legacy_sql: false
          use_query_cache: true
          maximum_bytes_billed: 1073741824  # 1GB limit per query
        labels:
          team: "ml-platform"
          environment: "production"
          service: "feast"
    
    # Online Store (Redis Labs)
    online_store:
      type: "redis"
      connection_string: "${REDIS_LABS_CONNECTION_STRING}"
      database: 0
      key_ttl: 259200  # 3ì¼ (ìš´ì˜í™˜ê²½)
      
      # Redis Labs ìµœì í™”
      ssl: true
      ssl_cert_reqs: "required"
      ssl_keyfile: null
      ssl_certfile: null
      ssl_ca_certs: null
    
    # í´ë¼ìš°ë“œ ë°°ì¹˜ ì—”ì§„
    batch_engine:
      type: "gcp.dataflow"
      
      # Dataflow ì„¤ì • (ì„ íƒì  - ëŒ€ê·œëª¨ materializationìš©)
      dataflow_config:
        project_id: "${GCP_PROJECT_ID}"
        region: "us-central1"
        staging_location: "gs://ml-pipeline-dataflow-staging"
        temp_location: "gs://ml-pipeline-dataflow-temp"
        
        # ë¦¬ì†ŒìŠ¤ ì„¤ì •
        runner: "DataflowRunner"
        machine_type: "n1-standard-2"
        max_num_workers: 10
    
    # Feature Server (ìš´ì˜í™˜ê²½ì—ì„œ í™œì„±í™”)
    feature_server:
      enabled: true
      host: "0.0.0.0"
      port: 6566
      
      # ë³´ì•ˆ ì„¤ì •
      auth:
        enabled: true
        type: "oidc"
    
    # ìš´ì˜ìš© ì—”í‹°í‹° ì •ì˜
    entities:
      - name: "user"
        value_type: "STRING"
        description: "ì‚¬ìš©ì ì‹ë³„ì"
      - name: "product"
        value_type: "STRING"
        description: "ìƒí’ˆ ì‹ë³„ì"
      - name: "session"
        value_type: "STRING"
        description: "ì„¸ì…˜ ì‹ë³„ì"
    
    # Entity Key Serialization
    entity_key_serialization_version: 2
    
    # Flags
    flags:
      alpha_features: true
      beta_features: true

# ğŸ†• í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ìš´ì˜ í™˜ê²½)
hyperparameter_tuning:
  enabled: true
  timeout: 3600  # 1ì‹œê°„ í—ˆìš© (ìš´ì˜ í™˜ê²½)
  max_parallel_jobs: 8  # í´ë¼ìš°ë“œ ë¦¬ì†ŒìŠ¤ í™œìš©
  
  # Optuna ë°±ì—”ë“œ (Cloud SQL PostgreSQL)
  study_storage: "postgresql://${OPTUNA_DB_USER}:${OPTUNA_DB_PASSWORD}@${OPTUNA_DB_HOST}:5432/${OPTUNA_DB_NAME}"
  
  pruning:
    enabled: true
    algorithm: "MedianPruner"
    n_startup_trials: 5
    
  # ìš´ì˜ í™˜ê²½ ì•ˆì „ì¥ì¹˜
  resource_limits:
    max_memory_gb: 32
    max_cpu_cores: 16

environment:
  # ìš´ì˜ìš© GCP í”„ë¡œì íŠ¸ ID
  gcp_project_id: "${GCP_PROJECT_ID}"

mlflow:
  # ğŸ†• Cloud Runì—ì„œ ì‹¤í–‰ë˜ëŠ” MLflow Tracking Server
  tracking_uri: "https://${MLFLOW_TRACKING_SERVER_URL}"
  experiment_name: "Campaign-Uplift-Modeling-Prod"
  artifact_location: "gs://${GCS_MLFLOW_BUCKET}/artifacts"
  
  # GCS ë°±ì—”ë“œ ì„¤ì •
  storage:
    backend: "gcs"
    bucket: "${GCS_MLFLOW_BUCKET}"
    prefix: "mlflow-artifacts"

serving:
  # API ì„œë²„ëŠ” ë°˜ë“œì‹œ "Production" ìŠ¤í…Œì´ì§€ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
  model_stage: "Production"
  # ğŸ†• Redis Labsë¥¼ ì‹¤ì‹œê°„ í”¼ì²˜ ìŠ¤í† ì–´ë¡œ ì‚¬ìš©
  realtime_feature_store:
    store_type: "redis"
    connection:
      host: "${REDIS_LABS_HOST}"
      port: "${REDIS_LABS_PORT}"
      password: "${REDIS_LABS_PASSWORD}"
      ssl: true
      db: 0

artifact_stores:
  augmented_dataset:
    # ğŸ†• ìš´ì˜ í™˜ê²½ì—ì„œëŠ” BigQueryì— ì €ì¥
    enabled: true
    base_uri: "bq://${GCP_PROJECT_ID}.feature_mart_prod"
  preprocessed_dataset:
    # ğŸ†• ìš´ì˜ í™˜ê²½ì—ì„œëŠ” GCSì— ì €ì¥ (ì„±ëŠ¥ ì¶”ì ìš©)
    enabled: true
    base_uri: "gs://${GCS_DATA_BUCKET}/processed"
  prediction_results:
    # ìš´ì˜ ì˜ˆì¸¡ ê²°ê³¼ëŠ” ì§€ì •ëœ BigQuery í…Œì´ë¸”ì— ì €ì¥ë©ë‹ˆë‹¤.
    base_uri: "bq://${GCP_PROJECT_ID}.prediction_results_prod"

# ğŸ†• ìŠ¤í† ë¦¬ì§€ ì„¤ì • (Google Cloud Storage)
storage:
  type: "gcs"
  bucket: "${GCS_DATA_BUCKET}"
  prefix: "ml-pipeline-data"
  
  # GCS ìµœì í™”
  transfer_config:
    chunk_size: 8388608  # 8MB chunks
    max_retry_delay: 60

# ğŸ†• ë¡œê¹… ì„¤ì • (Cloud Logging)
logging:
  level: "INFO"  # ìš´ì˜ í™˜ê²½ì—ì„œ ì ì ˆí•œ ë¡œê¹…
  format: "json"  # êµ¬ì¡°í™”ëœ ë¡œê¹…
  
  handlers:
    - type: "cloud_logging"
      project_id: "${GCP_PROJECT_ID}"
      resource_type: "cloud_run_revision"
      
    - type: "file"
      level: "WARNING"
      filename: "/tmp/app-errors.log"
      max_size: "100MB"
      backup_count: 3

# ğŸ†• ìš´ì˜ í™˜ê²½ ìµœì í™”
production:
  auto_scaling:
    min_instances: 1
    max_instances: 10
    target_cpu_utilization: 70
    
  performance:
    enable_caching: true
    cache_ttl: 3600
    connection_pooling: true
    
  # ì•ˆì „ì¥ì¹˜
  max_training_time: 7200  # 2ì‹œê°„ ì œí•œ
  max_concurrent_jobs: 5

# ğŸ†• ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ (Cloud Monitoring)
monitoring:
  enabled: true
  
  # Cloud Monitoring í†µí•©
  metrics:
    project_id: "${GCP_PROJECT_ID}"
    
    # í•µì‹¬ ë©”íŠ¸ë¦­
    custom_metrics:
      - name: "ml_pipeline/training_duration"
        description: "Model training duration in seconds"
      - name: "ml_pipeline/prediction_latency"
        description: "Prediction API latency in milliseconds"
      - name: "ml_pipeline/feature_store_hits"
        description: "Feature store cache hits"
        
  # ì•Œë¦¼ ì„¤ì •
  alerting:
    notification_channels: ["${SLACK_WEBHOOK_URL}"]
    
    policies:
      - name: "High Error Rate"
        condition: "error_rate > 0.05"
        duration: "5m"
        
      - name: "High Latency"
        condition: "prediction_latency > 1000ms"
        duration: "2m"

# ğŸ†• ë³´ì•ˆ ì„¤ì • (ìš´ì˜ í™˜ê²½)
security:
  authentication_required: true
  api_key_required: true
  ssl_enabled: true
  
  # IAM ì„¤ì •
  service_accounts:
    ml_pipeline: "${ML_PIPELINE_SERVICE_ACCOUNT}"
    mlflow: "${MLFLOW_SERVICE_ACCOUNT}"
    feast: "${FEAST_SERVICE_ACCOUNT}"
    
  # ì•”í˜¸í™”
  encryption:
    in_transit: true
    at_rest: true
    kms_key_id: "${GCP_KMS_KEY_ID}"

# ğŸ†• í™˜ê²½ ë³€ìˆ˜ í…œí”Œë¦¿
environment_variables:
  # GCP ê´€ë ¨
  GCP_PROJECT_ID: "${GCP_PROJECT_ID}"
  GOOGLE_APPLICATION_CREDENTIALS: "${GOOGLE_APPLICATION_CREDENTIALS}"
  
  # Feature Store ê´€ë ¨
  REDIS_LABS_CONNECTION_STRING: "${REDIS_LABS_CONNECTION_STRING}"
  GCS_FEAST_BUCKET: "${GCS_FEAST_BUCKET}"
  
  # MLflow ê´€ë ¨
  GCS_MLFLOW_BUCKET: "${GCS_MLFLOW_BUCKET}"
  MLFLOW_TRACKING_SERVER_URL: "${MLFLOW_TRACKING_SERVER_URL}"
  
  # ë³´ì•ˆ ê´€ë ¨
  API_SECRET_KEY: "${API_SECRET_KEY}"
  ML_PIPELINE_SERVICE_ACCOUNT: "${ML_PIPELINE_SERVICE_ACCOUNT}"