# config/dev.yaml: 'dev' í™˜ê²½ ì „ìš© ì„¤ì •
# -----------------------------------------------------------------------------
# ì´ íŒŒì¼ì€ APP_ENV=dev í™˜ê²½ì—ì„œ base.yamlì˜ ì„¤ì •ì„ ë®ì–´ì“°ëŠ” ê°’ë§Œ ì •ì˜í•©ë‹ˆë‹¤.
# Blueprint v17.0: DEV í™˜ê²½ì˜ ì™„ì „í•œ ê¸°ëŠ¥ì„ ì™¸ë¶€ ì¸í”„ë¼ ì—†ì´ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
# ì² í•™: "ëª¨ë“  ê¸°ëŠ¥ì´ ì™„ì „íˆ ì‘ë™í•˜ëŠ” ì•ˆì „í•œ ì‹¤í—˜ì‹¤"
# -----------------------------------------------------------------------------

# ğŸ†• ë°ì´í„° ì–´ëŒ‘í„° ì„¤ì • (Blueprint v17.0: ì™¸ë¶€ ì¸í”„ë¼ ì—†ì´ DEV í™˜ê²½ í…ŒìŠ¤íŠ¸)
data_adapters:
  # DEV í™˜ê²½: filesystem ê¸°ë°˜ì´ì§€ë§Œ ê¸°ëŠ¥ì ìœ¼ë¡œëŠ” ì™„ì „í•œ êµ¬í˜„
  default_loader: "filesystem"
  default_storage: "filesystem"
  default_feature_store: "filesystem"
  
  # DEV í™˜ê²½ íŠ¹í™” ì–´ëŒ‘í„° ì„¤ì •
  adapters:
    filesystem:
      class_name: "FileSystemAdapter"
      config:
        base_path: "./data"
        supported_formats: ["parquet", "csv", "json"]
        auto_create_dirs: true
        # DEV í™˜ê²½: ë” ìƒì„¸í•œ ë¡œê¹…
        enable_detailed_logging: true
    
    # ë¯¸ë˜ í™•ì¥ì„ ìœ„í•œ ì„¤ì • (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    postgresql:
      class_name: "PostgreSQLAdapter"
      config:
        host: "localhost"
        port: 5432
        database: "mlpipeline"
        user: "mluser"
        password: "mlpassword"
        schema: "public"
        pool_size: 10
        max_overflow: 20
        echo_sql: true
    
    redis:
      class_name: "RedisAdapter"
      config:
        host: "localhost"
        port: 6379
        db: 0
        password: ""
        decode_responses: true
        socket_timeout: 5
        connection_pool_max_connections: 20

# ğŸ†• Feature Store ì„¤ì • (Blueprint v17.0: ì™„ì „í•œ ê¸°ëŠ¥ì„ filesystemìœ¼ë¡œ ì‹œë®¬ë ˆì´ì…˜)
feature_store:
  provider: "filesystem"  # ì™¸ë¶€ ì¸í”„ë¼ ì—†ì´ Feature Store ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
  
  # DEV í™˜ê²½ íŠ¹í™” ì„¤ì •
  feast_config:
    project: "ml_pipeline_dev"
    provider: "local"
    
    # Registry (ë¡œì»¬ íŒŒì¼ ê¸°ë°˜)
    registry: "data/feature_store/dev_registry.sqlite"
    
    # Offline Store (íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜)
    offline_store:
      type: "file"
      path: "data/feature_store/dev_offline"
    
    # Online Store (ë¡œì»¬ SQLite)
    online_store:
      type: "sqlite"
      path: "data/feature_store/dev_online.sqlite"
    
    # Entity ì •ì˜
    entities:
      - name: "user"
        value_type: "STRING"
        description: "ì‚¬ìš©ì ì‹ë³„ì"
      - name: "product"
        value_type: "STRING"
        description: "ìƒí’ˆ ì‹ë³„ì"
      - name: "session"
        value_type: "STRING"
        description: "ì„¸ì…˜ ì‹ë³„ì"
    
    # ì„¤ì • í”Œë˜ê·¸
    entity_key_serialization_version: 2
    flags:
      alpha_features: true
      beta_features: true  # DEV í™˜ê²½ì—ì„œ ë² íƒ€ ê¸°ëŠ¥ í™œì„±í™”
    
    # ë°°ì¹˜ ì—”ì§„
    batch_engine:
      type: "local"
    
    # Feature Server (DEV í™˜ê²½ì—ì„œëŠ” ë¹„í™œì„±í™”)
    feature_server:
      enabled: false
  
  # ì—°ê²° ì •ë³´
  connection_timeout: 5000
  retry_attempts: 3
  connection_info:
    redis_host: "localhost:6379"
    offline_store_uri: "file://data/feature_store/dev_offline"

# ğŸ†• í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (DEV í™˜ê²½ ìµœì í™”)
hyperparameter_tuning:
  enabled: true
  timeout: 300  # 5ë¶„ ì œí•œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
  max_parallel_jobs: 2  # ë¡œì»¬ ë¦¬ì†ŒìŠ¤ ë³´í˜¸
  
  # ë¡œì»¬ SQLite ë°±ì—”ë“œ (ì™¸ë¶€ DB ë¶ˆí•„ìš”)
  study_storage: "sqlite:///data/optuna_studies.db"
  
  pruning:
    enabled: true
    algorithm: "MedianPruner"
    n_startup_trials: 3  # ë¹ ë¥¸ pruning
    n_warmup_steps: 5

environment:
  # DEV í™˜ê²½ ì‹ë³„ì
  gcp_project_id: "dev-local-project"

mlflow:
  # DEV í™˜ê²½: ë¡œì»¬ MLflow (íŒ€ ê³µìœ  ì‹œë®¬ë ˆì´ì…˜)
  tracking_uri: "./mlruns"
  experiment_name: "Campaign-Uplift-Modeling-Dev"
  artifact_location: "./data/artifacts"

serving:
  # DEV í™˜ê²½: API ì„œë¹™ ì™„ì „ í™œì„±í™”
  model_stage: "Staging"
  realtime_feature_store:
    store_type: "filesystem"  # ì™¸ë¶€ Redis ëŒ€ì‹  filesystem
    connection:
      base_path: "./data/feature_store/dev_online"

artifact_stores:
  augmented_dataset:
    enabled: true
    base_uri: "file://./data/artifacts/dev_augmented"
  
  preprocessed_dataset:
    enabled: true  # DEV í™˜ê²½ì—ì„œ ì¤‘ê°„ ê²°ê³¼ ì €ì¥
    base_uri: "file://./data/artifacts/dev_preprocessed"
  
  prediction_results:
    enabled: true
    base_uri: "file://./data/artifacts/dev_predictions"

# ğŸ†• ë¡œê¹… ì„¤ì • (DEV í™˜ê²½ ìƒì„¸ ë¡œê¹…)
logging:
  level: "DEBUG"
  format: "detailed"
  handlers:
    - type: "console"
      level: "INFO"
    - type: "file"
      level: "DEBUG"
      filename: "./logs/dev_app.log"
      max_size: "10MB"
      backup_count: 5

# ğŸ†• DEV í™˜ê²½ ìµœì í™”
development:
  auto_reload: true
  debug_mode: true
  
  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì„¤ì •
  sample_data_size: 10000
  cache_preprocessing: true
  
  # DEV í™˜ê²½ ì•ˆì „ì¥ì¹˜
  max_training_time: 1800  # 30ë¶„ ì œí•œ
